<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | OpenPOWER@UNICAMP</title>
    <link>https://openpower.ic.unicamp.br/post/</link>
      <atom:link href="https://openpower.ic.unicamp.br/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 19 Jun 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://openpower.ic.unicamp.br/img/icon-192.png</url>
      <title>Posts</title>
      <link>https://openpower.ic.unicamp.br/post/</link>
    </image>
    
    <item>
      <title>Using GitLab CI with GitHub repositories</title>
      <link>https://openpower.ic.unicamp.br/post/gitlab-ci-with-github-repo/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/gitlab-ci-with-github-repo/</guid>
      <description>&lt;p&gt;Despite GitHub offering some options for CI-CD platforms, such as Travis and Actions, you may want to try out GitLab’s alternatives, but feel turned off by the fact you might need to take your codes to a different platform. To avoid this problem, using these two platforms together sounds like a good idea. The goal of this tutorial is to show you how to configure a GitLab runner, a pipeline, and use the GitLab-CI to run your GitHub pipelines, without the need for premium services.&lt;/p&gt;
&lt;p&gt;For this tutorial, you will need to be registered to GitHub and GitLab, and also a computer where the GitLab-runner will be installed.&lt;/p&gt;
&lt;h2 id=&#34;configuring-the-gitlab-repo&#34;&gt;Configuring the GitLab repo&lt;/h2&gt;
&lt;p&gt;The first thing you need to do is to create a repository on GitLab. In this repository, the only thing you have to do is to create a file called &amp;ldquo;.gitlab-ci.yml&amp;rdquo;. This file works as a &amp;ldquo;travis.yml&amp;rdquo; file and is responsible for the configuration of the pipeline, such as the steps to be executed, installing the prerequisites&amp;hellip; You can find more information about it in the &lt;a href=&#34;https://docs.gitlab.com/ee/ci/yaml/gitlab_ci_yaml.html&#34;&gt;gitlab documentation&lt;/a&gt;. For this tutorial, the goal is to use this file to retrieve the contents of the GitHub repository. The easiest way of doing this is to clone the repository before running the script.&lt;/p&gt;
&lt;p&gt;To make it clear, suppose your GitHub repository contains a &amp;ldquo;build.sh&amp;rdquo; file, and your pipeline consists of running this script. Then, your .gitlab-ci.yml would look something like this:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;default:
  tags:
    - *your_runner_tag* #This tag is used to select a runner

stages:
  - build

before_script:
  - git clone *your_github_repo_url*

build:
  stage: build
  script: 
    - bash github_repo/build.sh
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;setting-up-a-gitlab-runner&#34;&gt;Setting up a GitLab-runner&lt;/h2&gt;
&lt;p&gt;The next part of the configuration is to set up a runner. To do so,  you will need a computer where the runner will be installed. One suggestion is to use a &lt;a href=&#34;https://openpower.ic.unicamp.br/minicloud/&#34;&gt;minicloud VM&lt;/a&gt; for this purpose.
After connecting to the VM, the next step is to install the runner. To do that, you can follow the steps described below. For more details, you can check the &lt;a href=&#34;https://docs.gitlab.com/runner/install/linux-manually.html#using-binary-file&#34;&gt;gitlab documentation&lt;/a&gt;.
First, download the runner&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo curl -L --output /usr/local/bin/gitlab-runner &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-ppc64le&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo chmod +x /usr/local/bin/gitlab-runner
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, you must create a user for the runner.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo useradd --comment &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;GitLab Runner&amp;#39;&lt;/span&gt; --create-home gitlab-runner --shell /bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note: Make sure to give this user the right permissions to execute your pipeline. For example, make sure this user is in the sudoers list if you plan to execute any sudo commands. Also, if you want the pipelines to be run as an already existing user, you can skip the previous step.&lt;/p&gt;
&lt;p&gt;Finally, install and execute the runner&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo gitlab-runner install --user&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;gitlab-runner –working-directory&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/home/gitlab-runner
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo gitlab-runner start
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Notice that, sometimes, due to an error, the working directory might not be set to the option you wanted. To fix this, you must edit the /etc/systemd/system/gitlab-runner.service file, and change the working directory to the right one. You might need to reboot your computer to apply this change.&lt;/p&gt;
&lt;p&gt;Now that the GitLab runner is installed, you must register it, so it will be connected to your GitLab account.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo gitlab-runner register
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After that, type in the GitLab instance URL you are using (For example, &lt;a href=&#34;https://gitlab.com/&#34;&gt;https://gitlab.com/&lt;/a&gt;)
Then, your registration token will be required. To find it, go to the GitLab website, enter the repo you created for this CI project, and then go to “Settings” &amp;gt; “CI/CD”.  After that, click “Expand” on the right side of the “Runners” section. In the “Specific Runners” tab, you will find your registration token, copy it, and paste it to your terminal to continue the runner registration.&lt;/p&gt;
&lt;p&gt;The next step is to name your runner, so you can identify it later. Finally, you must add tags to the runner.  These tags will make it easier for you to choose a runner for your pipelines. For example, you can install python on this runner, then add the &amp;ldquo;python&amp;rdquo; tag to it, so you can use it on pipelines where python is required.&lt;/p&gt;
&lt;p&gt;Then, you will be asked to enter a maintenance note, but you can just hit &amp;ldquo;enter&amp;rdquo; and leave it blank.&lt;/p&gt;
&lt;p&gt;For the final step on the runner setup, you need to choose an executor. The main ones are docker and shell. If you choose docker, you must provide a docker image on the pipeline configuration, and your pipeline will be run on a container build with said image. On the other hand, if you choose &amp;ldquo;shell&amp;rdquo;, the pipeline will be executed on the shell of the computer where the runner was installed. Notice that, in order to use the docker executor, docker must be previously installed. After this choice, the runner is completely installed.&lt;/p&gt;
&lt;p&gt;Before you continue with the configuration, make sure to remove the &amp;ldquo;.bash_logout&amp;rdquo; file from the gitlab-runner user&amp;rsquo;s home folder, because if you don&amp;rsquo;t, an error will occur during the pipeline execution. Also, back on the GitLab website, in the Runners section you just visited, make sure to disable the &amp;ldquo;Allow shared runners for this project&amp;rdquo; option, under &amp;ldquo;Shared Runners” so your own runners will always be used.&lt;/p&gt;
&lt;h2 id=&#34;linking-the-github-and-gitlab-repositories&#34;&gt;Linking the GitHub and GitLab repositories&lt;/h2&gt;
&lt;p&gt;The last thing you have to do is to link both repositories so that whenever a change is made to GitHub, it will trigger the GitLab pipeline.
First, go to the GitLab repository, then &amp;ldquo;Settings&amp;rdquo; &amp;gt; &amp;ldquo;CI/CD&amp;rdquo;. Click the &amp;ldquo;Expand&amp;rdquo; button next to &amp;ldquo;Pipeline triggers&amp;rdquo; and create a new trigger by giving it a description and pressing &amp;ldquo;Add trigger&amp;rdquo;. After that, find the &amp;ldquo;Use webhook&amp;rdquo; option under the tokens and copy this URL, but make sure to change the REF_NAME to be the branch you are using for the project (possibly the main branch), and also change the TOKEN variable to the value of the token you just created.&lt;/p&gt;
&lt;p&gt;With this URL, head to your GitHub repository, and click &amp;ldquo;Settings&amp;rdquo; &amp;gt; &amp;ldquo;Webhooks&amp;rdquo; (under the &amp;ldquo;Code and automation&amp;rdquo; section). Click &amp;ldquo;Add webhook&amp;rdquo;, and under &amp;ldquo;Payload URL&amp;rdquo;, add the URL you got from GitLab (with the correct values for REF_NAME and TOKEN). You can leave the other options as they are and then add the webhook.&lt;/p&gt;
&lt;p&gt;After all those steps, every time you make a change to your GitHub repository, it should trigger GitLab, and use the runner you just configured to execute a pipeline.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simulating Microwatt with GHDL</title>
      <link>https://openpower.ic.unicamp.br/post/simulating-microwatt-with-ghdl/</link>
      <pubDate>Sat, 02 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/simulating-microwatt-with-ghdl/</guid>
      <description>&lt;p&gt;GHDL is an open-source analyzer, compiler and synthesizer for VHDL generating machine code from a Hardware Description Language. As it is not an interpreter, it allows for high speed simulation which is crucial for applications like the Microwatt, a tiny Open POWER ISA softcore.&lt;/p&gt;
&lt;p&gt;In this tutorial you will be guided step-by-step in the setup of your environment for simulating Microwatt with GHDL.&lt;/p&gt;
&lt;p&gt;Disclaimer: For the purpose of this tutorial I will be using an Ubuntu 20.04 system and I&amp;rsquo;ll assume you&amp;rsquo;re familiar with it.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;First of all, make sure you have this packages installed:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install -y build-essential gnat zlib1g-dev llvm-dev clang git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This includes the project&amp;rsquo;s dependencies, as well as git and the basic packages to build a project.&lt;/p&gt;
&lt;h2 id=&#34;installing-ghdl&#34;&gt;Installing GHDL&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ll now clone and build GHDL.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/ghdl/ghdl.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ghdl
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./configure --prefix&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/usr/local --enable-libghdl --with-llvm-config
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-microwatt&#34;&gt;Install Microwatt&lt;/h2&gt;
&lt;p&gt;We are now ready to clone and build Microwatt.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/antonblanchard/microwatt.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd microwatt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;testing&#34;&gt;Testing&lt;/h3&gt;
&lt;p&gt;Now that everything is installed we can run some code.
Fortunately the project already includes a hello_world ready to be executed, just change the file to be executed and then run the simulation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ln -s hello_world/hello_world.bin main_ram.bin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./core_tb &amp;gt; /dev/null
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see a lightbulb being drawn on the terminal.
But if you want something more substantial, you will find bundled a python runtime:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rm main_ram.bin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ln -s micropython/firmware.bin main_ram.bin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./core_tb &amp;gt; /dev/null
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;optional-build-micropython&#34;&gt;(Optional) Build MicroPython&lt;/h3&gt;
&lt;p&gt;To compile code for the Power platform you will need a cross compiler, luckily it is already in the Ubuntu repository.
With that, just compile the project normally.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install -y gcc-powerpc64le-linux-gnu
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/micropython/micropython.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd micropython/ports/powerpc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make -j&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;nproc&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; UART&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;lpc_serial
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ../../../
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rm main_ram.bin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ln -s ../micropython/ports/powerpc/build/firmware.bin main_ram.bin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./core_tb &amp;gt; /dev/null
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that it is necessary to set the UART interface to lpc_serial when simulating using GHDL.&lt;/p&gt;
&lt;h2 id=&#34;compiling-code&#34;&gt;Compiling code&lt;/h2&gt;
&lt;p&gt;To compile code for the Power architecture you need the cross compiler shown in the optional section on MicroPython.
With it installed, just duplicate the hello_world folder and use it as a base for your code.
It is important to remember that the communication should be done using the headers provided by MicroWatt, as the terminal is redirected to the UART port.&lt;/p&gt;
&lt;h2 id=&#34;problems-using-wsl-and-windows&#34;&gt;Problems using WSL and Windows&lt;/h2&gt;
&lt;p&gt;You can do this entire process within WSL for Windows 10 and 11, but some people will experience random crashes when using the Home version of these systems. This is due to some incompatibility of the Virtual Machine Platform component with your hardware. A possible solution is to upgrade to Windows Pro, but I opted to use Ubuntu instead.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ghdl.github.io/ghdl/development/building/index.html&#34;&gt;Building GHDL from sources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/antonblanchard/microwatt&#34;&gt;A tiny Open POWER ISA softcore written in VHDL 2008&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Install Docker from package</title>
      <link>https://openpower.ic.unicamp.br/post/install-docker/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/install-docker/</guid>
      <description>&lt;p&gt;Docker is a set of systems that use virtualization to deliver software in packages, which are called containers.
The containers are isolated from the operating system and other containers, they have unique libraries,
as well as packages and configuration files. In addition, they can run different operating systems and
have a lower resource cost than traditional virtualization.&lt;/p&gt;
&lt;p&gt;We provide the &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/docker/&#34;&gt;docker-ce&lt;/a&gt;, an edition of Docker that is free software,
updated by the community. However, the package is officially not available for the Power architecture (ppc64 / ppc64le).
Thus, the laboratory makes the latest versions available for installation from the package managers:
Advanced Packaging Tool (APT) and Red Hat Package Manager (RPM).&lt;/p&gt;
&lt;p&gt;This tutorial shows the step-by-step installation of Docker using
the &amp;ldquo;.deb/.rpm&amp;rdquo; package. If you want to install using a package manager, read
&lt;a href=&#34;https://openpower.ic.unicamp.br/post/installing-docker-from-repository/&#34;&gt;Installing Docker from the OpenPower Lab Repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;p&gt;First of all, you need to install the Docker requirements.
You can perform this operation using one of the commands below:&lt;/p&gt;
&lt;h3 id=&#34;to-ubuntudebian&#34;&gt;To Ubuntu/Debian:&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install -y wget libseccomp2 libc6 libdevmapper1.02.1 libsystemd0 apparmor ca-certificates git libltdl7 pigz procps xz-utils runc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;to-rhelcentosfedora&#34;&gt;To RHEL/CentOS/Fedora:&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo yum update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo yum install -y wget libseccomp glibc-utils device-mapper-libs systemd-libs ca-certificates git libtool-ltdl pigz procps xz runc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-docker&#34;&gt;Install Docker&lt;/h2&gt;
&lt;p&gt;To install Docker-ce, it is necessary to download and install the packages:
&lt;strong&gt;containerd&lt;/strong&gt;, &lt;strong&gt;docker-ce&lt;/strong&gt;, &lt;strong&gt;docker-ce-cli&lt;/strong&gt; and &lt;strong&gt;docker-ce-rootless-extras&lt;/strong&gt;.
All these packages are available for download through our &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/&#34;&gt;FTP&lt;/a&gt;,
use one of the commands below to perform this operation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Containerd was used in version 1.5.7 and Docker in 20.10.6. Change package versions! For the latest versions,
access &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/&#34;&gt;Oplab FTP&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;to-ubuntudebian-1&#34;&gt;To Ubuntu/Debian&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://oplab9.parqtec.unicamp.br/pub/repository/debian/ppc64el/containerd/containerd-1.5.7-ppc64le.deb https://oplab9.parqtec.unicamp.br/pub/ppc64el/docker/version-20.10.6/ubuntu-focal/docker-ce-rootless-extras_20.10.6~3-0~ubuntu-focal_ppc64el.deb https://oplab9.parqtec.unicamp.br/pub/ppc64el/docker/version-20.10.6/ubuntu-focal/docker-ce-cli_20.10.6~3-0~ubuntu-focal_ppc64el.deb https://oplab9.parqtec.unicamp.br/pub/ppc64el/docker/version-20.10.6/ubuntu-focal/docker-ce_20.10.6~3-0~ubuntu-focal_ppc64el.deb
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To install on Ubuntu, use the &lt;strong&gt;dpkg&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo dpkg -i containerd-1.5.7-ppc64le.deb docker-ce-rootless-extras_20.10.6~3-0~ubuntu-focal_ppc64el.deb docker-ce-cli_20.10.6~3-0~ubuntu-focal_ppc64el.deb docker-ce_20.10.6~3-0~ubuntu-focal_ppc64el.deb
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;to-rhelcentosfedora-1&#34;&gt;To RHEL/CentOS/Fedora:&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://oplab9.parqtec.unicamp.br/pub/repository/rpm/ppc64le/containerd/containerd-1.5.7-1.ppc64le.rpm https://oplab9.parqtec.unicamp.br/pub/ppc64el/docker/version-20.10.6/centos-8/docker-ce-rootless-extras-20.10.6-3.el8.ppc64le.rpm https://oplab9.parqtec.unicamp.br/pub/ppc64el/docker/version-20.10.6/centos-8/docker-ce-cli-20.10.6-3.el8.ppc64le.rpm https://oplab9.parqtec.unicamp.br/pub/ppc64el/docker/version-20.10.6/centos-8/docker-ce-20.10.6-3.el8.ppc64le.rpm
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To install on CentOS 8, use the &lt;strong&gt;yum localinstall&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo yum localinstall containerd-1.5.7-1.ppc64le.rpm docker-ce-rootless-extras-20.10.6-3.el8.ppc64le.rpm docker-ce-cli-20.10.6-3.el8.ppc64le.rpm  docker-ce-20.10.6-3.el8.ppc64le.rpm
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;enable-and-verify-docker&#34;&gt;Enable and verify Docker&lt;/h2&gt;
&lt;p&gt;Before using Docker, you need to enable it and start it.
This process is also used to verify that the installation was successful.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl enable docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl start docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl status docker
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Expected output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ubuntu@docker-build:~$ sudo systemctl enable docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ubuntu@docker-build:~$ sudo systemctl start docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ubuntu@docker-build:~$ sudo systemctl status docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;● docker.service - Docker Application Container Engine
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     Loaded: loaded &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;/lib/systemd/system/docker.service; enabled; vendor preset: enabled&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     Active: active &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;running&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; since Sat 2021-12-04 00:15:12 UTC; 3min 33s ago
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TriggeredBy: ● docker.socket
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;       Docs: https://docs.docker.com
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   Main PID: &lt;span style=&#34;color:#ae81ff&#34;&gt;88776&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;dockerd&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      Tasks: &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     Memory: 76.6M
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     CGroup: /system.slice/docker.service
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;             └─88776 /usr/bin/dockerd -H fd:// --containerd&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/run/containerd/containerd.sock
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;04&lt;/span&gt; 00:15:10 docker-build dockerd&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;88776&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2021-12-04T00:15:10.992533127Z&amp;#34;&lt;/span&gt; level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;warning msg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Your kernel does &amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Dec 04 00:15:10 docker-build dockerd[88776]: time=&amp;#34;&lt;/span&gt;2021-12-04T00:15:10.992943323Z&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; level=warning msg=&amp;#34;&lt;/span&gt;Your kernel does &amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;04&lt;/span&gt; 00:15:10 docker-build dockerd&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;88776&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2021-12-04T00:15:10.993053898Z&amp;#34;&lt;/span&gt; level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;warning msg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Your kernel does &amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Dec 04 00:15:10 docker-build dockerd[88776]: time=&amp;#34;&lt;/span&gt;2021-12-04T00:15:10.993340051Z&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; level=info msg=&amp;#34;&lt;/span&gt;Loading containers: &amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;04&lt;/span&gt; 00:15:11 docker-build dockerd&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;88776&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2021-12-04T00:15:11.419025732Z&amp;#34;&lt;/span&gt; level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;info msg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Default bridge (dock&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Dec 04 00:15:11 docker-build dockerd[88776]: time=&amp;#34;&lt;/span&gt;2021-12-04T00:15:11.585401847Z&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; level=info msg=&amp;#34;&lt;/span&gt;Loading containers: &amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;04&lt;/span&gt; 00:15:12 docker-build dockerd&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;88776&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2021-12-04T00:15:12.507244532Z&amp;#34;&lt;/span&gt; level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;info msg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Docker daemon&amp;#34;&lt;/span&gt; commi&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;04&lt;/span&gt; 00:15:12 docker-build dockerd&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;88776&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2021-12-04T00:15:12.507417125Z&amp;#34;&lt;/span&gt; level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;info msg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Daemon has completed&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Dec 04 00:15:12 docker-build systemd[1]: Started Docker Application Container Engine.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Dec 04 00:15:12 docker-build dockerd[88776]: time=&amp;#34;&lt;/span&gt;2021-12-04T00:15:12.675971607Z&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; level=info msg=&amp;#34;&lt;/span&gt;API listen on /run/d&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If the output looks like the one above, then your Docker is installed
and ready to use.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building Docker for POWER</title>
      <link>https://openpower.ic.unicamp.br/post/building-docker-for-power/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/building-docker-for-power/</guid>
      <description>&lt;p&gt;This blogpost aims to teach how to build and create a Docker .deb and .rpm packages starting from Docker 20.10 release, considering that since that version the Docker Engine and Docker CLI are built directly from the source repositories.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Moby-logo.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;&lt;em&gt;Requirements&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;We used Ubuntu 20.04 for this tutorial for both .deb and .rpm builds.&lt;br&gt;
First, make sure you have both &lt;em&gt;git&lt;/em&gt; and the &lt;em&gt;make&lt;/em&gt; package on your machine.&lt;br&gt;
You can install then with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install make
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install unzip
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After that, we need to install Docker-CE. To do that, just add our POWER packages repository to your machine:&lt;/p&gt;
&lt;p&gt;Edit the file &lt;code&gt;/etc/apt/sources.list&lt;/code&gt; by adding the following line:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;deb https://oplab9.parqtec.unicamp.br/pub/repository/debian/ ./&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Download our &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/key/openpower-gpgkey-public.asc&#34;&gt;GPG key&lt;/a&gt;, and use the command below to add it to the system:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-key add openpower-gpgkey-public.asc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After that, update the package list and install docker-ce:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install docker-ce
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;More information about our repository in: &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;POWER Repository&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;build-and-packaging&#34;&gt;Build and Packaging&lt;/h1&gt;
&lt;p&gt;We&amp;rsquo;ll need to download docker-cli and moby (current name of the docker engine) and clone the repositories from scan-cli-plugin and docker-ce-packaging.&lt;br&gt;
Clone the following docker repositories:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/docker/scan-cli-plugin.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/docker/docker-ce-packaging.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Download the desired version (we&amp;rsquo;ll use 20.10.6) of the cli and moby by downloading its releases (you can use &lt;code&gt;git clone&lt;/code&gt; to build the master branch too):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download the cli source code and change its zip name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://github.com/docker/cli/archive/refs/tags/v20.10.6.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv v20.10.6.zip cli.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download the moby source code and change its zip name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://github.com/moby/moby/archive/refs/tags/v20.10.6.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv v20.10.6.zip moby.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Unzip the downloaded source-codes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;unzip cli.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;unzip moby.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Change the folders name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv cli-20.10.6 cli
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv moby-20.10.6 moby
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Because the Docker Build uses containerd.io, we need to modify two files on docker-ce-packaging in order to use the community version of the same software, which is probably already installed on your machine if you installed Docker-CE from our repository(&lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;POWER Repository&lt;/a&gt;).&lt;br&gt;
Besides that&lt;/p&gt;
&lt;p&gt;Modify the files with python3 by running the following script:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Running Patching Script...&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deb_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;docker-ce-packaging/deb/common/control&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deb_ver &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;containerd (&amp;gt;= 1.2.1)&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rpm_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;docker-ce-packaging/rpm/SPECS/docker-ce.spec&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rpm_ver &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Requires: containerd &amp;gt;= 1.2.1&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Update debian containerd dependency&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Patching DEB...&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(deb_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;containerd.io \([^)]*\)&amp;#39;&lt;/span&gt;, deb_ver, data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; new, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Nothing was changed in the file.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;open(deb_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(new)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Update rpm containerd dependency&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Patching RPM...&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rpm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(rpm_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rpm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Requires: containerd.io [^\n]*&amp;#39;&lt;/span&gt;, rpm_ver, data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; new, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Nothing was changed in the file.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;open(rpm_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(new)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DONE Patching&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After the patch is done, we need to create specific folders inside &lt;code&gt;docker-ce-packaging&lt;/code&gt; and copy the other cloned repositories into that folders.&lt;/p&gt;
&lt;p&gt;From the outside of &lt;em&gt;docker-ce-packaging&lt;/em&gt;, do that with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create the folders&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p docker-ce-packaging/src/github.com/docker/cli
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p docker-ce-packaging/src/github.com//docker/docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p docker-ce-packaging/src/github.com/docker/scan-cli-plugin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Copy cli, moby and scan-cli-plugin&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo cp -r cli/* docker-ce-packaging/src/github.com/docker/cli
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo cp -r moby/* docker-ce-packaging/src/github.com/docker/docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo cp -r scan-cli-plugin/* docker-ce-packaging/src/github.com/docker/scan-cli-plugin
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;making-deb-packages&#34;&gt;Making .deb packages&lt;/h2&gt;
&lt;p&gt;Systems available:&lt;br&gt;
&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;ubuntu-buster, ubuntu-bionic, ubuntu-focal, ubuntu-groovy, ubuntu-hirsute, ubuntu-xenial&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;Debian:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;debian-bullseye, debian-buster&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;Raspbian:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;raspbian-bullseye, raspbian-buster&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Make the packages with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd docker-ce-packaging/deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;20.10.6 make ubuntu-focal
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;They will be available at: &lt;code&gt;docker-ce-packaging/deb/debbuild/&lt;/code&gt;&lt;br&gt;
In our example, the .deb files will be at&lt;br&gt;
&lt;code&gt;docker-ce-packaging/deb/debbuild/ubuntu-focal&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;files.png&#34; alt=&#34;deb files&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;making-rpm-packages&#34;&gt;Making .rpm packages&lt;/h2&gt;
&lt;p&gt;Edit the file &lt;code&gt;docker-ce-packaging/rpm/gen-rpm-ver&lt;/code&gt;&lt;br&gt;
by changing the characters &lt;code&gt;||&lt;/code&gt; to &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; in line 46&lt;/p&gt;
&lt;p&gt;Systems available:&lt;br&gt;
&lt;strong&gt;CentOS:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;centos-7, centos-8&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;Fedora:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;fedora-32, fedora-33, fedora-34&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;RHEL:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;rhel-7&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Make the packages with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd docker-ce-packaging/rpm
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;20.10.6 make centos-8
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;They will be available at: &lt;code&gt;docker-ce-packaging/rpm/rpmbuild/&lt;/code&gt;&lt;br&gt;
In our example, the .rpm files will be at&lt;br&gt;
&lt;code&gt;docker-ce-packaging/rpm/rpmbuild/centos-8/SRPMS&lt;/code&gt; and&lt;br&gt;
&lt;code&gt;docker-ce-packaging/rpm/rpmbuild/centos-8/RPMS/ppc64le&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;files-rpm.png&#34; alt=&#34;rpm files&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;&lt;em&gt;References&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Docker CLI: &lt;a href=&#34;https://github.com/docker/cli&#34;&gt;https://github.com/docker/cli&lt;/a&gt;&lt;br&gt;
Docker Engine: &lt;a href=&#34;https://github.com/moby/moby&#34;&gt;https://github.com/moby/moby&lt;/a&gt;&lt;br&gt;
scan-cli-plugin: &lt;a href=&#34;https://github.com/docker/scan-cli-plugin&#34;&gt;https://github.com/docker/scan-cli-plugin&lt;/a&gt;&lt;br&gt;
Docker-CE Packaging: &lt;a href=&#34;https://github.com/docker/docker-ce-packaging&#34;&gt;https://github.com/docker/docker-ce-packaging&lt;/a&gt;&lt;br&gt;
OpenPOWER@UNICAMP POWER Repository: &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;https://openpower.ic.unicamp.br/project/power-repository/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PowerBoard plugin for TensorBoard</title>
      <link>https://openpower.ic.unicamp.br/post/powerboard-plugin-for-tensorboard/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/powerboard-plugin-for-tensorboard/</guid>
      <description>&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;First we need to talk about the motivation behind this plugin. The architecture Power was designed for use in artificial intelligence and deep learning. Investigating tools for deep learning and machine learning we found TensorBoard. TensorBoard is a tool to view models which were created in TensorFlow, the TensorBoard is a toolkit that allows graphic visualization of your models, making it easier to understand the used model, debug bottlenecks and, as a result, optimize it. In this blog post, we’ll show how to use the plugin we’ve created, which adds a new feature to the TensorBoard, this plugin assists on debugging bottlenecks in conjunction with the trace-viewer.&lt;/p&gt;
&lt;h3 id=&#34;powerboard&#34;&gt;PowerBoard&lt;/h3&gt;
&lt;p&gt;PowerBoard is a plugin designed to show the power that is consumed while the neural network is trained, doing that  allows the trace-viewer a better understanding of the model and helps to debug the bottlenecks.&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.6 &amp;gt;=&lt;/li&gt;
&lt;li&gt;TensorFlow 2.2 &amp;gt;=&lt;/li&gt;
&lt;li&gt;TensorBoard 2.2 &amp;gt;=&lt;/li&gt;
&lt;li&gt;Pandas 1.2.1 &amp;gt;=&lt;/li&gt;
&lt;li&gt;ipmitool&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;If you&amp;rsquo;re having trouble installing tensorflow follow the link to a blog post that teaches you how to install tensorflow in the Power architecture:
&lt;a href=&#34;https://openpower.ic.unicamp.br/post/profiling-using-tensorboard-profiler/&#34;&gt;https://openpower.ic.unicamp.br/post/profiling-using-tensorboard-profiler/&lt;/a&gt;
&lt;a href=&#34;https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power/&#34;&gt;https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For the installation of PowerBoard Plugin acess the site  &lt;a href=&#34;https://pypi.org/project/powerboard/&#34;&gt;https://pypi.org/project/powerboard/&lt;/a&gt;, or use the following pip command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install powerboard
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now you&amp;rsquo;re able to use the powerboard. The powerboard possesses an implementation library called libipmi, which is responsible for accessing the low level register to obtain the power consumption. For this, do the following import:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; powerboard &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; libipmi
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;libipmi&#34;&gt;libipmi:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The function &lt;code&gt;start() &lt;/code&gt; : This function is responsible for measuring the power consumption and time of each aquisition.&lt;/li&gt;
&lt;li&gt;The function &lt;code&gt;stop() &lt;/code&gt; : This function is responsible for stopping the aquisition of data.&lt;/li&gt;
&lt;li&gt;The function &lt;code&gt;dbToCSV(&amp;lt;PATH&amp;gt;)&lt;/code&gt;: The implementation of the function gets the data and saves it to a database, when the database is full the implementation saves all data in a csv file. For this, the argument PATH is the path to a directory were the data will be stored. My suggestion is to default the path to &amp;ldquo;./data&amp;rdquo; like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;libipmi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dbToCSV(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;./data&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now you are able to test the plugin, for this I&amp;rsquo;ll show an example of the code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datetime &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datetime
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; packaging &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; version
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; powerboard &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; libipmi 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datasets, layers, models
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stamp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;now()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%Y%m&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;-%H%M%S&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;logdir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;logs/Nfit/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; stamp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;writer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create_file_writer(logdir)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trace_on(profiler&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(train_images, train_labels), (test_images, test_labels) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cifar10&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Normalize pixel values to be between 0 and 1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;train_images, test_images &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_images &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;, test_images &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;class_names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;airplane&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;automobile&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bird&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;deer&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;frog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ship&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;truck&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPooling2D((&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPooling2D((&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;losses&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SparseCategoricalCrossentropy(from_logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;libipmi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;start()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_images, train_labels, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(test_images, test_labels))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;test_loss, test_acc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_images,  test_labels, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;libipmi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stop()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;libipmi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dbToCSV(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;./data&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; writer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;as_default():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trace_export(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;convolution&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      step&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      profiler_outdir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;logdir)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;before you run the script let&amp;rsquo;s make a directory in tmp files, so go to  &lt;code&gt;/tmp&lt;/code&gt; by doing &lt;code&gt; cd /tmp&lt;/code&gt; and make a directory inside. I&amp;rsquo;ll create the &amp;ldquo;teste&amp;rdquo; directory inside of tmp, as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd /tmp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir teste
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now go to the directory which the script was saved and run the script. Now copy the following directory into the &lt;code&gt;/tmp/teste&lt;/code&gt; by doing:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp -r demo_logs /tmp/teste
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp -r logs /tmp/teste
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now run the TensorBoard:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; tensorboard --logdir  /tmp/teste
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now let&amp;rsquo;s have some fun by cracking our heads to understand the bottlenecks using the trace-viewer and powerboard tools.
the following image shows the powerboard.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;power2.png&#34; alt=&#34;powerboard&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 1: PowerBoard.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now I&amp;rsquo;ll show the trace-viewer overview.
&lt;img src=&#34;trace-viewer2.png&#34; alt=&#34;TRACE-VIEWER&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 2: Trace-viewer overview.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let&amp;rsquo;s zoom in the image. You may control the graph by clicking in the button &lt;code&gt;w&lt;/code&gt; to zoom in , &lt;code&gt;s&lt;/code&gt; to zoom out, &lt;code&gt;d&lt;/code&gt; to scroll right and &lt;code&gt;e&lt;/code&gt; to scroll left.
&lt;img src=&#34;trace2.png&#34; alt=&#34;TRACE-VIEWER&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 3: Trace-viewer zoom in.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The trace-viewer cracks, parallels and executes all operations in CPU and/or GPU to train our neural network. If you&amp;rsquo;re using GPU the documentation of TensorBoard says &amp;ldquo;As a general rule of thumb, it is a good idea to always keep the device (GPU/TPU) active.
Use the tf.data API to optimize the input pipeline. In this case, let&amp;rsquo;s cache the training dataset and prefetch the data to ensure that there is always data available for the GPU to process. See here for more details on using tf.data to optimize your input pipelines&amp;rdquo;. In the trace-viewer we have the trace-context to aid in a better understanding of what is happening.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Go to: &lt;a href=&#34;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&#34;&gt;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&lt;/a&gt; for a complete documentation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;trace-context.png&#34; alt=&#34;TRACE-VIEWER CONTEXT&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 4: Trace-viewer: trace context.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Click on the first occurrence of the traceContext and look at &amp;lsquo;slice&amp;rsquo;, this part of the trace viewer shows all the arguments of the function, such as the time spent on this function.
&lt;img src=&#34;traceContext.png&#34; alt=&#34;TRACE-VIEWER CONTEXT1&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 5: Trace context: inside of slice.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that we are at the epoch number &amp;ldquo;0&amp;rdquo; and step_name &amp;ldquo;0&amp;rdquo;, that is, in this part of the x-axis the graph indicates the first image to train our neural network. If we proceed to the next trace context it will follow to the next images to be trained. When the epoch value changes to 1 it means that we have finished training our neural network for the first time, and a new epoch will begin. Note that the size of the set of images is selected by the batch_size slice of our code, that is, we take the total number of images from the dataset and divide them by batch_size, in general the batch_size are powers of 2.
&lt;img src=&#34;traceContext2.png&#34; alt=&#34;TRACE-VIEWER CONTEXT1&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 6: Trace context: the next interation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now the next part is understanding the power consumption and relationships with the code. For this the following image shows the last interation of 1 complete epoch:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;traceContext3.png&#34; alt=&#34;TRACE-VIEWER CONTEXT1&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 7: Trace context: the last interation of epoch 0.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that a full epoch takes about 22 seconds, as shown by the powerboard tab. Symmetry in the graph is expected, but it does not occur. Also note that between times 27.31 s and 28.78 s we have a sudden increase in power, so we will go in the trace-viewer to look at what is being carried out during this interval. In the meantime, we note that there is the following set of images from the training in epoch 1 [185-258]. Returning this set to epoch 0 it corresponds to the time interval between 9.35 s and 11.13 s.
It is possible to conclude that theoretically the epochs should be symmetrical in terms of operations, that is, the energy expenditure should be the same, but it is noticed that something beyond the code is supplying this increase in extra power consumption by the same part of operations. Perhaps a new approach at a lower level would be needed to reach better conclusions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Installing Tensorflow on POWER</title>
      <link>https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power/</link>
      <pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power/</guid>
      <description>&lt;p&gt;TensorFlow is a very popular open-source library for Machine Learning and in this post we will see two ways (from a Community Supported Build and from the IBM Watson Machine Learning Community Edition) of installing it on POWER.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;tf-logo.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;installing-tensorflow-from-the-community-supported-build&#34;&gt;&lt;em&gt;Installing TensorFlow from the Community Supported Build&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;On the TensorFlow repository README on GitHub (&lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;) there is a list of community builds of TensorFlow, in which includes CPU and GPU builds for POWER.&lt;/p&gt;
&lt;p&gt;We will be using the links available on there to install TensorFlow on POWER.&lt;/p&gt;
&lt;h3 id=&#34;before-installation&#34;&gt;Before Installation&lt;/h3&gt;
&lt;p&gt;Install the build-essential package with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get install build-essential
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;download-and-install-anaconda-package-manager&#34;&gt;Download and Install Anaconda package manager:&lt;/h3&gt;
&lt;p&gt;We&amp;rsquo;ll use Anacona to install TensorFlow within a virtual environment.&lt;/p&gt;
&lt;p&gt;Download: &lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;https://www.anaconda.com/products/individual&lt;/a&gt;&lt;br&gt;
Remember to check the script sha256sum: &lt;a href=&#34;https://docs.anaconda.com/anaconda/install/hashes/&#34;&gt;https://docs.anaconda.com/anaconda/install/hashes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To install Anaconda Individual Edition, you just need to run the script downloaded and follow the inscructions that it provides.&lt;/p&gt;
&lt;p&gt;Create Virtual Environment and activate it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create --name tf_env python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.6 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate tf_env 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We&amp;rsquo;ll be using python3.6 for this environment installation.&lt;/p&gt;
&lt;p&gt;To install Anaconda Individual Edition, you just need to run the script downloaded and follow the inscructions that it provides.&lt;/p&gt;
&lt;h3 id=&#34;download-and-install-a-tensorflow-build&#34;&gt;Download and Install a TensorFlow build:&lt;/h3&gt;
&lt;p&gt;The Community Supported Builds from TensorFlow repository README provides both TF Release 1.15 and 2.x versions for both CPU-only and GPU.&lt;/p&gt;
&lt;p&gt;In this tutorial we will be installing a 2.x CPU-only version, altough the same process can be use for the GPU version.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Access &lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt; and select the needed build.&lt;br&gt;
We&amp;rsquo;ll use the Release 2.x CPU (&lt;a href=&#34;https://powerci.osuosl.org/job/TensorFlow2_PPC64LE_CPU_Release_Build/&#34;&gt;https://powerci.osuosl.org/job/TensorFlow2_PPC64LE_CPU_Release_Build/&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;builds.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Download the needed version and pay attention to the requirements (for instance, our selected build was built for GLIBC 2.17 and above).&lt;br&gt;
We&amp;rsquo;ll download the cp36 version, since we created a virtual conda environment for python 3.6.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;downloads.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;After the .whl file was downloaded, we&amp;rsquo;ll install it with pip within our conda environment.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;attention&#34;&gt;Attention&lt;/h2&gt;
&lt;p&gt;When installing TensorFlow, it is possible that some requirements errors occurs. If that happens, just install the missing library and try instaling TensorFlow again.&lt;/p&gt;
&lt;p&gt;For intance, we needed to install scipy 1.4.1 and h5py before the installation succeeded, and that can be done with Anaconda with the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda install -c conda-forge scipy&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1.4.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda install -c conda-forge h5py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Installing TensorFlow from the .whl file with pip inside the conda environment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install tensorflow_cpu-2.2.0-cp36-cp36m-linux_ppc64le.whl
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After the installation is completed, check TensorFlow within a python shell with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__version__)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;alternative-installing-tensorflow-with-watson-machine-learning-community-edition&#34;&gt;&lt;em&gt;[ALTERNATIVE] Installing TensorFlow with Watson Machine Learning Community Edition&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;IBM Watson Machine Learning Community Edition also provides a TensorFlow installation through Anaconda, which will be taught in this tutorial.&lt;/p&gt;
&lt;h3 id=&#34;download-and-install-anaconda-package-manager-1&#34;&gt;Download and Install Anaconda package manager:&lt;/h3&gt;
&lt;p&gt;Download: &lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;https://www.anaconda.com/products/individual&lt;/a&gt;&lt;br&gt;
Remember to check the script sha256sum: &lt;a href=&#34;https://docs.anaconda.com/anaconda/install/hashes/&#34;&gt;https://docs.anaconda.com/anaconda/install/hashes/&lt;/a&gt;&lt;br&gt;
To install Anaconda Individual Edition, you just need to run the script downloaded and follow the inscructions that it provides.&lt;/p&gt;
&lt;h3 id=&#34;add-wmlce-channel-to-anaconda&#34;&gt;Add WMLCE Channel to Anaconda&lt;/h3&gt;
&lt;p&gt;After the installation, add WMLCE (IBM Watson Machine Learning Community Edition) channel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda config --prepend channels &lt;span style=&#34;color:#ae81ff&#34;&gt;\ &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Create an Anaconda Python3.6 environment for WMLCE and activate it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Currently (09/2020) WMLCE only works with python version 3.6&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create --name wmlce_env python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.6 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate wmlce_env 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;install-tensorflow&#34;&gt;Install TensorFlow&lt;/h3&gt;
&lt;p&gt;For CPU-only use, install TensorFlow with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda install tensorflow
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For GPU use, install TensorFlow with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda install tensorflow
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TF is now installed and ready for use.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference:&lt;/h2&gt;
&lt;p&gt;Anaconda:&lt;br&gt;
&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;https://www.anaconda.com/products/individual&lt;/a&gt;&lt;br&gt;
TensorFlow GitHub repository:&lt;br&gt;
&lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;&lt;br&gt;
IBM Watson Machine Learning Community Edition:&lt;br&gt;
&lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/SS5SF7_1.6.1/navigation/welcome.html&#34;&gt;https://www.ibm.com/support/knowledgecenter/SS5SF7_1.6.1/navigation/welcome.html&lt;/a&gt;&lt;br&gt;
WMLCE softwares list:&lt;br&gt;
&lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/SS5SF7_1.6.1/navigation/wmlce_software_pkgs.html&#34;&gt;https://www.ibm.com/support/knowledgecenter/SS5SF7_1.6.1/navigation/wmlce_software_pkgs.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>IBM Power Systems - Power8, Power9 and Power10</title>
      <link>https://openpower.ic.unicamp.br/post/series-ibm-power/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/series-ibm-power/</guid>
      <description>&lt;p&gt;In a comparison between IBM Power and x86, it can be said that the best options between them will depend on their use.
The x86 chips are intended for general use, have good scalability and high performance in almost all uses.
On the other hand, Power chips are focused on using high-performance and high-performance servers.
It has support to meet emerging demands, it has virtualization natively,
with several hardware resources focused on virtualization, being the best possible choice for this type of work.&lt;/p&gt;
&lt;p&gt;In addition, IBM Power is focused on the business line, having support plans for different business activities.
Mainly focused on virtualization solutions, to meet massive work demands.
In addition, the chips have resources to share jobs or pool resources, making multiple servers behave as one.&lt;/p&gt;
&lt;p&gt;In this way, IBM Power becomes a fundamental part of the business plan of any company linked to technology or that needs a great scalability of resources to meet a massive demand for work.
As well as mainly for the cloud computing area.&lt;/p&gt;
&lt;h2 id=&#34;power8&#34;&gt;POWER8&lt;/h2&gt;
&lt;p&gt;Power8 was presented by IBM in 2014. There, IBM made several improvements over its previous version.
The machines that were created with this chip, had the provision of 6 to 12 cores, in addition to a clock that varies from 2.5 GHz to 5 GHz.
Power8 has 32 KB for instructions + 64 KB for data in L1 cache, 512 KB for SRAM type in L2 cache, 96 MB for eDRAM type in L3 cache and 128 MB for eDRAM type in L4 cache.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Core&lt;/th&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;th&gt;L1 cache&lt;/th&gt;
&lt;th&gt;L2 cache&lt;/th&gt;
&lt;th&gt;L3 cache&lt;/th&gt;
&lt;th&gt;L4 cache&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;6 to 12&lt;/td&gt;
&lt;td&gt;2.5 GHz to 5 GHz&lt;/td&gt;
&lt;td&gt;64 KB + 32 KB&lt;/td&gt;
&lt;td&gt;512 KB&lt;/td&gt;
&lt;td&gt;96 MB&lt;/td&gt;
&lt;td&gt;128 MB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When it comes to processors, memory is a fundamental resource.
The cache memory is faster than the main memory (RAM memory),
because of that, its size is fundamental for better processor performance. When compared to the previous version of the chip, the L3 cache memory had its size increased.
This resulted in part to the higher performance of the processor compared to its predecessor.&lt;/p&gt;
&lt;p&gt;Power8 has many more features than its x86 competitors and its predecessor, being more powerful than them.
In addition, it has support for simultaneous multithreading with eight cores per thread (SMT-8), having a very high degree of parallelism.&lt;/p&gt;
&lt;h2 id=&#34;power9&#34;&gt;POWER9&lt;/h2&gt;
&lt;p&gt;Power9 was presented by IBM in 2017. This version has improved core and hardware, the chip is smaller resulting in an optimization in energy consumption.
The number of cores doubled to 24, the clock was set at 4 GHz.
Power9 has 32 KB for instructions + 32 KB for data in L1 cache, 512 KB for SRAM type in L2 cache, 128 MB for eDRAM type in L3 cache.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Core&lt;/th&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;th&gt;L1 cache&lt;/th&gt;
&lt;th&gt;L2 cache&lt;/th&gt;
&lt;th&gt;L3 cache&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;4 GHz&lt;/td&gt;
&lt;td&gt;32 KB + 32 KB&lt;/td&gt;
&lt;td&gt;512 KB&lt;/td&gt;
&lt;td&gt;128 MB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The increase in the number of cores, plus the reduction in the size of the chip, with the increase of the L3 cache, optimizes and increases the processing power.
Power9 has 1.5x better performance and 2x more memory than Power8.&lt;/p&gt;
&lt;p&gt;Power9 has a greater acceleration than its previous versions, it had optimized the reading of memories of the type DDR4.
Based on the acceleration, it was possible to reduce the cycle processes, the cost of hardware and increase efficiency.&lt;/p&gt;
&lt;p&gt;The chip has been improved to have a higher bandwidth and low latency interface.
This improvement was achieved through an interface created by NVIDIA, called NVLink.
In addition, the architecture has also been optimized for emerging workloads.
Improving your performance in carrying out work for high performance computing.&lt;/p&gt;
&lt;p&gt;All of these improvements were made with the prospect of creating a more optimized processor to develop high-performance operations, from cloud computing, to large data centers and research.&lt;/p&gt;
&lt;h2 id=&#34;power10&#34;&gt;POWER10&lt;/h2&gt;
&lt;p&gt;Power10 was presented by IBM in 2020. The chip has been enhanced for faster processing speed and greater capacity for intensive calculations.
The number of cores can vary from 15 to 30, with a clock that varies from 4.5 GHz to 4 GHz.
Power10 has 32 KB for instructions + 32 KB for data in the L1 cache, 2 MB type SRAM in the L2 cache, 128 MB type eDRAM in the L3 cache.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Core&lt;/th&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;th&gt;L1 cache&lt;/th&gt;
&lt;th&gt;L2 cache&lt;/th&gt;
&lt;th&gt;L3 cache&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;15 to 30&lt;/td&gt;
&lt;td&gt;3.5 GHz to 4 GHz&lt;/td&gt;
&lt;td&gt;32 KB + 32 KB&lt;/td&gt;
&lt;td&gt;2 MB&lt;/td&gt;
&lt;td&gt;128 MB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Power10 is designed to achieve a high degree of performance in existing encryption standards and in future encryption standards.
Power10 has implemented a mathematical matrix accelerator in its cores.
This resulted in an AI 10x, 15x, 20x faster inference for FP32, BFloat16 and INT8 calculations, respectively, compared to Power9.&lt;/p&gt;
&lt;p&gt;Several changes have been made compared to its predecessor.
Power10 had its reading hardware optimized, support for DDR5 memories was added,
the L2 cache memory had its capacity increased, in addition to the chip which had its size reduced.
These characteristics mean that the Power10 chip has increased performance and its optimization prepares the chip to support the newest technologies developed.&lt;/p&gt;
&lt;p&gt;IBM implemented PowerAXON on Power10.
It has the ability to share the main memory of a Power10 server with other Power10 servers.
This feature can be used to allow a set of small machines to become a large machine with great processing power.&lt;/p&gt;
&lt;p&gt;With all the features of previous versions optimized, with the addition of innovative features and with increased processing power and capacity,
make this processor the most powerful that IBM has ever created.
Perfect for data analysis jobs, cloud computing, high performance programming and among other jobs that need up-to-date and powerful machines.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;OpenPower Lab does not have Power10 servers within its collection.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Options for Kubernetes-CRI (Container Runtime Interface)</title>
      <link>https://openpower.ic.unicamp.br/post/options-for-kubernetes-cri/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/options-for-kubernetes-cri/</guid>
      <description>&lt;p&gt;Docker has been used for a long time with Kubelet and Kubernetes. However, recently Docker announced that it would cut
&lt;a href=&#34;https://www.zdnet.com/article/kubernetes-dropping-docker-is-not-that-big-of-a-deal/&#34;&gt;support for kubelet&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Because of this, this blog intends to present existing options to assume this role with Kubernetes.
All Kubernetes needs is a Container Runtime Interface (CRI), for that there are several portable software for the IBM Power architecture (ppc64le),
as it will be presented throughout the post.&lt;/p&gt;
&lt;h2 id=&#34;main-runtimes&#34;&gt;Main Runtimes&lt;/h2&gt;
&lt;p&gt;Through the Open Source community it is possible to find some packages like: &lt;a href=&#34;https://github.com/containerd/cri&#34;&gt;Containerd-CRI&lt;/a&gt;, &lt;a href=&#34;https://github.com/cri-o/cri-o&#34;&gt;Cri-O&lt;/a&gt; e &lt;a href=&#34;https://github.com/google/gvisor&#34;&gt;Gvisor&lt;/a&gt;.
All packages have the function of providing the support that Kubernetes needs, and some of them even have extra and more specialized features.&lt;/p&gt;
&lt;p&gt;For most of these packages it was possible to port to the Power architecture, however, as will be presented later, some were not possible to perform portability.&lt;/p&gt;
&lt;h2 id=&#34;containerd-cri&#34;&gt;Containerd-CRI&lt;/h2&gt;
&lt;h3 id=&#34;description-and-portability&#34;&gt;Description and Portability&lt;/h3&gt;
&lt;p&gt;CRI is a Containerd plugin for Kubernetes, it is a Container Runtime Interface (CRI) implemented to interact with Kubelet in the creation of containers using Containerd as Runtime.&lt;/p&gt;
&lt;p&gt;The software does not have official support for the IBM Power architecture, despite that, OpenPower Lab did a build job and made the package functional in Power. In addition, we offer the package in the following formats: binary, .rpm and .deb.&lt;/p&gt;
&lt;h3 id=&#34;build&#34;&gt;Build&lt;/h3&gt;
&lt;p&gt;The construction of the package was done following the recipe for CI/CD of the package, it is possible to obtain it through the &lt;a href=&#34;https://github.com/Unicamp-OpenPower/containerd-cri-releases/blob/master/build.sh&#34;&gt;GitHub&lt;/a&gt;.
Based on it, we make the package available in binary format which can be obtained through &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/containerd-cri/&#34;&gt;FTP&lt;/a&gt;.
The rest of the packages, available for Debian and RHEL based distros, can be installed through &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;OPenPower lab repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;cri-o&#34;&gt;Cri-O&lt;/h2&gt;
&lt;h3 id=&#34;description-and-portability-1&#34;&gt;Description and Portability&lt;/h3&gt;
&lt;p&gt;Cri-O is a CRI (Container Runtime Interface) implementation, being a lighter alternative to Docker as a Runtime. Since Docker is no longer an option, it becomes one of the lightest options available.&lt;/p&gt;
&lt;p&gt;The software does not have official support for the IBM Power architecture, despite that, OpenPower Lab did a build job and made the package functional in Power. In addition, the package is available in binary version and in .deb format.
Although it was not possible to generate the .rpm package, it is still possible to install the package with the installation of the binary.&lt;/p&gt;
&lt;h3 id=&#34;build-1&#34;&gt;Build&lt;/h3&gt;
&lt;p&gt;The construction of the package can be obtained through &lt;a href=&#34;https://github.com/Unicamp-OpenPower/crio-build&#34;&gt;build&lt;/a&gt;. The binary can be obtained by &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/crio/&#34;&gt;FTP&lt;/a&gt;, despite this, it is necessary to install the &lt;a href=&#34;https://github.com/cri-o/cri-o/blob/master/install.md#runtime-dependencies&#34;&gt;prerequisites&lt;/a&gt;.
The .deb format can be installed via the &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;OPenPower lab repository&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;install&#34;&gt;Install&lt;/h3&gt;
&lt;p&gt;It was not possible to convert the binary to the RPM Package Manager, so the only way to install these systems is to install the &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/crio/&#34;&gt;binary&lt;/a&gt;.
Before installing the binary it is necessary to install the &lt;a href=&#34;https://github.com/cri-o/cri-o/blob/master/install.md#runtime-dependencies&#34;&gt;prerequisites&lt;/a&gt;.
After installing the prerequisites, just use the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo tar -C / -xzvf crio-1.20.0.linux-ppc64le.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Confirm the installation by executing the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;crio --version
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;gvisor&#34;&gt;Gvisor&lt;/h2&gt;
&lt;h3 id=&#34;description-and-portability-2&#34;&gt;Description and Portability&lt;/h3&gt;
&lt;p&gt;GVisor is a software widely used by the community, it is focused on integration with Docker and Kubernetes.
The code is written in GO, uses &lt;a href=&#34;https://github.com/bazelbuild/bazel&#34;&gt;Bazel&lt;/a&gt; to build the source code and generate the binary.
However, Bazel requires several build files, and supported architectures must be specified. However, the Gvisor only has reference to AMD (x86_64).&lt;/p&gt;
&lt;p&gt;As such, Bazel is unable to generate the binary for IBM Power (ppc64le). Therefore, Gvisor does not have support for the Power architecture, and portability is considered as difficult and necessary reverse engineering work in the source code.&lt;/p&gt;
&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The OpenPower Lab repository contains several Open-Source software for Power. See the list of &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;available packages&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;See more about the lab&amp;rsquo;s work and our research by reading other &lt;a href=&#34;https://openpower.ic.unicamp.br/#posts&#34;&gt;posts&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Installing Docker from the OpenPower Lab Repository</title>
      <link>https://openpower.ic.unicamp.br/post/installing-docker-from-repository/</link>
      <pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/installing-docker-from-repository/</guid>
      <description>&lt;p&gt;Docker is a set of systems that use virtualization to deliver software in packages, which are called containers. The containers are isolated from the operating system and other containers, they have unique libraries, as well as packages and configuration files. In addition, they can run different operating systems and have a lower resource cost than traditional virtualization.&lt;/p&gt;
&lt;p&gt;We provide the &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/docker/&#34;&gt;docker-ce&lt;/a&gt;, an edition of Docker that is free software, updated by the community. However, the package is officially not available for the Power architecture (ppc64 / ppc64le). Thus, the laboratory makes the latest versions available for installation from the package managers: Advanced Packaging Tool (APT) and Red Hat Package Manager (RPM).&lt;/p&gt;
&lt;h2 id=&#34;add-the-repository-and-install-docker&#34;&gt;Add the repository and install Docker&lt;/h2&gt;
&lt;p&gt;To add the repository to the system, and to always obtain the new versions of software that we provide, use the command for your package manager.&lt;/p&gt;
&lt;h3 id=&#34;add-apt-repository&#34;&gt;Add APT repository&lt;/h3&gt;
&lt;p&gt;To install, use the command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo echo &amp;#34;deb https://oplab9.parqtec.unicamp.br/pub/repository/debian/ ./&amp;#34; &amp;gt;&amp;gt; /etc/apt/sources.list; wget https://oplab9.parqtec.unicamp.br/pub/key/openpower-gpgkey-public.asc; sudo apt-key add openpower-gpgkey-public.asc; sudo apt -y update; sudo apt -y install docker-ce
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;add-rpm-repository&#34;&gt;Add RPM repository&lt;/h3&gt;
&lt;p&gt;To install, use the command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget https://oplab9.parqtec.unicamp.br/pub/repository/rpm/open-power-unicamp.repo; sudo mv open-power-unicamp.repo /etc/yum.repos.d/; sudo yum -y update; sudo yum -y install docker-ce
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;wget requirement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;To install using other means or other packages, see &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;Project Power Repository&lt;/a&gt; or &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-builds/&#34;&gt;Project Power Builds&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Measuring energy power consumption on POWER9 through IPMI sensors</title>
      <link>https://openpower.ic.unicamp.br/post/power-consumption-on-power/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/power-consumption-on-power/</guid>
      <description>&lt;p&gt;In this post, we will show how to get data on power consumption in a POWER9 bare-metal machine and how to plot this data using python.&lt;/p&gt;
&lt;p&gt;To measure the power consumption, a program called ipmitool will be used, once it give us the access to ipmi sensor data.&lt;/p&gt;
&lt;p&gt;In order to get a good span of values, a Image Classification script was used, which its code and execution procedure can be found here: &lt;a href=&#34;https://openpower.ic.unicamp.br/post/ai-profiling-for-power/&#34;&gt;https://openpower.ic.unicamp.br/post/ai-profiling-for-power/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;using-ipmitool-to-get-sensors-data&#34;&gt;Using ipmitool to get sensors data&lt;/h2&gt;
&lt;p&gt;In order to get a list of IPMI sensors, use the following command.&lt;/p&gt;
&lt;p&gt;Command: &lt;code&gt;sudo ipmitool sensor list&lt;/code&gt;
Output fields meaning with example:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Sensor ID&lt;/th&gt;
&lt;th&gt;Sensor Reading&lt;/th&gt;
&lt;th&gt;Sensor Reading Unit&lt;/th&gt;
&lt;th&gt;Status&lt;/th&gt;
&lt;th&gt;Lower Non-Recoverable&lt;/th&gt;
&lt;th&gt;Lower Critical&lt;/th&gt;
&lt;th&gt;Lower Non-Critical&lt;/th&gt;
&lt;th&gt;Upper Non-Critical&lt;/th&gt;
&lt;th&gt;Upper Critical&lt;/th&gt;
&lt;th&gt;Upper Non-Recoverable&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CPU1 Temp&lt;/td&gt;
&lt;td&gt;34.000&lt;/td&gt;
&lt;td&gt;degrees C&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;5.000&lt;/td&gt;
&lt;td&gt;5.000&lt;/td&gt;
&lt;td&gt;10.000&lt;/td&gt;
&lt;td&gt;88.000&lt;/td&gt;
&lt;td&gt;90.000&lt;/td&gt;
&lt;td&gt;92.000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To get a single sensor data, use the command:&lt;br&gt;
&lt;code&gt;ipmitool sensor get &amp;lt;Sensor ID&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Example:&lt;br&gt;
&lt;code&gt;sudo ipmitool sensor get CPU1\ Temp&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Locating sensor record...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Sensor ID              : CPU1 Temp &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0xb&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Entity ID             : 65.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Sensor Type &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Threshold&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;  : Temperature
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Sensor Reading        : &lt;span style=&#34;color:#ae81ff&#34;&gt;36&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;+/- 1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; degrees C
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Status                : ok
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Lower Non-Recoverable : 5.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Lower Critical        : 5.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Lower Non-Critical    : 10.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Upper Non-Critical    : 88.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Upper Critical        : 90.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Upper Non-Recoverable : 92.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Positive Hysteresis   : 2.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Negative Hysteresis   : 2.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Assertion Events      : 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Assertions Enabled    : ucr+ 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Deassertions Enabled  : ucr+
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The power measurement was collected by using the following python script, which not only calls ipmitool, but also parse the data into a csv file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; subprocess
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; csv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;duration &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;file_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sensors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;:]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;time_begin &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(file_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.csv&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; file_out:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    write &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; csv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;writer(file_out)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    first_row &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sensor_ID&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Entity_ID&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sensor_Type_Threshold_&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sensor_Reading&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Status&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Lower_Non_Recoverable&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Lower_Critical&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Lower_Non_Critical&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Upper_Non_Critical&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Upper_Critical&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Upper_Non_Recoverable&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Positive_Hysteresis&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Negative_Hysteresis&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Assertion_Events&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Assertions_Enabled&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Deassertions_Enabled&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Time_elapsed&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    write&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;writerow(first_row)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; float(duration)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; end &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sens &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sensors:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            command &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sudo&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ipmitool&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sensor&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;get&amp;#39;&lt;/span&gt;, sens]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            process &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; subprocess&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    command,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    stdout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;subprocess&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;PIPE,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    universal_newlines&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; process&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stdout
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            current_row &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            current_row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(sens)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(output)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                output[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output[i]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                output[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,len(output[i])):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    output[i][j] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output[i][j]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(output[i][j]) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        current_row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(output[i][j][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        current_row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            current_row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{:.5f}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; time_begin))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            write&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;writerow(current_row)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This was the python command used:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python3 sensorsIPMI&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;py &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt; pwr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv Total\ Power CPU1\ Power CPU2\ Power PCIE\ CPU1\ Pwr PCIE\ CPU2\ Pwr
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;plot-the-data&#34;&gt;Plot the data&lt;/h2&gt;
&lt;p&gt;In order to plot the data, a jupyter notebook was used.&lt;br&gt;
Which is available here:&lt;br&gt;
&lt;a href=&#34;https://colab.research.google.com/github/Unicamp-OpenPower/openpower/blob/master/content/post/power-consumption-on-power/pwrAnalysis.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The following graphs were ploted in the notebook:
All sensors:&lt;br&gt;
&lt;img src=&#34;all_sensors.png&#34; alt=&#34;All sensors&#34;&gt;
Total Power:&lt;br&gt;
&lt;img src=&#34;total.png&#34; alt=&#34;All sensors&#34;&gt;
CPU1 Power:&lt;br&gt;
&lt;img src=&#34;cpu1.png&#34; alt=&#34;All sensors&#34;&gt;
CPU2 Power:&lt;br&gt;
&lt;img src=&#34;cpu2.png&#34; alt=&#34;All sensors&#34;&gt;
PCIE CPU1 Power:&lt;br&gt;
&lt;img src=&#34;pcie_cpu1.png&#34; alt=&#34;All sensors&#34;&gt;
PCIE CPU2 Power:&lt;br&gt;
&lt;img src=&#34;pcie_cpu2.png&#34; alt=&#34;All sensors&#34;&gt;&lt;/p&gt;
&lt;p&gt;IPMI on OpenPOWER source:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/developerworks/library/l-openpower-firmware-ipmi/index.html&#34;&gt;https://www.ibm.com/developerworks/library/l-openpower-firmware-ipmi/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/9006-22C/p9eih/p9eih_ipmi_syshealth.htm&#34;&gt;https://www.ibm.com/support/knowledgecenter/9006-22C/p9eih/p9eih_ipmi_syshealth.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Although made for a different hardware vendor, a good source for ipmitool commands can be found on the following url:
&lt;a href=&#34;https://docs.oracle.com/cd/E19464-01/820-6850-11/IPMItool.html&#34;&gt;https://docs.oracle.com/cd/E19464-01/820-6850-11/IPMItool.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Profiling using Tensorboard-Profiler</title>
      <link>https://openpower.ic.unicamp.br/post/profiling-using-tensorboard-profiler/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/profiling-using-tensorboard-profiler/</guid>
      <description>&lt;p&gt;This blog post will show how to install tensorflow 2.2 in POWER, how to use profiler and make a comparison between different architectures ( x86, POWER 8 and 9).&lt;/p&gt;
&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;
&lt;p&gt;In this part I&amp;rsquo;ll show how to setup your Virtual Machine (VM) and install tensorflow 2.2 in POWER. My PIP version is 20.3 and my version of python is 3.8.&lt;/p&gt;
&lt;p&gt;First we need to install some libraries to install tensorflow 2.2.&lt;/p&gt;
&lt;p&gt;Installing dependecies of scipy:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sudo apt-get install libblas-dev liblapack-dev libatlas-base-dev gfortran
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Installing h5py:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sudo apt install python3-h5py  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Installing keras using pip:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install -U --user keras_applications --no-deps
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install -U --user keras_preprocessing --no-deps
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we are able to install tensorflow 2.2. For this, access the site (&lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;) to download .whl file (this file is used to install tensorflow using pip comand). First go in Community Supported Builds Section, and click in Artifacts release 2.x of Linux ppc64le CPU Stable Release.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;gitTensorflow.png&#34; alt=&#34;Tensorflow installation&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 1: Tensorflow 2.2 cpu- only installation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After clicking we are directed to jenkins, where we click in tensorflow_cpu-2.2.0-cp38-cp38-linux_ppc64le.whl. Note that &amp;ldquo;cp38&amp;rdquo; indicates that the tensorflow should be installed in python 3.8. However, if you are using different versions of python you can download the version corresponding to your python version. But in this tutorial I&amp;rsquo;ll show how to setup using python 3.8.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Tensorflowbuild.png&#34; alt=&#34;Tensorflow installationpt2&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 2: Download .whl tensorflow 2.2 build.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For download in VM, copy the link (tensorflow_cpu-2.2.0-cp38-cp38-linux_ppc64le.whl) and use the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    wget https://powerci.osuosl.org/job/TensorFlow2_PPC64LE_CPU_Release_Build/lastSuccessfulBuild/artifact/tensorflow_pkg/tensorflow_cpu-2.2.0-cp38-cp38-linux_ppc64le.whl  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now for installation of the tensorflow using pip command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install tensorflow_cpu-2.2.0-cp38-cp38-linux_ppc64le.whl  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more information you can visit &lt;a href=&#34;https://www.tensorflow.org/install/source&#34;&gt;https://www.tensorflow.org/install/source&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now we need to install tensorboard, tensorboard-plugin-profiler and tensorflow-datasets.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install --upgrade tensorboard
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install tensorflow-datasets
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install -U tensorboard_plugin_profile
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;get-access-to-power-8-vm-in-minicloud&#34;&gt;Get access to POWER 8 VM in minicloud&lt;/h2&gt;
&lt;p&gt;Here is a brief tutorial on how to access POWER 8 virtual machine in minicloud, first access &lt;a href=&#34;https://openpower.ic.unicamp.br/minicloud/&#34;&gt;https://openpower.ic.unicamp.br/minicloud/&lt;/a&gt; and click in &lt;strong&gt;Request Access&lt;/strong&gt;  and answer the google forms to get access. Here is a link that may help you to get access to an instance on minicloud &lt;a href=&#34;https://github.com/Unicamp-OpenPower/minicloud/wiki&#34;&gt;https://github.com/Unicamp-OpenPower/minicloud/wiki&lt;/a&gt;. In the next section I&amp;rsquo;ll show to access tensorboard by terminal.&lt;/p&gt;
&lt;h2 id=&#34;ssh-connection&#34;&gt;SSH connection&lt;/h2&gt;
&lt;p&gt;You&amp;rsquo;ll need to connect to VM via ssh using the &lt;code&gt;-L 6006:localhost:6006&lt;/code&gt; flag. To be able to use tensorboard in the terminal, your command should be like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh ubuntu@minicloud.parqtec.unicamp.br -i ~/.ssh/your-key.pem -p &amp;lt;vm-port&amp;gt; -L 6006:localhost:6006&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For using tensorboard in the terminal we use this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tensorboard --logdir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;lt;name_of_log_directory&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we are able to open the link in your favorite browser.&lt;/p&gt;
&lt;h2 id=&#34;compare-tensorboard-profiler-in-different-architectures&#34;&gt;Compare Tensorboard-Profiler in different architectures&lt;/h2&gt;
&lt;p&gt;In this section, we will be profiling using Tensorboard-Profiler in different architectures and showing the results. First, we will standardize the test file. For this, download the file available in &lt;a href=&#34;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&#34;&gt;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&lt;/a&gt; and modify the line:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;model.fit(ds_train,
          epochs=2,
          validation_data=ds_test,
          callbacks = [tboard_callback])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;to:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;model.fit(ds_train,
          epochs=5,
          validation_data=ds_test,
          callbacks = [tboard_callback])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now we are ready to execute the script and debug performance bottlenecks using Tensorboard-Profiler.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes when running Tensorflow we get some errors like: AttributeError: partially initialized module &amp;rsquo;tensorflow&amp;rsquo; has no attribute &amp;lsquo;&lt;strong&gt;version&lt;/strong&gt;&amp;rsquo; (most likely due to a circular import). To fix this error you can use the flag -m.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    python3 -m &amp;lt;your-python-file&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After running the script in different architectures we obtain the following results:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Input pipeline analyzer:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data preprocessing (ms)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Table 1: Data preprocessing in different architectures&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;X86&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;POWER8&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;POWER9&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;390&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;180&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;164&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Reading data from files in advance (including caching, prefetching, interleaving) (in ms):&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Table 2: Reading data from files in advance in different architectures&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;X86&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;POWER8&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;POWER9&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;6.7&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;~ 0&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;~0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Tensorflow stats:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Operations which consume more time:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Table 3: Operations which consume more time in x86&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Operation&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Occurrences&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;total time (us)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;112,868&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch::ParallelMap&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.907&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;106,162&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch::ParallelMap::ParallelMap&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.907&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;104,103&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Decode Png&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;decode_image/cond_jpeg/else/_1/cond_png/then/_0/DecodePng&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.910&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;79,162&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table 4: Operations which consume more time in POWER8&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Operation&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Occurrences&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;total time (us)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;131,659&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch::ParallelMap&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.673&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;23,513&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MatMul&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;gradient_tape/sequential/dense/MatMul&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;16,335&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.673&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;15,375&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table 5: Operations which consume more time in POWER9&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Operation&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Occurrences&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;total time (us)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;114,562&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;_FusedMatMul&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;sequential/dense/Relu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;30,306&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch::ParallelMap&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.676&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;20,957&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.675&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;16,722&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now we can analyze the dada and compare beteween different architectures. First we note that x86 consumes more time for data preprocessing and reading data from files in advance (Tables 1 and 2). In Tensorflow stats we can crack the entire code in operations but I&amp;rsquo;ll show only the top 4 time-consuming operations in tables 3, 4 and 5. However, you can get all operations in tensorboard-profiler in section Tensorflow Stats.
From tables 3, 4 and 5 we obtain that the type of operation differs a little, for example in table 3 we have Decode Png in top 4, whereas in power architectures (Tables 4 and 5) we have matmul. But in all 3 architectures Dataset is highly time-consuming.&lt;/p&gt;
&lt;p&gt;An interesting function in tensorboard-profiler is &lt;strong&gt;Recommendation for Next Step&lt;/strong&gt;. This function highlights some otimizations that could improve your program, for exemple, when I execute my program in POWER 8 we have some recommendations like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your program is HIGHLY input-bound because 68.8% of the total step time sampled is waiting for input. Therefore, you should first focus on reducing the input time&lt;/li&gt;
&lt;li&gt;7.3 % of the total step time sampled is spent on All Others time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next tools to use for reducing the input time&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;input_pipeline_analyzer (especially Section 3 for the breakdown of input operations on the Host)&lt;/li&gt;
&lt;li&gt;trace_viewer (look at the activities on the timeline of each Host Thread near the bottom of the trace view)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AI Profiling for POWER</title>
      <link>https://openpower.ic.unicamp.br/post/ai-profiling-for-power/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/ai-profiling-for-power/</guid>
      <description>&lt;p&gt;Although there is plenty information on AI profiling for x86_64 and ARM architectures, there is almost none on POWER.&lt;/p&gt;
&lt;p&gt;With that motivation in mind, this post aim to share some results on this subject.&lt;/p&gt;
&lt;p&gt;The program profiled was a python script that had a pre-trained ResNet50 with ImageNet weights, which was obtained from TensorFlow API.&lt;br&gt;
It aimed to classify 500 hot-dogs images downloaded from the ImageNet.&lt;br&gt;
The profiling was done using Perf for collecting PMU data and ipmitool for energy consumption data.&lt;/p&gt;
&lt;p&gt;Requirements for the pyhton script:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bare-metal machine&lt;/li&gt;
&lt;li&gt;ipmitool&lt;/li&gt;
&lt;li&gt;python 3.6&lt;/li&gt;
&lt;li&gt;TensorFlow 2.1.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Machine Stats:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;POWER9 Processor&lt;/li&gt;
&lt;li&gt;CPU(s): 128&lt;/li&gt;
&lt;li&gt;On-line CPU(s) list: 0-127&lt;/li&gt;
&lt;li&gt;Thread(s) per core: 4&lt;/li&gt;
&lt;li&gt;Core(s) per socket: 16&lt;/li&gt;
&lt;li&gt;Socket(s): 2&lt;/li&gt;
&lt;li&gt;NUMA node(s): 2&lt;/li&gt;
&lt;li&gt;Model: 2.2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find information on how to install TensorFlow on POWER in this post: &lt;a href=&#34;https://openpower.ic.unicamp.br/post/building-tensorflow-on-power/&#34;&gt;https://openpower.ic.unicamp.br/post/building-tensorflow-on-power/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Eleven tests were executed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications.resnet50 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ResNet50
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; image
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications.resnet50 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input, decode_predictions
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datetime &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datetime
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;begin &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#folder = sys.argv[1]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;length &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;731&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;length &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (length &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;731&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Using maximum length: 731&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lenght &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;731&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;again &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;folder_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hot_dog&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ResNet50(weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;images &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(length):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    img_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; folder_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(i) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_img(img_path, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    images&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;img_to_array(img))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    images[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(images[i], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    images[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; preprocess_input(images[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(again):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(length):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(images[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;#print(decode_predictions(prediction[i], top=1)[0][0][1])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        strPrediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; decode_predictions(prediction, top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (strPrediction &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hotdog&amp;#39;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            count &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;#print(str(i) + &amp;#34; -&amp;gt; &amp;#34; + strPrediction)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Begin: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utcnow()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%H:%M:%S&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;End: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utcnow()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%H:%M:%S&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RIGHTS: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(count))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;WRONGS: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(again&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;length &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; count))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ACC: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(count&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(again&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;length)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Time Elapsed: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;s&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; begin))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Because the model is pre-trained, it obtained the same classification accuracy for every test.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;RIGHTS: 433
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;WRONGS: 67
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;profiling-using-perf&#34;&gt;Profiling using perf.&lt;/h3&gt;
&lt;p&gt;Perf is a profiling program included with the Linux kernel. Here it was used to instrument CPU performance counters.&lt;/p&gt;
&lt;p&gt;PMUs used:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;branches,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;branch-misses,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-misses,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-references,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cycles,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;instructions,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;idle-cycles-backend,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;idle-cycles-frontend.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following graphs shows the data fetched from those PMUs.&lt;br&gt;
Graphs:&lt;br&gt;
CPU Cycles:&lt;br&gt;
&lt;img src=&#34;cycles.png&#34; alt=&#34;CPU Cycles&#34;&gt;
Instructions:&lt;br&gt;
&lt;img src=&#34;instructions.png&#34; alt=&#34;Instructions&#34;&gt;
Cache-references:&lt;br&gt;
&lt;img src=&#34;cache-references.png&#34; alt=&#34;Cache-references&#34;&gt;
Cache-misses:&lt;br&gt;
&lt;img src=&#34;cache-misses.png&#34; alt=&#34;Cache-misses&#34;&gt;
Branches:&lt;br&gt;
&lt;img src=&#34;branches.png&#34; alt=&#34;Branches&#34;&gt;
Branch-misses:&lt;br&gt;
&lt;img src=&#34;branch-misses.png&#34; alt=&#34;Branch-misses&#34;&gt;
Time Elapsed:&lt;br&gt;
&lt;img src=&#34;time-elapsed.png&#34; alt=&#34;Time Elapsed&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;energy-consumption&#34;&gt;Energy consumption.&lt;/h3&gt;
&lt;p&gt;Make sure you are running on a bare-metal machine.&lt;/p&gt;
&lt;p&gt;How to use the ipmitool to get power consumption data:
Install ipmitool through:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get install ipmitool
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then run the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo ipmitool dcmi power reading
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Which is going to give you the output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Instantaneous power reading:                   262 Watts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Minimum during sampling period:                248 Watts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Maximum during sampling period:                263 Watts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Average power reading over sample period:      257 Watts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    IPMI timestamp:                           Sun Nov  8 19:51:18 2020
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Sampling period:                          00000005 Seconds.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Power reading state is:                   activated
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This command was executed continuosly for 1500 seconds using a python script that would parse the results into a csv file.&lt;/p&gt;
&lt;p&gt;Altough the sampling period was used for reference in order to plot the following graph, it does not represent an accurate time series in the x axis.
For a better undertanding of power consumption profiling on POWER with ML algorithms, see the following post: &lt;a href=&#34;https://openpower.ic.unicamp.br/post/power-consumption-on-power/&#34;&gt;https://openpower.ic.unicamp.br/post/power-consumption-on-power/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;That said, the data was used to plot the following graph:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;powerConsumption.png&#34; alt=&#34;Energy Consumption&#34;&gt;&lt;/p&gt;
&lt;p&gt;It is possible to see the average of energy consumption for each test and, at the end, the energy consumption going back to a normal state.
It can also be observed that there is an increase close to 100W when a test begins to run.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello Minikube for ppc64le</title>
      <link>https://openpower.ic.unicamp.br/post/hello-minikube/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/hello-minikube/</guid>
      <description>&lt;p&gt;This tutorial shows you how to create a cluster for the Power architecture (ppc64le) using Minikube.&lt;/p&gt;
&lt;p&gt;The tutorial was performed on Ubuntu 20.10 (ppc64le), the packages were downloaded using the package repository from &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;OpenPower Lab @ Unicamp&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;dependencies&#34;&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;The following packages are required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Minikube&lt;/li&gt;
&lt;li&gt;Kubectl&lt;/li&gt;
&lt;li&gt;Docker-ce&lt;/li&gt;
&lt;li&gt;Conntrack&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can use the commands below to solve the dependencies:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install docker-ce conntrack minikube kubectl
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Optionally, Kubeadm and Kubelet can be installed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;create-a-minikube-cluster&#34;&gt;Create a minikube cluster&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Start Minikube&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo minikube start --driver&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;none
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;The default drive is Docker, however the minikube does not recognize that Docker is available for ppc64le architecture and has an error.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To make &amp;rsquo;none&amp;rsquo; the default drive, use the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo minikube config set driver none
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;You may need to run the command:: &lt;code&gt;sudo sysctl fs.protected_regular=0&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Check Status&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo minikube status
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output is similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minikube
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;type: Control Plane
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;host: Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubelet: Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiserver: Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubeconfig: Configured
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Open the Kubernetes dashboard in a browser&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo minikube dashboard
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-a-deployment&#34;&gt;Create a Deployment&lt;/h2&gt;
&lt;p&gt;There are two structures in Kubernetes: Pod and Deployment. Pod can be a group of one or more Containers, while a Deployment checks, manages and restarts the pods. That is, the deployment is recommended when it will be used in a large group of pods.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a Deployment&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl create deployment hello-node --image&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;minicloud/node-server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://hub.docker.com/r/minicloud/node-server&#34;&gt;minicloud/node-server&lt;/a&gt;&lt;/em&gt;: is a public docker image created for the ppc64le architecture. The files used to build the image are in the &lt;a href=&#34;https://github.com/Unicamp-OpenPower/nodeServer&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;View the Deployment:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl get deployments
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output is similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME         READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-node   1/1     &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;            &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;           6m28s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;View the Pod:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl get pods
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output is similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                          READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-node-5dd47b76c8-l5vs2   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          6m51s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-a-service&#34;&gt;Create a Service&lt;/h2&gt;
&lt;p&gt;In order to be able to directly access the Pod, it is necessary to create a service.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a Service&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl expose deployment hello-node --type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;NodePort --port&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;View the Service&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl get services
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output is similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;          AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-node   NodePort    10.102.223.224   &amp;lt;none&amp;gt;        8080:31253/TCP   8s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubernetes   ClusterIP   10.96.0.1        &amp;lt;none&amp;gt;        443/TCP          14m
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Open the service in the browser: &lt;a href=&#34;http://localhost:8080/&#34;&gt;http://localhost:8080/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;hello-minikube.png&#34; alt=&#34;Hello Minikube in browser&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If it is not possible to access this port, change the 8080, for the 5 digit port that appears in the view. In that case it would be port 31253.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;clean-up&#34;&gt;Clean up&lt;/h2&gt;
&lt;p&gt;Now you can clean up the resources you created in your cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete service hello-node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete deployment hello-node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Optionally, stop the Minikube:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minikube stop
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Optionally, delete the Minikube:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minikube delete
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;tutorial-for-others-architectures&#34;&gt;Tutorial for others architectures&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/tutorials/hello-minikube/&#34;&gt;Hello Minikube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Installing Bazel and other packages from the OpenPower Lab Repository</title>
      <link>https://openpower.ic.unicamp.br/post/installing-bazel-from-repository/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/installing-bazel-from-repository/</guid>
      <description>&lt;p&gt;Bazel is a free software tool that allows for the automation of building and testing of software. Similar to build tools like Make, Maven, and Gradle, Bazel builds software applications from source code using a set of rules.&lt;/p&gt;
&lt;p&gt;It is not officially supported by the Power architecture, because of that, we provide the binary and the possibility to use the package through the Advanced Packaging Tool (APT), and Red Hat Package Manager (RPM).&lt;/p&gt;
&lt;p&gt;In order for installation via APT or YUM, the user must add our repository to his system. To do this, just do the following steps.&lt;/p&gt;
&lt;h2 id=&#34;add-the-repository-and-install-bazel&#34;&gt;Add the repository and install Bazel&lt;/h2&gt;
&lt;p&gt;To add the repository to the system, and to always obtain the new versions of software that we provide, follow these steps.&lt;/p&gt;
&lt;h3 id=&#34;add-apt-repository&#34;&gt;Add APT repository&lt;/h3&gt;
&lt;p&gt;Edit the file: &lt;em&gt;/etc/apt/sources.list&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Insert the line at the end of the file:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;deb https://oplab9.parqtec.unicamp.br/pub/repository/debian/ ./&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Download our &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/key/openpower-gpgkey-public.asc&#34;&gt;GPG key&lt;/a&gt;, and use the command below to add it to the system:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt-key add openpower-gpgkey-public.asc&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After that, update the system using the command below:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt update&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;install-bazel&#34;&gt;Install Bazel&lt;/h3&gt;
&lt;p&gt;To install, use the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt install bazel&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;add-rpm-repository&#34;&gt;Add RPM repository&lt;/h3&gt;
&lt;p&gt;Create and edit the file: &lt;em&gt;/etc/yum.repos.d/open-power.repo&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Add the text to it:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[Open-Power]
name=Unicamp OpenPower Lab - $basearch
baseurl=https://oplab9.parqtec.unicamp.br/pub/repository/rpm/
enabled=1
gpgcheck=0
repo_gpgcheck=1
gpgkey=https://oplab9.parqtec.unicamp.br/pub/key/openpower-gpgkey-public.asc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that, performs the following command with super-user capabilities to update the system.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yum update&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To be a super user, use the command: &lt;code&gt;sudo su&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;install-bazel-1&#34;&gt;Install Bazel&lt;/h3&gt;
&lt;p&gt;To install, it use the command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yum install bazel&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To install using other means, see &lt;a href=&#34;https://openpower.ic.unicamp.br/post/installing-bazel-power-other-architectures-systems/&#34;&gt;Installing Bazel on Power and Other Unsupported Architectures/Systems&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Creating and adding a Linux repository</title>
      <link>https://openpower.ic.unicamp.br/post/how-create-repository/</link>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/how-create-repository/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The OpenPower@Unicamp laboratory performs &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-builds/&#34;&gt;CI/CD&lt;/a&gt; activity for several open-source programs that are not available for the Power architecture. Besides, we make the binaries generated from these programs available on our &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/&#34;&gt;FTP&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To add our repositories to the system, jump to &lt;a href=&#34;#step-5---adding-the-repository-to-the-system&#34;&gt;step 5&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;problem&#34;&gt;Problem&lt;/h2&gt;
&lt;p&gt;Many of the programs we make available have frequent updates and can generate several versions within a month. Based on this, several users needed to constantly access FTP to keep their programs up to date.&lt;/p&gt;
&lt;p&gt;As a result, we decided to create two repositories. A repository for distros which use the Advanced Packaging Tool (APT), and another for distros that use the Red Hat Package Manager (RPM).&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps&lt;/h2&gt;
&lt;h3 id=&#34;step-1---prerequisites&#34;&gt;Step 1 - Prerequisites&lt;/h3&gt;
&lt;p&gt;To create a repository, we first need the programs to be hosted on a place with a public IP and that can be accessed by the browser from anywhere in the world.&lt;/p&gt;
&lt;p&gt;For us, this was a simple matter, our FTP has these characteristics.&lt;/p&gt;
&lt;h3 id=&#34;step-2---create-directory&#34;&gt;Step 2 - Create directory&lt;/h3&gt;
&lt;p&gt;This information must be accessible to the general public through the browser, so it is necessary to establish where this information will be in the system.&lt;/p&gt;
&lt;p&gt;FTP is a specific path of the server system. Currently, the path /pub/ppc64el is used to store programs binaries. Then we create the path /pub/repository/debian/ to store the APT repository information, and /pub/repository/rpm/ to store the RPM repository information.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The steps to create an FTP or make a server system path accessible by browsers will not be covered in this guide.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step-3---add-programs&#34;&gt;Step 3 - Add programs&lt;/h3&gt;
&lt;p&gt;As we are developing binaries and programs for a specific architecture, we create a folder with the architecture name. For APT, it is &lt;em&gt;ppc64el&lt;/em&gt;, and for RPM, &lt;em&gt;ppc64le&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The next step is to add all the programs into the folder with architecture name. As each of our programs has several versions, we created a folder with the name of the program, and all of its versions are inside it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To create a program in APT format, you can see &lt;a href=&#34;https://terminalroot.com.br/2014/12/como-criar-pacotes-deb.html&#34;&gt;this tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;To create a program in RPM format, you can see &lt;a href=&#34;https://opensource.com/article/18/9/how-build-rpm-packages&#34;&gt;this tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;step-4---create-compatible-file-systems&#34;&gt;Step 4 - Create compatible file systems&lt;/h3&gt;
&lt;p&gt;For the file system to recognize the repository, it is necessary to create some files. These files contain information about the program and their path within the directory. Besides that, they can be signed with a GPG key, which serves to prove the authenticity of the programs present in the repository.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To create a gpg key, you can see &lt;a href=&#34;https://www.redhat.com/sysadmin/creating-gpg-keypairs&#34;&gt;this tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;generate-essential-apt-files&#34;&gt;Generate essential APT files&lt;/h4&gt;
&lt;p&gt;To create the files, run the following commands inside the folder that will be the path to your directory. In our case in /pub/repository/debian/&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dpkg-scanpackages -m . &amp;gt;&amp;gt; Packages
gzip -c Packages &amp;gt;&amp;gt; Packages.gz
apt-ftparchive release . &amp;gt; Release
keyname=name-your-gpgkey
rm -fr Release.gpg; gpg --default-key ${keyname} -abs -o Release.gpg Release
rm -fr InRelease; gpg --default-key ${keyname} --clearsign -o InRelease Release
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;generate-essential-rpm-files&#34;&gt;Generate essential RPM files&lt;/h4&gt;
&lt;p&gt;To create the files, run the following commands inside the folder that will be the path to your directory. In our case in /pub/repository/rpm/&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;createrepo --database /pub/repository/rpm/
gpg --detach-sign --armor repodata/repomd.xml
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;step-5---add-the-repository-to-the-system&#34;&gt;Step 5 - Add the repository to the system&lt;/h3&gt;
&lt;p&gt;To add the repository to the system, and always stay updated on the new versions of the software we make available, follow the next steps.&lt;/p&gt;
&lt;h4 id=&#34;add-apt-repository&#34;&gt;Add APT repository&lt;/h4&gt;
&lt;p&gt;Edit the file: &lt;em&gt;/etc/apt/sources.list&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Insert the line at the end of the file:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;deb https://oplab9.parqtec.unicamp.br/pub/repository/debian/ ./&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Download our &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/key/openpower-gpgkey-public.asc&#34;&gt;GPG key&lt;/a&gt;, and use the command below to add it to the system:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;apt-key add openpower-gpgkey-public.asc&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Lastly, update the system and install any of the program we provide.&lt;/p&gt;
&lt;h4 id=&#34;add-rpm-repository&#34;&gt;Add RPM repository&lt;/h4&gt;
&lt;p&gt;Create and edit the file: &lt;em&gt;/etc/yum.repos.d/open-power.repo&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Add the text to it:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[Open-Power]
name=Unicamp OpenPower Lab - $basearch
baseurl=https://oplab9.parqtec.unicamp.br/pub/repository/rpm/
enabled=1
gpgcheck=0
repo_gpgcheck=1
gpgkey=https://oplab9.parqtec.unicamp.br/pub/key/openpower-gpgkey-public.asc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Lastly, update the system and install any of the program we provide.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Inline Assembly with PowerPC</title>
      <link>https://openpower.ic.unicamp.br/post/inline-asm-intro/</link>
      <pubDate>Tue, 14 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/inline-asm-intro/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Usually, we let the compiler handle all the “C to Assembly” conversion, but there are certain losses in this automated process: poorly utilized special registers, unnecessary branching and memory accesses, among other issues. These details are insignificant when there are few occurrences during a program’s runtime, however, some sections of code can be executed over a billion times, and, if these sections ignore these details, it can amount to a significant performance overhead.
The inline assembly tool in C aims to avert some of these problems by delegating part of the assembling job to the programmer. The tool consists of a special function which receives a raw assembly code section written by the programmer, as well as some register constraints and qualifiers. This tool is mostly used in two scenarios: code optimization and OS/hardware services.&lt;/p&gt;
&lt;h2 id=&#34;inline-assembly-basics&#34;&gt;Inline Assembly Basics:&lt;/h2&gt;
&lt;h3 id=&#34;syntax&#34;&gt;Syntax:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;asm [asm-qualifiers] ( 
        AssemblerTemplate 
        [  : OutputOperands 
        [ : InputOperands
        [ : Clobbers ] ] ]
    );
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Keyword “asm”:&lt;/strong&gt; The inline assembly function is called as asm(). There are &lt;a href=&#34;https://gcc.gnu.org/onlinedocs/gcc/Alternate-Keywords.html#Alternate-Keywords&#34;&gt;alternative keywords&lt;/a&gt; for “asm” since some compiler options might not recognize it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qualifiers:&lt;/strong&gt; These communicate to the compiler certain behaviors. They tend to be used when the compiler must be informed of something that occurs within the asm code for the program to function properly. The volatile qualifier, for instance, forces the compiler to not remove the asm section during the optimization stage, even if the section produces no outputs (which is quite common when interacting with OS/hardware services).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assembler Template:&lt;/strong&gt; This is the actual assembly code and the only mandatory parameter. Here we can pass one or more strings which will be concatenated and printed into the assembly file (file.s). Due to the concatenation, all instructions must be terminated with “\n” or “;”. The most common termination used is “\n\t” as it ensures the instructions are in separate lines and properly formatted with tabs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Output and Input Operands:&lt;/strong&gt; Both consist of a list with all the C variables which should be passed to the assembly code. The main difference is that input operands are not meant to be “written to” only “read from”, because the compiler considers that these values will not be altered during the assembly execution. Output operands, on the other hand, are expected to be modified, if they’re not, the compiler may exclude the asm call entirely as it can consider an asm call with no return value useless.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Clobbers List:&lt;/strong&gt; It is a register list which may have it’s registers altered. Every register in the list will be avoided by the compiler when assigning registers for input/output operands. Useful when instructions implicitly change registers (compare instructions for instance). &lt;a href=&#34;https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html#Clobbers-and-Scratch-Registers&#34;&gt;More about Clobbers here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;operands-formats&#34;&gt;Operands Formats:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Output: [ [asmSymbolicName] ] constraint (C_variable_name)
Input:  [ [asmSymbolicName] ] constraint (C_expression)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Symbolic Names:&lt;/strong&gt; Every input/output has a symbolic name by default which is defined by the operands index: the first element (indexed by 0) is the leftmost output operand, the last, is the rightmost input operand. The N-th operand can then be referenced with &lt;code&gt;%N&lt;/code&gt;, where N is it’s index. A custom symbolic name can be defined in the operands list and reference by using &lt;code&gt;%[asmSymbolicName]&lt;/code&gt; within the template.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Constraints:&lt;/strong&gt; Every input/output operand must have a constraint which, as the name implies, constrains the contents and location of an operand as well as it’s access. Since the idea is to leave the least amount of work possible for the compiler, using them can be helpful. Constraints can be generic or machine specific, &lt;a href=&#34;https://gcc.gnu.org/onlinedocs/gccint/Constraints.html&#34;&gt;there’s a whole list of these&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;naming_operands.PNG&#34; alt=&#34;Input and Output Operands naming conventions.&#34;&gt;
&lt;em&gt;Figure 1 - Input and Output Operands naming conventions.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/em&gt; &lt;em&gt;You can check out some PowerPC asm examples &lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/SSGH3R_16.1.0/com.ibm.xlcpp161.aix.doc/language_ref/asm_example.html#asm_example__Example5TheFollowingExampleShowsTh-027B19F3&#34;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;max-element-with-inline-assembly&#34;&gt;Max Element With Inline Assembly&lt;/h2&gt;
&lt;p&gt;As for a practical example, let’s create an &lt;em&gt;asm&lt;/em&gt; call that finds the maximum value within an integer array.&lt;/p&gt;
&lt;h3 id=&#34;the-code&#34;&gt;The Code:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;int asm_max (int vec[], int size) {
    int max=0;

    __asm__(
    &amp;quot;mtctr %[size]\n\t&amp;quot;           // Load value to SPR Counter Register
    &amp;quot;subi  %[vec], %[vec], 4\n\t&amp;quot; // Load first element and update
    &amp;quot;loop:\n\t&amp;quot;
    &amp;quot;lu 4, 4(%[vec])\n\t&amp;quot;         // Load Word and Zeros with update
    &amp;quot;cmpd 4, %[max]\n\t&amp;quot;          // Compare 
    &amp;quot;blt skip\n\t&amp;quot;                // skips update if less than
    &amp;quot;addi %[max], 4, 0\n\t&amp;quot;       // Updates maximum
    &amp;quot;skip:\n\t&amp;quot;
    &amp;quot;bdnz loop\n\t&amp;quot;           // Branch and Decrement CTR if CTR Not Zero
    : [max]&amp;quot;+r&amp;quot;(max), [vec]&amp;quot;+r&amp;quot;(vec)
    : [size]&amp;quot;r&amp;quot;(size)
    : &amp;quot;ctr&amp;quot;, &amp;quot;cr0&amp;quot;, &amp;quot;r4&amp;quot;
    );

    return max;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;asm_max&lt;/em&gt; function is a wrapper which receives two parameters: an integer array (&lt;em&gt;vec&lt;/em&gt;), and it’s &lt;em&gt;size&lt;/em&gt;. The asm will be responsible for returning the maximum value within &lt;em&gt;vec&lt;/em&gt; and assigning it to the return variable &lt;em&gt;max&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/em&gt; &lt;em&gt;Isolating the asm call within another function can be helpful to prevent registers from being unintentionally overwritten. Ideally, this should be avoided, as the function call creates an overhead affecting overall performance. The correct use of the operands list should suffice.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;special-registsers-overview&#34;&gt;Special Registsers Overview:&lt;/h3&gt;
&lt;p&gt;Before we start dissecting the code, let’s take a look at two special purpose registers used (CTR and CR) as well as some specific instructions (mtctr, cmpd, blt and bdnz).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Special Purpose Registers:&lt;/strong&gt; The Condition Register (CR) holds the results of comparisons. It consists of 8 bitfields (blocks of 4 bits) that can be individually accessed through indexes, also, it can be implicitly altered when the cmp instruction is called. The Counter Register (CTR) is mainly used for loops. Besides being an integer counter, it has special instructions to facilitate assertions (CTR==0? or CTR!=0?) and incrementation/decrementation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;cr_bitfield.PNG&#34; alt=&#34;CR&amp;amp;rsquo;s bitfield diagram&#34;&gt;
&lt;em&gt;Figure 2 - Condition register bitfields diagram&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;More About Comparisons:&lt;/strong&gt; The compare instruction is actually a subtraction that identifies if the result is negative, zero or positive. For example, if we have “cmpd A, B”, the operation realized is “A-B”. If the result is negative, the bit 0 of bitfield X is set. if 0, the bit 1of bitfield X is set. If positive, bit 3 is set. So, if we want to branch when ”A&amp;lt;B” we can use blt (checks if bit 0 from &lt;em&gt;bitfield&lt;/em&gt; 0 is set). Note that the order of the registers A and B is paramount.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mnemonics:&lt;/strong&gt; Many instructions depend on certain unintuitive parameters to behave as we want them to. The cmp instruction (cmp BF, L, RA, RB), for example, needs parameters to define if it will compare 32 (L=0) or 64 (L=1) bits, and in which bitfield the result of this comparison will be kept (BF=[0-7]). The goal of mnemonics is to facilitate the use of assembly instructions (or sometimes just to shorten them) by adding intuitive synonyms to the instruction set.
Example: Let’s suppose we want to compare RA and RB, both with doublewords (64 bits), and save the result in the bitfield 0 of the CR register.  The standard instruction to do so would be “cmp 0, 1, RA, RB”, where 0 indicates the bitfield and 1 the fact that we are comparing doublewords. Alternatively, we can use the mnemonic (or synonym) “cmpd RA, RB”, which stands for Compare Doubleword. Note that there’s no bitfield defined in the latter, this is because it implicitly uses the bitfield 0.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/em&gt; &lt;em&gt;Defaulting to the bitfield 0 or 1 is actually quite common among mnemonics, because we usually only work with one comparison at a time. The bitfield 0 is implicit if it’s an integer comparison, if it’s a floating point comparison, bitfield 1 is implicit.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;summing-it-up&#34;&gt;Summing it up:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;cmpd&lt;/strong&gt; - Compare Doubleword (and implicitly set result to CR’s bitfield 0)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mtctr&lt;/strong&gt; - Move to counter register (equivalent to mtspr 9, Rx)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;blt&lt;/strong&gt; - Branch if Less Than in bitfield 0 (equivalent to bc 12, 0, Label)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bdnz&lt;/strong&gt; - Branch and Decrement if Not Zero (equivalent to bc 16, 0, Label)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;lu&lt;/strong&gt; - Load Word and Update (equivalent to lwzu)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-asm-operands-list&#34;&gt;The ASM Operands List:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;: [max]&amp;quot;+r&amp;quot;(max), [vec]&amp;quot;+r&amp;quot;(vec)
: [size]&amp;quot;r&amp;quot;(size)
: &amp;quot;ctr&amp;quot;, &amp;quot;cr0&amp;quot;, &amp;quot;r4&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s uderstand what&amp;rsquo;s happening here. We have max and vec as outputs* constrained by “+r” which mark them as read and write (+) and maps them to general purpose registers (r). As for input operands, we have the variable size as read only (it’s the default for input operands) and mapped to a general purpose register as well (r).
When defining clobbers, we set the two SPRS discussed previously (CTR and CR) as these are altered during the code’s execution. In particular, CR has the index “0” appended to it, indicating that only the bitfield 0 will be used. The R4 register is also added to the list since it is used as an auxiliary variable in the code and should be avoided by the compiler.&lt;/p&gt;
&lt;p&gt;*&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/em&gt; &lt;em&gt;In this case, vec is technically not an output, as it shouldn’t be altered. But, since it’s a copy made by the wrapper function, we do not need to worry about modifying its contents and will use it as an index for iterating through the array.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-asm-code&#34;&gt;The ASM Code:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;1   &amp;quot;mtctr %[size]\n\t&amp;quot;           // Load value to SPR Counter Register
2   &amp;quot;subi  %[vec], %[vec], 4\n\t&amp;quot; // Load first element and update
3   &amp;quot;loop:\n\t&amp;quot;
4   &amp;quot;lu 4, 4(%[vec])\n\t&amp;quot;         // Load Word and Zeros with update
5   &amp;quot;cmpd 4, %[max]\n\t&amp;quot;          // Compare 
6   &amp;quot;blt skip\n\t&amp;quot;                // skips update if less than
7   &amp;quot;addi %[max], 4, 0\n\t&amp;quot;       // Updates maximum
8   &amp;quot;skip:\n\t&amp;quot;
9   &amp;quot;bdnz loop\n\t&amp;quot;            // Branch and Decrement CTR if CTR Not Zero
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, let’s understand the code. In the very first line, we set the value of the CTR as the size of the vector, which will make it easier to iterate through the vector. The second line is a bit confusing: since the lu instruction first increments the given address and then access it, we decrement the base address of the array in order to make sure it will start from the first element and not the second (kinda like starting at position -1 and always incrementing before reading). Alternatively we could load the first element in the max variable and exclude the second line, but if so, the code would have to be adjusted to work with arrays of a single element, and the CTR might need to be treated differently depending on how the first element is loaded (if we use lu, the CTR value should be size-1 to not exceed the array’s length).
The loop label indicates the start of our iteration through the array. The first step in the loop is to update* our index [vec] and load the next element in R4. Here, the value 4 indicates the amount to add to the current address so we can access the next index*. On line 5 we compare the next element to the current maximum**. If the element is smaller than the maximum, we simply skip the update, otherwise the addi instruction is executed adding 0 to the new maximum and updating [max]’s value. The last instruction in the loop is bdnz, which will first decrement the CTR and then check if it hasn’t reached zero. If CTR is not zero, the loop is executed again, otherwise, the asm terminates.&lt;/p&gt;
&lt;p&gt;*&lt;em&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/em&gt; &lt;em&gt;it computes in bytes. Since we have an integer array, which is four bytes per element, to access the next position we must add 4 bytes to the current address [vec].&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The C Inline assembly tool allows us to quickly integrate assembly code with high level code, which allows for certain optimizations based on the processor&amp;rsquo;s architecture as well as access to specific OS/Hardware services. Despite being useful, it’s a delicate tool which alters the assembly code by the programmer&amp;rsquo;s orders, meaning that, if the parameters are not carefully checked, it could affect the program&amp;rsquo;s cohesion by messing with register allocations. If this is the case, the code’s correctness/consistency would likely be broken rendering it useless.&lt;/p&gt;
&lt;h2 id=&#34;anecdotes-on-inline-asm&#34;&gt;Anecdotes on Inline ASM&lt;/h2&gt;
&lt;h4 id=&#34;counter-register-and-mnemonics&#34;&gt;Counter Register and Mnemonics:&lt;/h4&gt;
&lt;p&gt;The major advantage the CTR provides is the ease of executing loops with counters in assembly. This ease is provided mainly by mnemonics which can modify, compare and branch all in single instruction (in our case bdzn). You can check other mnemonics on Appendix C (page 790) of &lt;a href=&#34;https://ibm.ent.box.com/s/1hzcwkwf8rbju5h9iyf44wm94amnlcrv&#34;&gt;the official Power ISA&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;labels-duplicates&#34;&gt;Labels Duplicates:&lt;/h4&gt;
&lt;p&gt;When talking about the asm call, I commented on the fact that the assembly code is literally concatenated and pasted to the assembly file generated by the compiler. Now suppose your code has multiple sections using asm calls and these sections all have the label loop or skip in it. In this case, when the asm is pasted to the file, there will be multiple labels with the same name and the compiler will point to  a conflict of addresses. The asm call allows you to define relative branches, but it’s quite limited: it only works if the labels are numerals, and it can only branch to the first label above or below the branching instruction. To use this tool you can add the suffixes b (backward) or f (forward) to the label’s name when branching. More about it &lt;a href=&#34;https://www.ibm.com/developerworks/rational/library/inline-assembly-c-cpp-guide/index.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;branching-prediction&#34;&gt;Branching Prediction:&lt;/h4&gt;
&lt;p&gt;Many architectures implement an optimization called branching prediction. As the name implies, it considers that a certain branch instruction will or won’t be executed and optimizes the code by preprocessing some steps of the branch procedure. This can be relevant when a comparison is executed multiple times in some iteration and its outcome is almost always the same. The prediction can be implied in assembly language by appending the ‘+’ (probably will branch) and ‘-’ (unlikely to branch) symbols to the branching instruction. More about it &lt;a href=&#34;https://www.ibm.com/developerworks/library/l-powasm3/index.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;multi-arch-programs&#34;&gt;Multi-Arch Programs:&lt;/h4&gt;
&lt;p&gt;In case you’re not aware, assembly instructions are architecture dependent (meaning they might not be the same for different processors). In case you’re trying to implement come assembly code for a multi-arch software, you’ll need to be able to identify the machine’s architecture the program is being executed on. For this scenario we can use predefined compiler macros, such as &lt;code&gt;__powerpc64__&lt;/code&gt;. With these macros we can chose to compile certain blocks of code using C compiler directives (Ex: &lt;code&gt;#IF DEFINED  __powerpc64__&lt;/code&gt;) or use an if-else statement to choose between asm blocks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Upgrading to OpenStack Train</title>
      <link>https://openpower.ic.unicamp.br/post/upgrading-to-openstack-train/</link>
      <pubDate>Wed, 04 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/upgrading-to-openstack-train/</guid>
      <description>&lt;p&gt;Recently, we’ve upgraded Minicloud’s (a Power architecture based server) Openstack environment to it’s latest version (Openstack Train), and this post aims to tackle some of the issues which we’ve faced.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Minicloud Environment:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Our server holds multiple machines of two Power architectures: Power8 and Power9 servers. As for our Openstack implementation, we use a Power8 to be the controller and the remaining machines are designated as compute nodes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preparations:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are some details to consider before upgrading, these mainly revolve around softwares and firmwares versions, as well as network architecture.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;As for firmware, make sure all your machines are up to date with the latest patches&lt;/strong&gt;, otherwise there can be unforeseen errors even if Openstack is correctly installed. An example of such errors is KVM’s safe cache capability which is not supported on older firmware versions.&lt;/p&gt;
&lt;p&gt;Before starting, format all bare metal machines to make sure you’re getting a clean install (we’ve used the Ubuntu Server 18.04 as the OS for the server).** Software versions were picked considering Openstack dependencies** and the latest release available for power architecture.&lt;/p&gt;
&lt;p&gt;As for the network, it won’t be addressed in this post, hence, if necessary, &lt;a href=&#34;https://alta3.com/&#34;&gt;Alta3 Research&lt;/a&gt; has a handy &lt;a href=&#34;https://www.youtube.com/watch?v=8FYgmM3tUCM&#34;&gt;playlist&lt;/a&gt; addressing this matter.&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;Note: avoid running an apt upgrade command after the environment is set, as some packages might break or lose it’s configurations, also, disable automatic package upgrades.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Firmware Updates:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In case of Power machines, all you’ll need to realize an firmware update is located in &lt;a href=&#34;https://www.ibm.com/support/fixcentral/&#34;&gt;IBM’s Fix Central&lt;/a&gt;. Simply find the requested hardware info (&lt;em&gt;lshw&lt;/em&gt; command should do the job) and search for your machine model. After finding your model, inserting it’s serial number and selecting the latest fix, you will find a page with all software and instruction for the update.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adjusting Simultaneous Multithreading:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One of the main problems you’ll face with Power8 servers is the Simultaneous Multithreading (SMT) functionality. Essentially, SMT allows a better resource usage, but it can also cause errors. In our case, the SMT was completely disabled in P8 machines and set to 4 in P9 machines.&lt;/p&gt;
&lt;p&gt;When running Openstack with SMT enabled on Power8, we dealt with VMs being allocated but remaining in a paused state as they were unable launch due to SMT configurations.&lt;/p&gt;
&lt;p&gt;The following settings can be used to set a service with &lt;em&gt;systemd&lt;/em&gt; which will disable SMT on power machines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Unit]
Description=ppc64 set SMT off
Before=libvirt-bin.service

[Service]
Type=oneshot
RemainAfterExit=true
ExecStart=/usr/sbin/ppc64_cpu --smt=off
ExecStop=/usr/sbin/ppc64_cpu --smt=on

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Installation Checklist:&lt;/strong&gt; Here’s a helpful step by step installation checklist for an environment with multiple node:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Steps to Execute&lt;/th&gt;
&lt;th&gt;Controller&lt;/th&gt;
&lt;th&gt;Compute&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/install-guide/environment-networking.html&#34;&gt;Host networking&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/install-guide/environment-ntp.html&#34;&gt;Network Time Protocol (NTP)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/install-guide/environment-packages.html&#34;&gt;OpenStack packages&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/install-guide/environment-sql-database.html&#34;&gt;SQL database&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;cross.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/install-guide/environment-messaging.html&#34;&gt;Message queue&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;cross.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/install-guide/environment-memcached.html&#34;&gt;Memcached&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;cross.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/install-guide/environment-etcd.html&#34;&gt;Etcd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;cross.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/keystone/train/install/&#34;&gt;keystone&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;cross.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/glance/train/install/&#34;&gt;glance&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;cross.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/placement/train/install/&#34;&gt;placement&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/nova/train/install/&#34;&gt;nova&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/neutron/train/install/&#34;&gt;neutron&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;cross.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.openstack.org/horizon/train/install/&#34;&gt;horizon&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;check.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Troubleshooting:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this section we’ll share some of the errors we had during installation and the solutions we found to each of them. Note that these errors are not specifically of POWER architecture installations.&lt;/p&gt;
&lt;h4 id=&#34;mariadb-note&#34;&gt;MariaDB note:&lt;/h4&gt;
&lt;p&gt;Some SQL commands were failing due to unknown reasons even with the correct dependencies. A solution we found for this issue was bumping our mariaDB version from 10.2 to 10.4.&lt;/p&gt;
&lt;h4 id=&#34;apache--horizon-login&#34;&gt;Apache &amp;amp; Horizon Login:&lt;/h4&gt;
&lt;p&gt;A small change to Horizon from the previous OpenStack release was the dashboard login page URL settings. Simply using &lt;strong&gt;&lt;!-- raw HTML omitted --&gt;/horizon&lt;/strong&gt; would redirect to the login page in previous versions. This might require some redirection tweaks in the Apache server configuration file.&lt;/p&gt;
&lt;h4 id=&#34;virtual-interface-exception&#34;&gt;Virtual Interface Exception:&lt;/h4&gt;
&lt;p&gt;When attempting to create a VM, the following error was presented by the Nova module: &lt;em&gt;VirtualInterfaceCreateException: Virtual Interface creation failed.&lt;/em&gt;&lt;br&gt;
To fix this, we&lt;a href=&#34;https://ask.openstack.org/en/question/26938/virtualinterfacecreateexception-virtual-interface-creation-failed/&#34;&gt; followed the instructions from a post&lt;/a&gt; in which two lines of configurations are added to the &lt;em&gt;nova.conf&lt;/em&gt; file: &lt;strong&gt;vif_plugging_is_fatal: false&lt;/strong&gt; and &lt;strong&gt;vif_plugging_timeout: 0.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Good luck upgrading.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Power Architecture&#39;s Assembly Language</title>
      <link>https://openpower.ic.unicamp.br/post/assembly_introduction/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/assembly_introduction/</guid>
      <description>&lt;p&gt;As programmers, we’re fairly used to high level coding and optimization, but we rarely work on lower level languages such as assembly. Even so, understanding these languages is essential for several reasons: optimization, portability, etc. Also, the standard learning languages for assembly tend to be either for Intel’s x86 and/or ARMv7 architectures, leaving aside many others.&lt;/p&gt;
&lt;p&gt;In this post, we’ll be introducing the Power instruction set architecture (to be precise, the PowerPC 64-bit little-endian architecture) and walking through the initial steps for studying and analysing assembly code in Power. More specifically, the code which we’ll compile and analyse is a C program with a single function which returns one or minus one given a probability (which is passed as a function parameter) using C&amp;rsquo;s standard random number generator.&lt;/p&gt;
&lt;h2 id=&#34;compiling-for-power-processors&#34;&gt;&lt;strong&gt;Compiling for Power Processors&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Using a Power Machine&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The most simple and straightforward method for obtaining an assembler or binary code for Power architecture is using a Power machine. You can access the Minicloud website and request a free Power VM. Once you’ve setup the VM and installed GCC, all you have to do is compile it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Unicamp-OpenPower/minicloud/wiki/Getting-Started-with-Minicloud&#34;&gt;Setting Up a Power VM at Minicloud&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Using GCC Packages&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To install a GCC version which can cross compile for power machines we can simply use &lt;code&gt;sudo apt install gcc-7-powerpc64le-linux-gnu&lt;/code&gt;.
The &lt;em&gt;powerpc64le-linux-gnu&lt;/em&gt; suffix is what we call target Here we’re specifying that we want to install GCC v7 for powerpc66le architecture which  runs linux-gnu OS. Upon installing the cross compiler we can get the assembly code using &lt;code&gt;powerpc64le-linux-gnu-gcc program.c -S&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;overview-of-the-c-code&#34;&gt;&lt;strong&gt;Overview of the C code&lt;/strong&gt;&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;time.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rand_p&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; p) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; r &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt;)rand()&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt;)RAND_MAX;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (r &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; p) &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;; &lt;span style=&#34;color:#75715e&#34;&gt;//Returns with probability p
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;;      &lt;span style=&#34;color:#75715e&#34;&gt;//Returns with probability (1-p)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;} 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Understanding the C code is quite trivial. We start with a variable ‘p’ passed as a parameter, and then we instantiate a variable ‘r’ with the casted result of the division of rand() by RAND_MAX. To wrap it up, we test if ‘r’ is smaller than ‘p’. If so, the return value is 1, and -1 otherwise. Should also be noted that the code only works because &lt;em&gt;rand()&lt;/em&gt; returns a random value between [0,RAND_MAX] with uniform probability. Now let us see if we can establish a similar analysis but with the assembly code.&lt;/p&gt;
&lt;h2 id=&#34;overview-of-the-assembly-code&#34;&gt;&lt;strong&gt;Overview of the Assembly Code&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Since we’re starting with the basics, we’ll be skipping some lines of code which aren&amp;rsquo;t necessary for grasping the general idea of what’s happening within the program.
We can split the code into three main blocks: directives, function call handling and the program logic.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;sectioned_asm.png&#34; alt=&#34;Assembly Code&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&#34;http://www.idc-online.com/technical_references/pdfs/electronic_engineering/Assembler_Directives.pdf&#34;&gt;directives&lt;/a&gt; (Red) assist in guiding the assembly process as well as inserting data.&lt;/li&gt;
&lt;li&gt;Functions calls demands a series of conventions (Blue) to allow the proper integration of the code within multiple environments. These are defined by the Power’s &lt;a href=&#34;http://www.idc-online.com/technical_references/pdfs/electronic_engineering/Assembler_Directives.pdf&#34;&gt;ABI&lt;/a&gt; (Application&amp;rsquo;s Binary Interface), which has a dedicated document for it’s description.&lt;/li&gt;
&lt;li&gt;The program logic (Black) is where the code we’ve written is translated to the assembler code. This is the section which we’ll be analysing here.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminary-notes&#34;&gt;&lt;strong&gt;Preliminary Notes&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Before we can dive in, there&amp;rsquo;s a few concepts which must be known beforehand to fully understand the assembly code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Register Types:&lt;/strong&gt; There are multiple register types within the Power architecture, the following initials will be used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GX stands for General purpose register X.&lt;/li&gt;
&lt;li&gt;FX stands for Floating point register X.&lt;/li&gt;
&lt;li&gt;LR and CR refers to Linked Register and Condition Register respectively. These are considered Special Registers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Special Registers:&lt;/strong&gt; Some registers have designated functions within  the architecture, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CR&lt;/strong&gt; which contains 8 adressable fields (with 4 bits each) for saving the result of comparison instructions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LR&lt;/strong&gt; keeps the return address of a function call when the instruction BL (Branch Linked) is used, and can be used to return to the calling point with the instruction BLR (Branch to Linked Register).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Parameters and Return Registers:&lt;/strong&gt; The Power ABI defines a set of registers (both GX and FX types) which ares used as variables when returning values or passing parameters to functions. The registers G[3,10] and F[1,13] are such registers. &lt;!-- raw HTML omitted --&gt; &lt;em&gt;Example:&lt;/em&gt; if we have &lt;code&gt;f(int w, int x, float y, double z)&lt;/code&gt;, the registers G3, G4, F1 and F2 will contain w, x, y and z respectively when &lt;code&gt;f&lt;/code&gt; is called.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Volatile and Nonvolatile Registers:&lt;/strong&gt; When a function is called, by the ABI&amp;rsquo;s specifications, &lt;em&gt;nonvolatile&lt;/em&gt; registers are presumed to remain intact, meaning that their values either won&amp;rsquo;t change or will be restored by any called function. On the other hand, &lt;em&gt;volatile&lt;/em&gt; registers must be saved by the caller if necessary, since these can be altered at will by any called function.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Table of Contents (TOC):&lt;/strong&gt; For now, all we need to know is that &lt;code&gt;RAND_MAX&lt;/code&gt; is kept here, and to access it we&amp;rsquo;ll need the address of the table plus an offset. The directives below &lt;code&gt;.LCO:&lt;/code&gt; are responsible for defining the offset.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Observation:&lt;/em&gt; These informations can be found within the &lt;a href=&#34;https://openpowerfoundation.org/?resource_lib=power-isa-version-3-0&#34;&gt;Power ISA&lt;/a&gt; and &lt;a href=&#34;http://www.idc-online.com/technical_references/pdfs/electronic_engineering/Assembler_Directives.pdf&#34;&gt;Power ABI&lt;/a&gt; specifications.&lt;/p&gt;
&lt;h2 id=&#34;analysing-the-assembly-code&#34;&gt;&lt;strong&gt;Analysing the Assembly Code&lt;/strong&gt;&lt;/h2&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[...]
 7  rand_p: 
 8  .LCF0:
 9  0:	
10      addis 2,12,.TOC.-.LCF0@ha
11   	addi 2,2,.TOC.-.LCF0@l
[...]
18      stfd 1,40(31)
19   	bl rand
20   	nop
21  	mr 9,3
22  	mtvsrd 32,9
23 	    xscvsxddp 12,32
24  	addis 9,2,.LC0@toc@ha
25  	addi 9,9,.LC0@toc@l
26  	lfd 0,0(9)
27   	fdiv 0,12,0
28  	stfd 0,56(31)
29  	lfd 12,56(31)
30  	lfd 0,40(31)
31  	fcmpu 7,12,0
32      bnl 7,.L6
33  	li 9,1
34  	b .L4
35  .L6:
36      li 9,-1
37  .L4:
38      mr 3,9
39	    addi 1,31,80
40	    ld 0,16(1)
41	    mtlr 0
42	    ld 31,-8(1)
43	    blr
[...]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;First, let’s locate where is the parameter ‘p’. Since ‘p’ is a Float and it’s also the single parameter passed, it’s located at FPR1 (as specified by the ABI).&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;lines 10 and 11&lt;/strong&gt; initialize the &lt;strong&gt;TOC base pointer at G2&lt;/strong&gt; using the ADDIS and ADD instructions. We&amp;rsquo;ll use this value later for obtaining &lt;code&gt;RAND_MAX&lt;/code&gt; from memory. Let’s ignore the &lt;code&gt;.localentry&lt;/code&gt; directive that follows.&lt;/p&gt;
&lt;p&gt;At line 19, the compiler calls the &lt;em&gt;rand()&lt;/em&gt; function with the BL instruction, since &lt;strong&gt;&lt;em&gt;rand()&lt;/em&gt; returns an integer, it’s return value will be placed at G3 (as specified by the ABI) and will be converted to a double at lines 22 and 23&lt;/strong&gt; which involves more complicated instructions. Also, in these lines, the value in &lt;strong&gt;G3 is transferred to F12&lt;/strong&gt;. Note that &lt;strong&gt;FPR1 is saved at line 17&lt;/strong&gt;, since FPR1 is a volatile register and can be lost during &lt;em&gt;rand()&lt;/em&gt;&amp;rsquo;s execution. The NOP instruction does literally nothing, but it does have a purpose  in the bigger picture.&lt;/p&gt;
&lt;p&gt;At the next step, the compiler will load RAND_MAX. Lines 24 and 25 adds an offset to the TOC pointer (G2) and saves the result at G9. Now, G9 withholds the absolute address of RAND_MAX’s value. To load RAND_MAX’s value, we can use LFD (line 26) using G9 as the offset and &lt;strong&gt;setting G0 as RAND_MAX&lt;/strong&gt;. Note that the LFD instruction interprets the value 0, not as the register G0, but as the number 0, as describes the ISA.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We have &lt;em&gt;rand()&lt;/em&gt;’s return value and RAND_MAX constant&lt;/strong&gt;, both at floating point registers, therefore, we can finally &lt;strong&gt;divide these values&lt;/strong&gt; to initialize the variable ‘r’. This division is observed at line 27 by the FDIV instruction, where F12 is divided by F0 and the result saved in F0. In other words, &lt;strong&gt;F0 now stores the variable ‘r’ of our C program&lt;/strong&gt;. In line 28 and 29, the value of &lt;strong&gt;F0 is stored and then loaded in F12&lt;/strong&gt;, probably due to poor optimization.&lt;/p&gt;
&lt;p&gt;Since F1 might have change during &lt;em&gt;rand()&lt;/em&gt;’s execution, we must restore F1 with its saved value by loading it from the memory address we saved it in line 18. This can be observed at line 30, where &lt;strong&gt;the saved value of our parameter ‘p’ is loaded into F0&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We finally have &lt;code&gt;r&lt;/code&gt; in F12 and &lt;code&gt;p&lt;/code&gt; in F0&lt;/strong&gt;, meaning that these values can be compared.The instruction FCMPU at line 31 is responsible for &lt;strong&gt;comparing F12 with F0 and storing their relation at CR&amp;rsquo;s 7th field&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;At line 32, the if-else structure is built. First, a &lt;strong&gt;BNL instruction checks if F12 is NOT smaller than F0&lt;/strong&gt; (by checking CR&amp;rsquo;s 7th field) and, if true, jumps to label .L6 loading -1 into G9, otherwise does not branch and loads 1 at G9. Note that the conditional here (‘r’ &amp;gt;=  ‘p’) is the negation of the one present in the C code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Finally, we have the function’s return value at G9&lt;/strong&gt;. To properly end the function call, there are few rules established by the ABI which should be followed, but we won&amp;rsquo;t cover all of them here. For now, we’ll focus on two steps: &lt;strong&gt;Moving result from G9 to G3 and loading the return address&lt;/strong&gt;. The first one is relevant because the caller function will consider that our function’s return value is at G3, therefore, G9 is moved to G3 at line 38 by the MR instruction. The second step ensures that we return to the point where our function was called. For this, we’ll restore the value of the LR register at line 40 using the MTLR instruction.&lt;/p&gt;
&lt;p&gt;To end our function’s execution, BLR is invoked at line 43 and the function call ends.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As short and simple a C program is, when analysed by it’s assembly code, can be quite complex. As seen here, what can be described in a paragraph at high level code, can turn to a long text at low level code (not to mention that we ignored a large portion of the code). The increased complexity is mostly due to the several elements which are omitted for the programmers sake when using high level languages, but this comes at a cost. These instructions can be combined in multiple ways, and the optimal way to do so depends on the program, it’s compilation and the host architecture, resulting in countless combinations which makes the automated optimization process extremely complicated. So overall, understanding such low level code and it’s host architecture is relevant for writing efficient programs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Installing spaCy on POWER8 or POWER9.</title>
      <link>https://openpower.ic.unicamp.br/post/installing-spacy-power/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/installing-spacy-power/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;SpaCy_logo.jpg&#34; alt=&#34;SpaCy Logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://spacy.io&#34;&gt;spaCy&lt;/a&gt; is an open-source software library for advanced Natural Language Processing, written in Python and Cython. The library is published under the MIT license and currently offers statistical neural network models for English, German, Spanish, Portuguese, French, Italian, Dutch and multi-language NER, as well as tokenization for various other languages.&lt;/p&gt;
&lt;p&gt;Its installation is very straightforward using the &lt;a href=&#34;https://pypi.org/project/pip/&#34;&gt;pip&lt;/a&gt; package manager. However, you will not succeed if you try to make it into a POWER processor. This is due to a problem with the headers of the Numpy library when using the pip. Thus, the easiest way to install spaCy is by using another package manager, &lt;a href=&#34;https://www.anaconda.com&#34;&gt;Conda&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Conda is an open source, cross-platform, language-agnostic package manager and environment management system. It is released under the Berkeley Software Distribution License by Continuum Analytics.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;installing-python-37&#34;&gt;Installing Python 3.7&lt;/h1&gt;
&lt;p&gt;To install spaCy, you will need to have python 3.7. To verify that you have it installed, simply use the command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;python3.7 --version
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you have not installed it, use the package manager of your system to install.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start by updating the packages and installing the prerequisites:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt update
sudo apt install software-properties-common
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Add the deadsnakes PPA to your sources list:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo add-apt-repository ppa:deadsnakes/ppa
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Once the repository is enabled, install Python 3.7 with:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt install python3.7
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h1 id=&#34;installing-conda&#34;&gt;Installing Conda&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; Download the &lt;a href=&#34;https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-ppc64le.sh&#34;&gt;Anaconda installer for POWER8 and POWER9&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Enter the following on the download directory:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bash Anaconda3-2019.03-Linux-ppc64le.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; The installer prompts “In order to continue the installation process, please review the license agreement.” Click Enter to view license terms.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.&lt;/strong&gt; Using Enter, scroll to the bottom of the license terms and enter “Yes” to agree to them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.&lt;/strong&gt; Click Enter to accept the default install location.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6.&lt;/strong&gt; Enter &amp;ldquo;yes&amp;rdquo; to initialize Anaconda3 by running conda init.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7.&lt;/strong&gt; Close and open your terminal window for the installation to take effect.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;source ~/.bashrc.
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h1 id=&#34;installing-spacy&#34;&gt;Installing spaCy&lt;/h1&gt;
&lt;p&gt;You only need to use the following command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;conda install -c conda-forge spacy
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>How use scikit-learn and Jupyter remotely</title>
      <link>https://openpower.ic.unicamp.br/post/how-use-scikit-learn-and-jupyter-remotely/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/how-use-scikit-learn-and-jupyter-remotely/</guid>
      <description>&lt;h2 id=&#34;introduction-and-prerequisites&#34;&gt;Introduction and Prerequisites&lt;/h2&gt;
&lt;p&gt;In this tutorial I will show how to use Jupyter in your browser to control scikit-learn running inside a VM.
First of all you need build and connect to VM, which is showed in &lt;a href=&#34;https://github.com/Unicamp-OpenPower/minicloud/wiki/Getting-Started-with-Minicloud&#34;&gt;this tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ssh-connection&#34;&gt;SSH connection&lt;/h2&gt;
&lt;p&gt;Now you need connect to VM via ssh using &lt;code&gt;-L 8888:localhost:8888&lt;/code&gt; flag, which will bind your computer port 8888 to port 8888 from VM:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh ubuntu@minicloud.parqtec.unicamp.br -i ~/.ssh/your-key.pem -p &amp;lt;vm-port&amp;gt; -L 8888:localhost:8888&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;instalation-and-executing&#34;&gt;Instalation and executing&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s update O.S., then install jupyter and sklearn:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   sudo apt upgrade -y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   sudo apt  sudo apt install jupyter python3-sklearn python3-pandas -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Initiate jupyter notebook with &lt;code&gt;&amp;amp;&lt;/code&gt; flag, which will allow jupyter run in backgroud:
&lt;img src=&#34;jupyter-token.png&#34; alt=&#34;Jupyter Token&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;Open link showed by jupyter on your favorite browser:
&lt;img src=&#34;jupyter1.png&#34; alt=&#34;Jupyter&#34;&gt;&lt;/p&gt;
&lt;p&gt;And now you are ready to use scikit-learn using jupyter remotely.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Installing Bazel on Power and Other Unsupported Architectures/Systems</title>
      <link>https://openpower.ic.unicamp.br/post/installing-bazel-power-other-architectures-systems/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/installing-bazel-power-other-architectures-systems/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;bazel-logo2.jpg&#34; alt=&#34;Bazel Logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;Bazel is a free software tool that allows for the automation of building and testing of software. Similar to build tools like Make, Maven, and Gradle, Bazel builds software applications from source code using a set of rules.&lt;/p&gt;
&lt;p&gt;It uses a human-readable, high-level build language. Bazel supports projects in multiple languages and builds outputs for multiple platforms and supports large codebases across multiple repositories, and large numbers of users.&lt;/p&gt;
&lt;p&gt;In designing Bazel, emphasis has been placed on build speed, correctness, and reproducibility. The tool uses parallelization to speed up parts of the build process. It includes a Bazel Query language that can be used to analyze build dependencies in complex build graphs&lt;/p&gt;
&lt;p&gt;Bazel must have Power support in the future, making its installation possible through community-supported methods. However, currently, if you want to install on Power or other architectures or systems that do not have support, you need compiling Bazel from source.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;hr&gt;
&lt;h1 id=&#34;building-bazel-from-scratch-bootstrapping&#34;&gt;Building Bazel from scratch (bootstrapping)&lt;/h1&gt;
&lt;p&gt;Here we will see how to do self-compilation. If you are using Ubuntu 14.04 or Ubuntu 16.04 in ppc64le, you can skip right to: &lt;a href=&#34;#ready&#34; title=&#34;Using ready binaries&#34;&gt;Using ready binaries&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;First, install the prerequisites:&lt;/strong&gt;&lt;br&gt;
Pkg-config&lt;br&gt;
Zip, Unzip&lt;br&gt;
G++&lt;br&gt;
Zlib1g-dev&lt;br&gt;
JDK 8 (you must install version 8 of the JDK. Versions other than 8 are not supported)&lt;br&gt;
Python (versions 2 and 3 are supported, installing one of them is enough)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# add-apt-repository ppa:openjdk-r/ppa  
# apt-get update  
# apt-get install pkg-config zip unzip g++ zlib1g-dev openjdk-8-jdk python  
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Next, download the Bazel binary installer named bazel-&lt;!-- raw HTML omitted --&gt;-dist.zip from the &lt;a href=&#34;https://github.com/bazelbuild/bazel/releases&#34;&gt;Bazel releases page on GitHub&lt;/a&gt;:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  wget https://github.com/bazelbuild/bazel/releases/download/&amp;lt;version&amp;gt;/bazel-&amp;lt;version&amp;gt;-dist.zip
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There is a single architecture-independent distribution archive. There are no architecture-specific or OS-specific distribution archives.&lt;/p&gt;
&lt;p&gt;You have to use the distribution archive to bootstrap Bazel. You cannot use a source tree cloned from GitHub (the distribution archive contains generated source files that are required for bootstrapping and are not part of the normal Git source tree).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unpack the zip file somewhere on disk:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  unzip bazel-&amp;lt;version&amp;gt;-dist.zip
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Run the compilation script:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  bash ./compile.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;This may take several minutes&amp;hellip;&lt;/em&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;build-successful.png&#34; alt=&#34;Bazel Logo&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;using-ready-binaries&#34;&gt;Using ready binaries&lt;/h1&gt;
&lt;p&gt;If you are using Ubuntu 14.04 or Ubuntu 16.04 in ppc64le, you can use our already compiled versions of the binaries.&lt;/p&gt;
&lt;p&gt;Make sure you have the JDK 8 installed:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  java -version
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If you do not have it, you need to install it:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# add-apt-repository ppa:openjdk-r/ppa
# apt-get update
# apt-get install openjdk-8-jdk
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We have released the last 10 versions of Bazel already compiled in this link: &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/bazel/&#34;&gt;https://oplab9.parqtec.unicamp.br/pub/ppc64el/bazel/&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Download the desired version:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  wget https://oplab9.parqtec.unicamp.br/pub/ppc64el/bazel/ubuntu_&amp;lt;version&amp;gt;/bazel_bin_&amp;lt;version&amp;gt;
# mv bazel_bin_&amp;lt;version&amp;gt; bazel
# chmod +x bazel
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h1 id=&#34;installing-bazel&#34;&gt;Installing Bazel&lt;/h1&gt;
&lt;p&gt;Finally, the compiled output is placed into output/bazel (or it is in the current directory if you have downloaded the binary). This is a self-contained Bazel binary, without an embedded JDK. You can copy it anywhere or use it in-place. For convenience we recommend copying this binary to a directory that&amp;rsquo;s on your PATH (such as /usr/local/bin on Linux).&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# mv output/bazel /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# mv bazel /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When using Bazel for the first time, it will extract the installation and prepare everything. To do this, simply use the command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;From now on, Bazel is installed and to use it simply use the command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  bazel &amp;lt;command&amp;gt; &amp;lt;options&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h1 id=&#34;using-bazel-to-compile-bazel&#34;&gt;Using Bazel to compile Bazel&lt;/h1&gt;
&lt;p&gt;Once installed, you can use Bazel itself to compile a new version. To do this, simply download the desired version (as seen in &lt;a href=&#34;#building&#34; title=&#34;Building Bazel from scratch&#34;&gt;Building Bazel from scratch&lt;/a&gt;) or even the developing version on &lt;a href=&#34;https://github.com/bazelbuild/bazel&#34;&gt;GitHub&lt;/a&gt; and use the following command in the directory of the downloaded files:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  Bazel build //src:bazel
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bazel.build/&#34;&gt;https://docs.bazel.build/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Building a opensuse openstack image</title>
      <link>https://openpower.ic.unicamp.br/post/opensuse-tutorial/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/opensuse-tutorial/</guid>
      <description>&lt;p&gt;This tutorial I will show how create a openstack image (.qcow2) of opensuse from a ISO image using qemu.
In this tutorial will be used opensuse Tumbleweed ppc64 le (because it&amp;rsquo;s the most challenging), but similiar process can be done for leap (15 and 42.3) and Tumbleweed ppc64be.&lt;/p&gt;
&lt;h2 id=&#34;preparing-environment&#34;&gt;Preparing environment&lt;/h2&gt;
&lt;p&gt;First we need download opensuse image from repository (&lt;a href=&#34;https://software.opensuse.org/distributions/tumbleweed&#34;&gt;Tumbleweed&lt;/a&gt;, &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/opensuse/&#34;&gt; leap 15&lt;/a&gt; and  &lt;a href=&#34;http://download.opensuse.org/ports/ppc/distribution/leap/42.3/iso/&#34;&gt;leap 42.3&lt;/a&gt;) and sha256 of respective image.&lt;/p&gt;
&lt;p&gt;Execute sha256:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sha256sum openSUSE-Tumbleweed-DVD-ppc64le-Current.iso
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Compare sha256sum output with sha256 downloaded:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;715d9f89d90eb795b6a64ffe856aa5b7f3a64c7195a9ede8abea14a9d4f69e67
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Install qemu using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install qemu-kvm libvirt-clients libvirt-daemon-system -y
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we need create a disk .qcow2 to install our O.S. with this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;qemu-img create -f qcow2 openSUSE-Tumbleweed-ppc64le.qcow2 5G
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Update 09/2020&lt;/em&gt;: this comand above may cause problem, try this command:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;qemu-img create -f qcow2 openSUSE-Tumbleweed-ppc64le.qcow2 6G
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Execute qemu to run the instaler:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo qemu-system-ppc64le -enable-kvm -m &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt; -cdrom openSUSE-Tumbleweed-DVD-ppc64le-Current.iso -drive file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;openSUSE-Tumbleweed-ppc64le.qcow2,media&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;disk,if&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;virtio -nographic -smp cores&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1,threads&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; -monitor pty -serial stdio -nodefaults -netdev user,id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;enp0s1 -device virtio-net-pci,netdev&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;enp0s1 -boot order&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;d
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Update 09/2020&lt;/em&gt;: this comand above may not work, try this command:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo qemu-system-ppc64le -machine cap-htm&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;off -m &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt; -cdrom openSUSE-Tumbleweed-DVD-ppc64le-Current.iso -drive file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;openSUSE-Tumbleweed-ppc64le.qcow2,media&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;disk,if&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;virtio -nographic -smp cores&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1,threads&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; -monitor pty -serial stdio -nodefaults -netdev user,id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;enp0s1 -device virtio-net-pci,netdev&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;enp0s1 -boot order&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;d
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;installing-opensuse&#34;&gt;Installing openSUSE&lt;/h2&gt;
&lt;p&gt;Select your language (using tab and arrows):
&lt;img src=&#34;Language-selection-screen.png&#34; alt=&#34;Language selection screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 1: Language selection screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select te most suitable bundle for your goal:
&lt;img src=&#34;Bundle-selector-screen.png&#34; alt=&#34;Bundle selector screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 2: Bundle selector screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select expert partitioner:
&lt;img src=&#34;Partioner-selection-screen.png&#34; alt=&#34;Partioner selection screen 1&#34;&gt;
&lt;img src=&#34;Partioner-selection-screen2.png&#34; alt=&#34;Partioner selection screen 2&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 3-4: Partioner selection screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select the hard drive that you want install opensuse:
&lt;img src=&#34;Drive-selector-screen.png&#34; alt=&#34;Drive selector screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 5: Drive selector screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Add new partition selecting &lt;code&gt;add&lt;/code&gt; button:
&lt;img src=&#34;Partition-screen.png&#34; alt=&#34;Partition screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 6: Partition screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Set &lt;code&gt;partition size&lt;/code&gt; to &lt;code&gt;8 MiB&lt;/code&gt;:
&lt;img src=&#34;Partition-size-screen.png&#34; alt=&#34;Partition size screen (Boot)&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 7: Partition size screen (Boot)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select &lt;code&gt;raw partition&lt;/code&gt;:
&lt;img src=&#34;Partition-role-screen.png&#34; alt=&#34;Partition role screen (Boot)&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 8: Partition role screen (Boot)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select file system as &lt;code&gt;Ext4&lt;/code&gt; (or other filesystem of your preference):
&lt;img src=&#34;File-System-type.png&#34; alt=&#34;File System type (Boot)&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 9: File System type (Boot)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select partition as &lt;code&gt;PReP Boot Partition&lt;/code&gt; and &lt;code&gt;next&lt;/code&gt;:
&lt;img src=&#34;Partition-type.png&#34; alt=&#34;Partition type (Boot)&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 10: Partition type (Boot)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The boot partition was create and now we will create O.S. partition, select &lt;code&gt;add&lt;/code&gt; and inside Patition size screen select &lt;code&gt;Maximum Size&lt;/code&gt;:
&lt;img src=&#34;Partition-size-screen-2.png&#34; alt=&#34;Partition size screen (O.S)&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 11: Partition size screen (O.S)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select &lt;code&gt;Operating System&lt;/code&gt; option:
&lt;img src=&#34;Partition-role-screen-2.png&#34; alt=&#34;Partition role screen (O.S)&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 12: Partition role screen (O.S)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select file system as &lt;code&gt;Ext4&lt;/code&gt; again (or other filesystem of your preference):
&lt;img src=&#34;File-System-type-2.png&#34; alt=&#34;File System type (O.S)&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 13: File System type (O.S)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Left selected &lt;code&gt;Linux Native&lt;/code&gt;:
&lt;img src=&#34;Partition-type-2.png&#34; alt=&#34;Partition type (O.S)&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 14: Partition type (O.S)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Left &lt;code&gt;Mount device&lt;/code&gt; as &lt;code&gt;/&lt;/code&gt; and select &lt;code&gt;next&lt;/code&gt;:
&lt;img src=&#34;Mount-point.png&#34; alt=&#34;Mount point&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 15: Mount point&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Partition configuration will look like this:
&lt;img src=&#34;Final-partion-configuration.png&#34; alt=&#34;Final partion configuration&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 16: Final partion configuration&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We will receive warning message but we can ignore it and select &lt;code&gt;yes&lt;/code&gt;:
&lt;img src=&#34;Warning-message.png&#34; alt=&#34;Warning message&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 17: Warning message&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Next&lt;/code&gt; again:
&lt;img src=&#34;Sumary-partition-screen.png&#34; alt=&#34;Sumary partition screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 18: Sumary partition screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Select your clock and time zone:
&lt;img src=&#34;Clock-and-time-zone-screen.png&#34; alt=&#34;Clock and time zone screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 19: Clock and time zone screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Put you username and password:
&lt;img src=&#34;Clock-and-time-zone-screen.png&#34; alt=&#34;Local user screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 20: Local user screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Accept instalation and install:
&lt;img src=&#34;Summary-screen.png&#34; alt=&#34;Summary screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 21: Summary screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;Instalation-screen.png&#34; alt=&#34;Instalation screen&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 22: Instalation screen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;preparing-image&#34;&gt;Preparing image&lt;/h2&gt;
&lt;p&gt;Update all packages and install necessary ones (you can also uninstall unnecessary packages):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo zypper update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo zypper install cloud-init growpart yast2-network yast2-services-manager acpid
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Remove hard-coded MAC address:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo cat /dev/null &amp;gt; /etc/udev/rules.d/70-persistent-net.rules
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Enable ssh and cloud-init:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl enable cloud-init
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl enable sshd
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Disable firewall:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl stop firewalld
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl disable firewalld
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Inside &lt;code&gt;/etc/default/grub&lt;/code&gt; file, set grub timeout to 0:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;GRUB_TIMEOUT=0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;Grub-configuration.png&#34; alt=&#34;Grub configuration&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 23: Grub configuration&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Update grub:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo exec grub2-mkconfig -o /boot/grub2/grub.cfg &amp;#34;$@&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;only-for-opensuse-tumbleweed-lebe&#34;&gt;Only for openSUSE Tumbleweed Le/Be&lt;/h2&gt;
&lt;p&gt;Opensuse Tumbleweed ppc64 Le/Be lacks some parameters on cloud-init.service, this causes instability on boot, which, sometimes, causes network connection errors. This problem was &lt;a href=&#34;https://bugzilla.opensuse.org/show_bug.cgi?id=1111441&#34;&gt;reported&lt;/a&gt; and hopefully will be solved when you read this tutorial.&lt;/p&gt;
&lt;p&gt;Edit &lt;code&gt;cloud-init.service&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo vim /etc/systemd/system/cloud-init.target.wants/cloud-init.service
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add lines bellow after &lt;code&gt;After=systemd-networkd-wait-online.service&lt;/code&gt; line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Requires&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;wicked.service
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;After&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;wicked.service
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;After&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;dbus.service
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Conflicts&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;shutdown.target
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;Configuration-of-cloud-init.service.png&#34; alt=&#34;Configuration of cloud-init.service&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 24: Configuration of cloud-init.service&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Reload cloud-init service:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl restart cloud-init
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo systemctl daemon-reload
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Because Leap 42.3 ppc64Le&amp;rsquo;s configuration fits better for a cloud role, so we will replace cloud.cfg of Tumbleweed by Leap42.3&amp;rsquo;s cloud.cfg:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo vim /etc/cloud/cloud.cfg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/Igortorrente/6d770e47d589db89fe2f1b49218f1c58.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;cleaning-image&#34;&gt;Cleaning image&lt;/h2&gt;
&lt;p&gt;Now delete all remaining data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /dev/null &amp;gt; ~/.bash_history &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; history -c &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo su
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /dev/null &amp;gt; /var/log/wtmp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /dev/null &amp;gt; /var/log/btmp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /dev/null &amp;gt; /var/log/lastlog
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /dev/null &amp;gt; /var/run/utmp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /dev/null &amp;gt; /var/log/auth.log
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /dev/null &amp;gt; /var/log/kern.log
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /dev/null &amp;gt; ~/.bash_history &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; history -c &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo poweroff
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;adding-to-openstack&#34;&gt;Adding to openstack&lt;/h2&gt;
&lt;p&gt;And finaly add image to openstack:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;glance image-create --file openSUSE-Tumbleweed-ppc64le.qcow2 --container-format bare --disk-format qcow2 --property hw_video_model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;vga --name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;openSUSE Tumbleweed ppc64le&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If all the steps worked, you should see these messages at the next boot.
&lt;img src=&#34;Boot.png&#34; alt=&#34;Boot&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figura 25: Boot&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Setting up a FTP Server with Access List and Disk Quota</title>
      <link>https://openpower.ic.unicamp.br/post/ftp-server-setup-with-acl-and-quota/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/ftp-server-setup-with-acl-and-quota/</guid>
      <description>&lt;p&gt;In this guide, we will show how to setup a public FTP server with directory access control and disk quota per-user.
We used Ubuntu Server 16.04, running on ppc64le architecture, but it should work on other architectures as well, because no exclusive software was used, only open source software.&lt;/p&gt;
&lt;h1 id=&#34;disk-space&#34;&gt;Disk space&lt;/h1&gt;
&lt;p&gt;You will need an &lt;code&gt;ext4&lt;/code&gt; partition with enough space, that can be mounted on &lt;code&gt;/&lt;/code&gt; or on &lt;code&gt;/var/www&lt;/code&gt;. If you need help, look at &lt;a href=&#34;https://www.howtogeek.com/106873/how-to-use-fdisk-to-manage-partitions-on-linux/&#34;&gt;this tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After that, create the directories that will be used in the web and ftp servers:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo mkdir /var/www/html
sudo mkdir /var/www/html/pub
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Set the permissions to these directories:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo chown nobody:nogroup /var/www/html
sudo chmod a-w /var/www/html
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;http-server-apache&#34;&gt;HTTP Server (apache)&lt;/h1&gt;
&lt;p&gt;We intend that our files can be accessed through a web browser. In that case, we will need a HTTP Server, like Apache.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Install the package &lt;code&gt;apache2&lt;/code&gt;, with the following commands:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install apache2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart the service to make sure that the web server works:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo systemctl restart apache2
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;content&#34;&gt;Content&lt;/h2&gt;
&lt;p&gt;You can create a welcome page in HTML with links to &lt;code&gt;/pub&lt;/code&gt; folder, to show the files though the browser. Your page &lt;code&gt;index.html&lt;/code&gt; need to be in the directory &lt;code&gt;/var/www/html&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For reference, you can look at our web page in &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;ssl-certificate-certbot&#34;&gt;SSL Certificate (certbot)&lt;/h1&gt;
&lt;p&gt;Certbot is a client that deploy free SSL certificates from Let&amp;rsquo;s Encrypt to any web server.
If you already have a SSL certificate, you can &lt;a href=&#34;#firewall-ufw&#34;&gt;&lt;em&gt;skip this part&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;installation-1&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Run these commands to install the package &lt;code&gt;certbot&lt;/code&gt;:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install software-properties-common
sudo add-apt-repository ppa:certbot/certbot
sudo apt-get update
sudo apt-get install python-certbot-apache
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;We need to configure the web server to work with the certificate. Run this command to use the Certbot certificate with the Apache web server:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo certbot --apache
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The certificate expires in 90 days, so you need to renew this certificate periodically. To schedule the execution of &lt;code&gt;certobot renew&lt;/code&gt; command, we will use &lt;code&gt;cronjob&lt;/code&gt;, a time-base job scheduler. To use the scheduler, run this command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo crontab -e
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And add the following line in the end of the file:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;0 0 * * * sudo certbot renew
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Save the file.
After that, the renew command is scheduled to run everyday.&lt;/p&gt;
&lt;h1 id=&#34;firewall-ufw&#34;&gt;Firewall (ufw)&lt;/h1&gt;
&lt;p&gt;The UFW is an easy frontend interface for iptables. We need to configure the firewall to work with the other installed software.&lt;/p&gt;
&lt;h2 id=&#34;installation-2&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Install the package &lt;code&gt;ufw&lt;/code&gt; to manage the firewall, with the following commands:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install ufw
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;configuration-1&#34;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Forwarding the ports:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo ufw allow 20/tcp
sudo ufw allow 21/tcp
sudo ufw allow 990/tcp
sudo ufw allow 60000:60500/tcp
sudo ufw allow ssh
sudo ufw allow &amp;#39;Apache Full&amp;#39;
sudo ufw status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart to conclude the steps:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo ufw disable
sudo ufw enable
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;ftp-server-vsftpd&#34;&gt;FTP Server (vsftpd)&lt;/h1&gt;
&lt;p&gt;We will use the vsftpd software to run the FTP server, the default in the Ubuntu, CentOS, Fedora, NimbleX, Slackware and RHEL Linux distributions.&lt;/p&gt;
&lt;h2 id=&#34;installation-3&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Install the package &lt;code&gt;vsftpd&lt;/code&gt; with the following command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get install vsftpd
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;configuration-2&#34;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Backup your original file:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo cp /etc/vsftpd.conf /etc/vsftpd.orig
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Edit the configuration file with the following command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo nano /etc/vsftpd.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Example config file:
&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/lcnzg/233a7b406f2528cb0d517fc6fbeed5c9.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;In the previous config, we allowed read permission for anonymous.&lt;/p&gt;
&lt;p&gt;To create the userlist that have permission to access the FTP server, and allow the anonymous user, use the following commands:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo touch /etc/vsftpd.userlist
sudo echo &amp;#34;anonymous&amp;#34; &amp;gt;&amp;gt; /etc/vsftpd.userlist
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;disabling-shell-for-ftp-users&#34;&gt;Disabling shell for ftp users&lt;/h2&gt;
&lt;p&gt;With these commands, we will create a new shell with no functionalities, to restrict the access of the FTP users:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo touch /bin/ftponly
sudo echo -e &amp;#39;#!/bin/sh\necho &amp;#34;This account is limited to FTP access only.&amp;#34;&amp;#39; &amp;gt;&amp;gt; /bin/ftponly
sudo chmod a+x /bin/ftponly
sudo echo &amp;#34;/bin/ftponly&amp;#34; &amp;gt;&amp;gt; /etc/shells
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart the FTP server service:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo systemctl restart vsftpd
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;disk-quota&#34;&gt;Disk Quota&lt;/h1&gt;
&lt;p&gt;We will use a disk quota to limit the disk space used by the FTP users.&lt;/p&gt;
&lt;h2 id=&#34;installation-4&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Install the package &lt;code&gt;quota&lt;/code&gt; with the following command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt install quota
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;configuration-3&#34;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Edit the &lt;code&gt;fstab&lt;/code&gt; file and add &lt;code&gt;usrquota&lt;/code&gt; option in the partition you chose earlier:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo nano /etc/fstab
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Remount partition and enable the quota:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo mount -o remount /var/www
sudo quotacheck -cum /var/www
sudo quotaon /var/www
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;defining-a-default-quota&#34;&gt;Defining a default quota&lt;/h2&gt;
&lt;p&gt;Create a new user to copy the quota settings for the new users:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo adduser ftpuser
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Insert a password.&lt;/p&gt;
&lt;p&gt;After that, you will need to edit the quota of &lt;code&gt;ftpuser&lt;/code&gt; with this command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo edquota ftpuser
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Put the values of soft and hard quota in these columns.&lt;/p&gt;
&lt;p&gt;Example: 10GB: 10000000 and 10485760 in block quota session.&lt;/p&gt;
&lt;p&gt;Let 0 if you don&amp;rsquo;t want to have a limit.&lt;/p&gt;
&lt;p&gt;Set the default quota user as &lt;code&gt;ftpuser&lt;/code&gt; to copy a quota for the new users:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo sed -i -e &amp;#39;s/.*QUOTAUSER=&amp;#34;&amp;#34;.*/QUOTAUSER=&amp;#34;ftpuser&amp;#34;/&amp;#39; /etc/adduser.conf
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;There are a few commands useful for controlling the quota:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;quota user&lt;/code&gt; shows the &lt;code&gt;user&lt;/code&gt; quota.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;repquota -a&lt;/code&gt; shows the general quota report.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;edquota user&lt;/code&gt; to edit &lt;code&gt;user&lt;/code&gt; quota.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;access-list-acl&#34;&gt;Access List (acl)&lt;/h1&gt;
&lt;p&gt;We will use Access List Control, or ACL, to have a better control of file permissions. With ACL we can set different file permissions, in different directories, to each FTP user.&lt;/p&gt;
&lt;h2 id=&#34;installation-5&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Install the package &lt;code&gt;acl&lt;/code&gt; with the following command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt install acl
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;configuration-4&#34;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Edit the &lt;code&gt;fstab&lt;/code&gt; file and add &lt;code&gt;acl&lt;/code&gt; option in the &lt;code&gt;/var/www&lt;/code&gt; partition:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo nano /etc/fstab
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Remount the partition to apply the changes:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo mount -o remount /var/www
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;commands-1&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;The commands used to enable write permission to &lt;code&gt;$USER&lt;/code&gt; in &lt;code&gt;$DIRECTORY&lt;/code&gt; were:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;setfacl -d -R -m u:$USER:rwX $DIRECTORY
setfacl -R -m u:$USER:rwX $DIRECTORY
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;adding-new-users&#34;&gt;Adding new users&lt;/h1&gt;
&lt;p&gt;We created the following script to manage the creation of new users:
&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/lcnzg/54a44d87babcf3f33523fbcae152c47f.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;chmod +x create_user.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Add new users by running the script this way:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo ./create_user.sh &amp;#39;user&amp;#39; &amp;#39;pass&amp;#39; &amp;#39;directory&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Directory instructions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;for the root of FTP directory, use &lt;code&gt;.&lt;/code&gt; .&lt;/li&gt;
&lt;li&gt;for other directories, don&amp;rsquo;t write the initial and final slashes (ex: ppc64el/debian for /www/html/pub/ppc64el/debian/).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Should any problem with file permissions ocurr, use the &lt;code&gt;fix_acl.sh&lt;/code&gt; script, that will remake the permissions based on &lt;code&gt;acl.list&lt;/code&gt; file.&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/lcnzg/51258738564989bc8e2b0b7d25397b02.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Add execute permission to the script:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;chmod +x fix_acl.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Run the script with sudo, this way:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo ./fix_acl.sh
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-install-the-apache-web-server-on-ubuntu-16-04&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-install-the-apache-web-server-on-ubuntu-16-04&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-setup-a-firewall-with-ufw-on-an-ubuntu-and-debian-cloud-server&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-setup-a-firewall-with-ufw-on-an-ubuntu-and-debian-cloud-server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-vsftpd-for-a-user-s-directory-on-ubuntu-16-04&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-set-up-vsftpd-for-a-user-s-directory-on-ubuntu-16-04&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Building Tensorflow on POWER - CPU only</title>
      <link>https://openpower.ic.unicamp.br/post/building-tensorflow-on-power/</link>
      <pubDate>Tue, 16 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/building-tensorflow-on-power/</guid>
      <description>&lt;p&gt;TensorFlow is a widespread software library for numerical computation using data flow graphs. It is very common on machine learning and deep neural networks projects. Therefore, today we are going to see how to install it on POWER with CPU only configuration.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;tf-logo.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;update-032021&#34;&gt;&lt;em&gt;Update 03/2021&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;If you only want to install TensorFlow on POWER (and not build it), there is an easier way which is taught in the following tutorial: &lt;a href=&#34;https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power&#34;&gt;https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;outdated-&#34;&gt;&lt;em&gt;OUTDATED&lt;/em&gt; :&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;OUTDATED 09/2020&lt;/em&gt; The following tutorial is an outdated way of building TensorFlow on Power. If you still want to build TensorFlow from source by following this tutorial, proceed with caution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Before installing TensorFlow, there are a couple of details we have to pay attention to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Due to Bazel, one of TF dependencies, the operating system must be Ubuntu 14.04 or Ubuntu 16.04.&lt;/li&gt;
&lt;li&gt;We are going to use Python 2.7, since TF doesn&amp;rsquo;t seem to be supported by Python 3.5 &lt;strong&gt;on POWER&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;tensorflow-dependencies&#34;&gt;Tensorflow Dependencies&lt;/h1&gt;
&lt;p&gt;You can use the commands below to solve most of the dependencies:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install python-numpy python-dev python-pip python-wheel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;bazel-installation&#34;&gt;Bazel installation&lt;/h1&gt;
&lt;p&gt;Bazel is one of the TF dependencies, but its installation is less intuitive than the others due to its community not officially supporting POWER architecture. That said, we must compile it from the Source. First of all, we need to install its own dependencies by the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install unzip build-essential python openjdk-8-jdk protobuf-compiler zip g++ zlib1g-dev
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It is also important to add enviroment variables on .bashrc for JDK.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vi .bashrc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	export JAVA_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/usr/lib/jvm/java-8-openjdk-ppc64el
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	export JRE_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;JAVA_HOME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/jre
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	export CLASSPATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;.:&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;JAVA_HOME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/lib:&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;JRE_HOME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/lib
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	export PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;JAVA_HOME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/bin:$PATH
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For compiling Bazel, we are going to download and unpack its distribution archive (the zip file from the release page &lt;a href=&#34;https://github.com/bazelbuild/bazel/releases&#34;&gt;https://github.com/bazelbuild/bazel/releases&lt;/a&gt;. The .sh is not compatible with ppc64le) and compile it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir bazel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd bazel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget -c https://github.com/bazelbuild/bazel/releases/download/0.11.1/bazel-0.11.1-dist.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;unzip bazel-0.11.1-dist.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./compile.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;if you want to download other version of bazel, this link must be switched by the one you are intenting to use.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Update 09/2020&lt;/em&gt;: It is also possible to perform the installation by following this &lt;a href=&#34;https://openpower.ic.unicamp.br/blog/installing-bazel-from-repository.html&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As we can see, this tutorial was tested with bazel 0.11.1, but feel free to try other version and see if it works properly.&lt;/p&gt;
&lt;p&gt;Also, if you are having any trouble about lack of resources, you can take a look on &amp;lsquo;Build issues and Support Websites&amp;rsquo; to see if there&amp;rsquo;s any link that could help you. Anticipating: if you don&amp;rsquo;t have memory enough and your Bazel can&amp;rsquo;t complete the compile step, you might have a problem with the garbage collector of JAVA (and there&amp;rsquo;s a link which explains how to deal with it).&lt;/p&gt;
&lt;h1 id=&#34;installing-tensorflow&#34;&gt;Installing Tensorflow&lt;/h1&gt;
&lt;p&gt;Since we are going to use the current version of TF, we need to clone it from the official GitHub and execute the configuration script.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/tensorflow/tensorflow
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ~/tensorflow
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./configure
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;On this step, we have to specify the pathname of all relevant TF dependencies and other build configuration options. On most of them we can use the answers suggested on each question. Here, I will show how it was done for this tutorial. (Yours might be a little different, depending on the pathnames)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify the location of python. &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Default is /usr/bin/python&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: /usr/bin/python2.7
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Found possible Python library paths:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  /usr/local/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  /usr/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please input the desired Python library path to use.  Default is &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;/usr/lib/python2.7/dist-packages&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: /usr/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Using python library path: /usr/local/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Y/N Answers given: All of them as suggested in each question.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify optimization flags to use during compilation when bazel option &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--config=opt&amp;#34;&lt;/span&gt; is specified &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Default is -march&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;native&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: -mcpu&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;native
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Configuration finished
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To build and install TF, we use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bazel build --copt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;-mcpu=native&amp;#34;&lt;/span&gt; --jobs &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --local_resources 2048,0.5,1.0 //tensorflow/tools/pip_package:build_pip_package
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg &lt;span style=&#34;color:#75715e&#34;&gt;#creates the pip package&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install /tmp/tensorflow_pkg/tensorflow-1.5.0rc0-cp27-cp27mu-linux_ppc64le.whl &lt;span style=&#34;color:#75715e&#34;&gt;#installs the pip package.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;This name depends on your operating system, Python version and CPU only vs. GPU support. Therefore, check it out its name before this step.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By this moment, your TF must be working. Remember not to import it into its own directory: you have to chance directory before executing Python.&lt;/p&gt;
&lt;h1 id=&#34;build-issues-and-support-websites&#34;&gt;Build Issues and Support Websites:&lt;/h1&gt;
&lt;p&gt;While testing this tutorial, I could separate some useful issues reports and links to help some of the troubles you might have on the way.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/14540&#34;&gt;https://github.com/tensorflow/tensorflow/issues/14540&lt;/a&gt; It solves a protobuf problem I had. It seems pretty common on PPC TF installation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/349&#34;&gt;https://github.com/tensorflow/tensorflow/issues/349&lt;/a&gt; This one is about local resources. If you are running out of memory (your build fails on C++ compilation rules), you have to specify your resources on the command line when you build TF. On the tutorial, it is already done.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/install/install_sources&#34;&gt;https://www.tensorflow.org/install/install_sources&lt;/a&gt; An official tutorial about how to install TF from Sources&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bazel.build/versions/master/install-compile-source.html&#34;&gt;https://docs.bazel.build/versions/master/install-compile-source.html&lt;/a&gt; An official tutorial about how to install Bazel from Sources.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/Building_TensorFlow_on_OpenPOWER_Linux_Systems?lang=en&#34;&gt;https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/Building_TensorFlow_on_OpenPOWER_Linux_Systems?lang=en&lt;/a&gt; IBM source about Tensorflow installation. Provides interesting information about bazel installation on PPC and how to install TF with GPU support. It also points to an IBM Bazel modified to PPC (which we are not using in this tutorial, but you can take a look on it).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/7979#issuecomment-283559640&#34;&gt;https://github.com/tensorflow/tensorflow/issues/7979#issuecomment-283559640&lt;/a&gt; An issue about enviroment variables: on the configuration step, if it does not recognize some of the TF variables, this might help you to solve the problem.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bazelbuild/bazel/issues/1308&#34;&gt;https://github.com/bazelbuild/bazel/issues/1308&lt;/a&gt; An issue about Bazel: &amp;ldquo;The system is out of resources&amp;rdquo;. You might need to add a command line on compile file to change the garbage collector size. On the issue on git, it&amp;rsquo;s suggested to change it to 384, but, at least on one of the computers I tried to compile, I needed to change it to 512 (in other words, change -J-Xmx384m on the solution line to -J-Xmx512m). It&amp;rsquo;s important to see that ideally we should not have to change the source code, but it solves the problem. Another option is to increase the memory of your system if it&amp;rsquo;s possible (recommended).&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Integrating OpenStack Ansible with Let’s Encrypt</title>
      <link>https://openpower.ic.unicamp.br/post/integrating-openstack-ansible-with-lets-encrypt/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/integrating-openstack-ansible-with-lets-encrypt/</guid>
      <description>&lt;p&gt;Deploying HTTPS is essential for security, and OpenStack Ansible does it by default. However, if no certificates are provided, it will generate self-signed ones, which although are more secure than no SSL at all, it will trigger a warning when accessing the dashboard in the browser. Luckily, the Let’s Encrypt project provides signed SSL certificates for free.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;browser-warning.png&#34; alt=&#34;Browser Warning&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let’s Encrypt requires your server to be validated before issuing the certificate. This means it will create a temporary file on your server and then try to access it from their servers, to verify that you control the domain you&amp;rsquo;re trying to get a certificate to.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;lets-encrypt-validation.png&#34; alt=&#34;Lets Encrypt Validation&#34;&gt;&lt;/p&gt;
&lt;p&gt;It can launch a temporary web server to do so, however, this will require to stop your usual web server (e.g. Apache) and lead to a few seconds of downtime. Alternatively, you can provide your web root path. Let’s Encrypt will create the files there, and they will be served directly by your usual web server. This approach does not lead to downtime, but presents some additional challenges when using it with OpenStack Ansible:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;OpenStack Ansible does not have a web root path out of the box to be used by Let’s Encrypt.&lt;/li&gt;
&lt;li&gt;SSL certificates must be provided to HAProxy, which runs on metal, while the Apache server to be used by Let’s Encrypt runs inside a container.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;openstack-ansible.png&#34; alt=&#34;Openstack Ansible&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;installing-openstack-ansible&#34;&gt;Installing OpenStack Ansible&lt;/h1&gt;
&lt;p&gt;Install OpenStack as usual, without providing any certificates. Self-signed ones will be therefore generated, and we will replace them later.&lt;/p&gt;
&lt;h1 id=&#34;enable-web-root&#34;&gt;Enable web root&lt;/h1&gt;
&lt;p&gt;We will not actually create a web root. Since Let’s Encrypt only requires writing on &lt;code&gt;your-domain.com/.well-known&lt;/code&gt; directory, we will create an alias to the &lt;code&gt;.well-known&lt;/code&gt; path.&lt;/p&gt;
&lt;p&gt;Attach to the horizon container. Replace the container name accordingly with your setup. If you don’t know the name, run &lt;code&gt;lxc-ls | grep horizon&lt;/code&gt; to get the container name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lxc-attach -n infra1_horizon_container-XXXXXXXX
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add the following line to &lt;code&gt;/etc/apache2/sites-enabled/openstack-dashboard.conf&lt;/code&gt;, inside the &lt;code&gt;&amp;lt;VirtualHost *:80&amp;gt;&lt;/code&gt; tag&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Alias /.well-known /var/www/html/.well-known
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Restart the apache2 service:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;service apache2 restart
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, we can use &lt;code&gt;/var/www/html&lt;/code&gt; as our web root, at least from the Let’s Encrypt Certbot point of view.&lt;/p&gt;
&lt;h1 id=&#34;getting-the-certificates&#34;&gt;Getting the certificates&lt;/h1&gt;
&lt;p&gt;Now install the Let’s Encrypt Certbot. The intention is to only get the certificates files, not configure them in Apache. Use the following commands to do so:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install software-properties-common
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;add-apt-repository ppa:certbot/certbot
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install certbot
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;certbot certonly
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When asked to choose an authentication method, choose &lt;code&gt;2&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;How would you like to authenticate with the ACME CA?
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-------------------------------------------------------------------------------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1: Spin up a temporary webserver &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;standalone&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2: Place files in webroot directory &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;webroot&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-------------------------------------------------------------------------------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Select the appropriate number &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;1-2&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;enter&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;press &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;c&amp;#39;&lt;/span&gt; to cancel&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When asked for the webroot, input &lt;code&gt;/var/www/html&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Select the webroot &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; your-domain.com:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-------------------------------------------------------------------------------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1: Enter a new webroot
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-------------------------------------------------------------------------------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Press &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;enter&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; to confirm the selection &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;press &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;c&amp;#39;&lt;/span&gt; to cancel&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Input the webroot &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; unicamp.br: &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Enter &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;c&amp;#39;&lt;/span&gt; to cancel&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: /var/www/html
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After this, the certificate files will be placed on &lt;code&gt;/etc/letsencrypt/live/your-domain.com&lt;/code&gt;&lt;/p&gt;
&lt;h1 id=&#34;allow-the-container-to-copy-files-to-the-host&#34;&gt;Allow the container to copy files to the host&lt;/h1&gt;
&lt;p&gt;Generate an SSH key &lt;strong&gt;inside the container&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ssh-keygen -t rsa
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Print the public key and copy it to the clipboard:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /root/.ssh/id_rsa.pub
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now append the container&amp;rsquo;s public key to the authorized_keys file &lt;strong&gt;in the host&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;echo &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;PASTE THE COPIED KEY HERE&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &amp;gt;&amp;gt; /root/.ssh/authorized_keys
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will allow the container to copy the certificates to the host using &lt;code&gt;scp&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&#34;applying-the-certificates-in-haproxy&#34;&gt;Applying the certificates in HAProxy&lt;/h1&gt;
&lt;p&gt;To use them in HAProxy, we must concatenate some files. Replace &lt;code&gt;your-domain.com&lt;/code&gt; accordingly.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /etc/letsencrypt/live/your-domain.com/privkey.pem &amp;gt; /etc/letsencrypt/live/your-domain.com/haproxy.key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat /etc/letsencrypt/live/your-domain.com/cert.pem /etc/letsencrypt/live/your-domain.com/chain.pem /etc/letsencrypt/live/your-domain.com/privkey.pem &amp;gt; /etc/letsencrypt/live/your-domain.com/haproxy.pem
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Set the permissions properly:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chmod &lt;span style=&#34;color:#ae81ff&#34;&gt;640&lt;/span&gt; /etc/letsencrypt/live/your-domain.com/haproxy.key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chmod &lt;span style=&#34;color:#ae81ff&#34;&gt;644&lt;/span&gt; /etc/letsencrypt/live/your-domain.com/haproxy.pem
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Still inside the horizon container, copy the files we just generated to the host. Replace &lt;code&gt;your-domain.com&lt;/code&gt; and &lt;code&gt;HOST_IP_ADDRESS&lt;/code&gt; accordingly.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;scp /etc/letsencrypt/live/your-domain.com/haproxy.* HOST_IP_ADDRESS:/etc/ssl/private
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now &lt;strong&gt;exit the container&lt;/strong&gt; and apply the new certificate:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;service haproxy reload
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;secure.png&#34; alt=&#34;Secure&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;renewing-the-certificates-automatically&#34;&gt;Renewing the certificates automatically&lt;/h1&gt;
&lt;p&gt;As Let’s Encrypt certificates are only valid for 90 days, it is highly advisable to schedule automatic renewing. We can do this using crontab inside the horizon container.&lt;/p&gt;
&lt;p&gt;Attach to the horizon container. Replace the container name accordingly with your setup. If you don’t know the name, run &lt;code&gt;lxc-ls | grep horizon&lt;/code&gt; to get the container name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lxc-attach -n infra1_horizon_container-XXXXXXXX
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Open the crontab editor:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;crontab -e
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Place this line at the end of the file, replacing &lt;code&gt;your-domain.com&lt;/code&gt; and &lt;code&gt;HOST_IP_ADDRESS&lt;/code&gt; accordingly.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;26 3 * * 5 certbot renew &amp;amp;&amp;amp; cat /etc/letsencrypt/live/your-domain.com/privkey.pem &amp;gt; /etc/letsencrypt/live/your-domain.com/haproxy.key &amp;amp;&amp;amp; cat /etc/letsencrypt/live/your-domain.com/cert.pem /etc/letsencrypt/live/your-domain.com/chain.pem /etc/letsencrypt/live/your-domain.com/privkey.pem &amp;gt; /etc/letsencrypt/live/your-domain.com/haproxy.pem &amp;amp;&amp;amp; scp /etc/letsencrypt/live/your-domain.com/haproxy.* HOST_IP_ADDRESS:/etc/ssl/private &amp;amp;&amp;amp; ssh HOST_IP_ADDRESS service haproxy reload
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will run every week, but it will only actually renew the certificate at most every 60 days, as only certificates that expire in less than 30 days are renewed. Running it more often than every 60 days makes it safer, as even if it fails to run once after the 60 days window, it will still run again before the certificate expire.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Install and initial configuration Buildbot on Fedora, Ubuntu and Debian</title>
      <link>https://openpower.ic.unicamp.br/post/buildbot-tutorial/</link>
      <pubDate>Fri, 22 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/buildbot-tutorial/</guid>
      <description>&lt;p&gt;Buildbot its tool to automate compilation and tests. This tutorial we will install it on three important distro and run it.&lt;/p&gt;
&lt;h1 id=&#34;1---installation-dependencies&#34;&gt;1 - Installation dependencies:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Installation of necessary packages to correct installation of Buildbot bundle.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;fedora-25&#34;&gt;Fedora 25:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo dnf install python-devel python-pip redhat-rpm-config make gcc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;fedora-26&#34;&gt;Fedora 26:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo dnf install python-pip redhat-rpm-config make gcc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ubuntu-and-debian&#34;&gt;Ubuntu and Debian:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get install Python-dev build-essential python-pip
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;2---installation-without-virtualenv&#34;&gt;2 - Installation without virtualenv:&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo pip install --upgrade pip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo pip install &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;buildbot[bundle]&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo pip install buildbot-grid-view
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo pip install buildbot-worker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo pip install setuptools-trial
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;25---installation-with-virtualenv-optional&#34;&gt;2.5 - Installation with virtualenv (optional):&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;First we need install virtual environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;fedora&#34;&gt;Fedora:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo dnf install python-virtualenv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ubuntu-and-debian-1&#34;&gt;Ubuntu and Debian:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install python-virtualenv
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Now we need activate the environment&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;virtualenv --no-site-packages YourSandbox
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;source YourSandbox/bin/activate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;instalation&#34;&gt;Instalation:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install --upgrade pip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;buildbot[bundle]&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install buildbot-grid-view
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install buildbot-worker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install setuptools-trial
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;3--initial-master-setup&#34;&gt;3- Initial Master setup:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Creation of folder where Buildbot archives will stay:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p BuildBot
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd BuildBot
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Creation of Master with name&lt;code&gt;[master]&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;buildbot create-master master
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;Create-master.png&#34; alt=&#34;Create Master&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The configuration of all functions of Buildbot its done in configuration file inside Master folder, to simplify we will use the sample configuration file provided in default template of Master &lt;code&gt;[master.cfg.sample]&lt;/code&gt;, but it’s needed be renamed to &lt;code&gt;[master.cfg]&lt;/code&gt; to be recognized by Buildbot:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv master/master.cfg.sample master/master.cfg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Here we will start Master daemon:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;buildbot start master
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;Start-master.png&#34; alt=&#34;Start Master&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;4--initial-worker-setup&#34;&gt;4- Initial Worker setup:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Here we will create a worker (previously slave) with name &lt;code&gt;[worker]&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;buildbot-worker create-worker worker localhost example-worker pass
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;Create-start-Worker.png&#34; alt=&#34;Create start Worker&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-command-syntax&#34;&gt;The command syntax:&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;* buildbot-worker = Buildbot Worker program.
* create-worker = Command to creation of Worker
* worker = Name of worker folder
* localhost = Master location on the network (This example Master are in the same VM)
* example-worker = Name of worker
* pass = Authentication password
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Start of worker daemon:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    buildbot-worker start worker
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Access address &lt;a href=&#34;http://localhost:8010/&#34;&gt;http://localhost:8010/&lt;/a&gt; on your browser.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;Buildbot-interface.png&#34; alt=&#34;Buildbot interface&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to OpenCL2CUDA</title>
      <link>https://openpower.ic.unicamp.br/post/opencl2cuda/</link>
      <pubDate>Wed, 07 Jun 2017 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/opencl2cuda/</guid>
      <description>&lt;h1 id=&#34;introduction-to-opencl2cuda&#34;&gt;Introduction to OpenCL2CUDA&lt;/h1&gt;
&lt;p&gt;We all know that software is replacing many people functions. Said that, many very complicated data processing
are now made by computers, that are getting better and better ways to do those tasks. There are many libraries
and frameworks that helps programmers and engineers writing code to process some big amount of data. Two of these
well known libraries are OpenCL, developed for heterogeneous computing (gpu, processors, fpga), and CUDA, a NVIDIA
library created so people can write code to run on their GPUs. These libraries have some similar routines, cause there 
are many steps you have to do on both of them. Thinking about it, I started writing a OpenCL to CUDA converter.&lt;/p&gt;
&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;
&lt;p&gt;The implementation of this code still really simple, since all I am doing is searching for some OpenCL functions and
replacing it for its equivalent on CUDA. Besides, if its not a direct translation, the converter suggests some possible fixes
for you code. To find the suggestions on your code search for the #tranlation# word. We are using Python 3. To run this code 
all you have to do is:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;chmod +x createCUDAkernel.py (just the first time)
./createCUDAkernel.py --opencl_name=&amp;#34;name of the opencl file&amp;#34; --main_name=&amp;#34;name of the C/C++ file&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;how-to-contribute&#34;&gt;How to contribute&lt;/h2&gt;
&lt;p&gt;Now, I am searching for CUDA and OpenCL codes that do the same thing, so I can go on this project. Besides, you can 
&lt;a href=&#34;https://github.com/Guilhermeslucas/OpenCL2CUDA&#34;&gt;fork&lt;/a&gt; the project on Github.&lt;/p&gt;
&lt;p&gt;Thanks a lot.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to PowerGraph</title>
      <link>https://openpower.ic.unicamp.br/post/powergraph/</link>
      <pubDate>Tue, 30 May 2017 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/powergraph/</guid>
      <description>&lt;h1 id=&#34;introduction-to-powergraph&#34;&gt;Introduction to PowerGraph&lt;/h1&gt;
&lt;p&gt;As computers evolve, people are trying new methods do analyse how good some machine
is when compared to another one. The amount of energy that some machine is 
consuming, seems to be a nice measure, once we are willing to produce faster and
cheaper. 
IPMI(Intelligent Platform Management Interface), on the other side,
is a set of computer interface specifications for an autonomous computer 
subsystem that provides management and monitoring capabilities independently 
of the host system. One of the measures that IPMI allow us to do is:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dcmi power reading
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This command shows the instant power consumption. With this tools, my team decided
to create a software that gets informations about the consumption of a machine
and exports it on a readable way. Thats how we did it:&lt;/p&gt;
&lt;h2 id=&#34;infrastructure&#34;&gt;Infrastructure&lt;/h2&gt;
&lt;p&gt;The infrastructure was not so complicated to configure. We have to download some
packages and set some configurations (process we are automating with Ansible). All
the system is deployed on Minicloud. The packages (all via apt) we are using are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ipmitool&lt;/li&gt;
&lt;li&gt;apache2&lt;/li&gt;
&lt;li&gt;python2.7&lt;/li&gt;
&lt;li&gt;python-pip&lt;/li&gt;
&lt;li&gt;git&lt;/li&gt;
&lt;li&gt;htop&lt;/li&gt;
&lt;li&gt;tmux&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Besides, we are using &lt;code&gt;crontab&lt;/code&gt; to be sure our service is still runing, and if 
it is not, restart it. We are doing this verification every ten minutes with the
&lt;code&gt;killer.sh&lt;/code&gt; script. 
To solve all &lt;code&gt;Python&lt;/code&gt; dependencies you can run:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;apache-configurations&#34;&gt;Apache configurations&lt;/h3&gt;
&lt;p&gt;Here you will install two modules in your apache server and change the virtual
host configuration file. Doing this you will be able to control your browser&amp;rsquo;s cache.&lt;/p&gt;
&lt;p&gt;In your server terminal run:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo a2enmod headers
sudo a2enmod expires
sudo service apache2 restart
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that, find your virtual host configuration file
(&lt;em&gt;/etc/apache2/sites-available/default/000-default.conf&lt;/em&gt; if you are using ubuntu OS)
and insert the following lines, adjusting the parameters according to your needs:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;lt;Directory /var/www/html&amp;gt;
   ExpiresActive On
   ExpiresDefault &amp;#34;access plus 10 minutes&amp;#34;
   ExpiresByType text/html &amp;#34;access plus 1 day&amp;#34;
   ExpiresByType text/javascript &amp;#34;access plus 1 day&amp;#34;

   # if it is your interest, you can set a specific expiration time for your csv file
   # ExpiresByType text/csv &amp;#34;access plus 30 seconds&amp;#34;

   &amp;lt;FilesMatch &amp;#34;file.csv&amp;#34;&amp;gt;
         Header set Cache-control &amp;#34;no-cache&amp;#34;
   &amp;lt;/FilesMatch&amp;gt;
&amp;lt;/Directory&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;back-end-code&#34;&gt;Back-end code&lt;/h2&gt;
&lt;p&gt;PowerGraph was totally developed using &lt;code&gt;Python&lt;/code&gt;. There are three main codes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;powergraph.py&lt;/li&gt;
&lt;li&gt;graph_csv.py&lt;/li&gt;
&lt;li&gt;csvcreator.py&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below, I will explain each code and its function.&lt;/p&gt;
&lt;h3 id=&#34;powergraphpy&#34;&gt;powergraph.py&lt;/h3&gt;
&lt;p&gt;This is the code that keeps getting power info about a machine and save it to 
&lt;code&gt;tinyDB&lt;/code&gt; or prompt the result to user. You can run it using the command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;python2.7 powergraph.py --host=&amp;#34;server address&amp;#34; --port=&amp;#34;server port&amp;#34; 
--user=&amp;#34;allowed user&amp;#34; --passwd=&amp;#34;password for this user&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can use the optional parameter &lt;code&gt;--store&lt;/code&gt; in order to save the infos 
as json on tinydb. Without this parameter, the script will print on the terminal. 
Besides, you can use &lt;code&gt;--feedback&lt;/code&gt; with store in order to see the measures 
status. 
If you want to set the time interval that a new csv file is generated, you can 
use the flag &lt;code&gt;--csv_interval&lt;/code&gt;. The &lt;code&gt;--tail_length&lt;/code&gt; is used to set the 
number of lines the csv file will have.&lt;/p&gt;
&lt;h3 id=&#34;csvcreatorpy&#34;&gt;csvcreator.py&lt;/h3&gt;
&lt;p&gt;This is the code that converts the JSON stored on &lt;code&gt;tinyDB&lt;/code&gt; for a &lt;code&gt;csv&lt;/code&gt;
file. This code is really important, cause our front end is expecting a &lt;code&gt;csv&lt;/code&gt; 
with two columns: timestamp and consumption.
In order to run this code, you have to store the data of &lt;code&gt;powergraph.py&lt;/code&gt; on the
database, as we explained before. To run this use:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;python2.7 csvcreator.py --jsonfile=&amp;#34;generated_json_name&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are two optional arguments: &lt;code&gt;--date&lt;/code&gt;, to create the csv only with 
the data from a specific day and &lt;code&gt;--name&lt;/code&gt;, with the name you want your 
&lt;code&gt;csv&lt;/code&gt; file.&lt;/p&gt;
&lt;h3 id=&#34;graph_csvpy&#34;&gt;graph_csv.py&lt;/h3&gt;
&lt;p&gt;This is the code that orchestrates the other ones. It is a multithread code that 
creates one thread always running with the &lt;code&gt;powergraph.py&lt;/code&gt; code and another 
one generating a new thread with &lt;code&gt;csvcreator&lt;/code&gt; running from time to time
updating the measures. To run this code use:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;python2.7 graph_csv.py --host=&amp;#34;server address&amp;#34; --port=&amp;#34;server port&amp;#34; 
--user=&amp;#34;allowed user&amp;#34; --passwd=&amp;#34;password for this user&amp;#34; 
--jsonfile=&amp;#34;path to bd jsonfile&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Besides, you can use the following optional arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;interval: interval between each ipmi measure (default=10)&lt;/li&gt;
&lt;li&gt;nread: number of ipmi measures to be done (default=infinity)&lt;/li&gt;
&lt;li&gt;csv_interval: interval that a new csv file is made (deafult=300s)&lt;/li&gt;
&lt;li&gt;tail_length: size of the csv files (default=300)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;front-end-code&#34;&gt;Front-end code&lt;/h2&gt;
&lt;p&gt;In order to create an interactive website that plot a graph from the csv file,
you first need to deal with the following dependencies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;apache configurations&lt;/li&gt;
&lt;li&gt;javascript libraries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After that, we have developed the code in &lt;strong&gt;javascript/graph.js&lt;/strong&gt; where
you can read and present in real time the data provided by the back-end.&lt;/p&gt;
&lt;h3 id=&#34;javascript-libraries&#34;&gt;Javascript libraries&lt;/h3&gt;
&lt;p&gt;Here we have three libraries included in our html file (index.html).&lt;/p&gt;
&lt;p&gt;The first one is the &lt;strong&gt;D3.js&lt;/strong&gt; library, a worldwide known tool to create
dynamic and interactive data visualizations, in other words, this is the engine
of the website. Insert in your html body the &lt;code&gt;&amp;lt;script src=&amp;quot;http://d3js.org/d3.v4.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;
to get the most recent code from D3.js.&lt;/p&gt;
&lt;p&gt;The next library, &lt;strong&gt;Moment.js&lt;/strong&gt;, is used to manipulate date objects and in our
case, for example, it allows us to show the time adjusted to the user&amp;rsquo;s location.
You can download the code from the following address &lt;a href=&#34;https://momentjs.com/downloads/moment.min.js&#34;&gt;https://momentjs.com/downloads/moment.min.js&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Finally, the &lt;strong&gt;D3-tip&lt;/strong&gt; library just inserts tooltips in the graph for a better experience of use. This library was donwloaded from &lt;a href=&#34;https://github.com/Caged/d3-tip/blob/master/index.js&#34;&gt;https://github.com/Caged/d3-tip/blob/master/index.js&lt;/a&gt;. It is also interesting that you take a look our style implementation for the tooltips from the file &lt;strong&gt;style/style.css&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you want to see the project working, acces this 
&lt;a href=&#34;http://oplab134.parqtec.unicamp.br/powergraph&#34;&gt;link&lt;/a&gt;. If you want to contribute, acces the 
&lt;a href=&#34;https://github.com/Unicamp-OpenPower/powergraph&#34;&gt;github link&lt;/a&gt;. Hope you all enjoy 
it. Thanks a lot!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Acessing a Docker Container outside Minicloud</title>
      <link>https://openpower.ic.unicamp.br/post/external_docker/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/external_docker/</guid>
      <description>&lt;p&gt;#Acessing a Docker Container outside Minicloud
Docker containers are widely used nowadays for making software development and delivery easier, since it isolates the container from the rest of the system. This is very useful, cause the developer can install any software, depencies to run the project perfectly, delivering the &amp;ldquo;whole package&amp;rdquo; to anyone who wants to run it.
Some applications are expected to access or be accessed from outside, like a webserver, Jenkins, and so on. To do it, you have to map a container port with a server port.&lt;/p&gt;
&lt;h2 id=&#34;maping-a-container-port-with-a-server-port&#34;&gt;Maping a Container port with a server port&lt;/h2&gt;
&lt;p&gt;Is very simple and useful to do it. All you have to do is to include a parameter on command line when launching a container with &lt;code&gt;docker run&lt;/code&gt;, like this example running a Jenkins container:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker run -i -t -p &amp;#34;physical machine port&amp;#34;:&amp;#34;container port&amp;#34; guilhermeslucas/jenkins:2.0 /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this example Jenkins container is running through port &amp;ldquo;container port&amp;rdquo; and you can access it by reaching the &amp;ldquo;physical machine port&amp;rdquo; of the server.&lt;/p&gt;
&lt;h2 id=&#34;acessing-docker-container-from-a-local-browser&#34;&gt;Acessing Docker Container from a local browser&lt;/h2&gt;
&lt;p&gt;Some applications are configured or managed using the browser. In this case, you can run the application on a server, but configure it using a ssh tunnel on your local machine. This is very simple too, just add a parameter on the ssh command line, mapping it correctly, like the example.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh user@host -L local-port:host:remote-port
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;it can be used like:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh guilherme@123.456.78.910 -L 8080:localhost:8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this example, the 8080 remote port will be forward to &lt;code&gt;localhost:8080&lt;/code&gt; and you can access it via browser.&lt;/p&gt;
&lt;p&gt;So, you&amp;rsquo;ll have to map a container port with a server port and forward this server port on your localhost, on any port not in use.&lt;/p&gt;
&lt;p&gt;This should do the work.&lt;/p&gt;
&lt;p&gt;Written by Guilherme Lucas. You can see some of my work at my &lt;a href=&#34;https://github.com/Guilhermeslucas&#34;&gt;Github Page&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Brief tutorial about how to use the SDAccel service</title>
      <link>https://openpower.ic.unicamp.br/post/sdaccel/</link>
      <pubDate>Thu, 06 Oct 2016 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/sdaccel/</guid>
      <description>&lt;h1 id=&#34;how-to-use-the-sdaccel-service&#34;&gt;How to use the SDAccel Service&lt;/h1&gt;
&lt;p&gt;SDAccel is a service that allow the user to load C/C++ aplications and optmize it using FPGA acceleration.
To use this service, first go to the link below:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;https://ny1.ptopenlab.com/sdaccel/auth/login/?next=/sdaccel/project/#/projects/b767365a-8402-41a5-97b4-d148c359b114/detail?_k=p64eew
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this page, you can enter your username and password to log in the SDAccel service. If you do not have on account,
just create one and get back to that link.&lt;/p&gt;
&lt;p&gt;You will be redirect to a page with the following tabs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Overview&lt;/em&gt; : this page contains some explanation about how the SDAccel is built and the advantages of using a service like that.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Document&lt;/em&gt; : tutorials about SDAccel and some C/C++ code to run.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Project&lt;/em&gt; : manage your projects and upload some code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To create a new project, go to &lt;em&gt;Project&lt;/em&gt; -&amp;gt; &lt;em&gt;New Project&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Just put a any name and description and press &lt;em&gt;Submit&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Click on the project name (that should be blue) and you wil be redirect to a files page.&lt;/p&gt;
&lt;p&gt;Go to the &lt;em&gt;compile&lt;/em&gt; tab and wait a little till the loading is finished and, the &lt;em&gt;console password&lt;/em&gt; on the password place and hit &lt;em&gt;Enter&lt;/em&gt;.
A desktop environment will appear on the screen.&lt;/p&gt;
&lt;p&gt;Now, on the virtualized desktop, go to &lt;em&gt;Applications&lt;/em&gt; -&amp;gt; &lt;em&gt;System Tools&lt;/em&gt; -&amp;gt; &lt;em&gt;Terminal&lt;/em&gt;. Now type the following commands:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd
mkdir test
cd test
git clone https://github.com/Guilhermeslucas/SDAccel_Examples.git
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, close the terminal and click on the &lt;em&gt;SDAccel Icon&lt;/em&gt; on the desktop, and hit ok on the first window and &lt;em&gt;close the welcome tab&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;On the &lt;em&gt;Project Explorer&lt;/em&gt; -&amp;gt; &lt;em&gt;New&lt;/em&gt; -&amp;gt; &lt;em&gt;Xilinx SDAccel Project&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now, enter any string to be the &lt;em&gt;Project Name&lt;/em&gt; and change the locarion for the folder you placed the vadd project(just the &lt;em&gt;src&lt;/em&gt; folder, from de &lt;em&gt;SDACell_Examples&lt;/em&gt;.
I will name the project as &lt;em&gt;tutorial_code&lt;/em&gt;.
The next step, is to click with the right button of the button on the &lt;em&gt;project folder&lt;/em&gt; and hit &lt;em&gt;build project&lt;/em&gt;. It will ask you to create a solution.
Go ahed and create one. In order to do that click on &lt;em&gt;add&lt;/em&gt;(change the name if you want) -&amp;gt; &lt;em&gt;ok&lt;/em&gt; -&amp;gt; &lt;em&gt;&amp;raquo;&lt;/em&gt; -&amp;gt; &lt;em&gt;ok&lt;/em&gt;
Now, try to build the project again as we said above (it should take some seconds).&lt;/p&gt;
&lt;p&gt;Now, open a &lt;em&gt;terminal&lt;/em&gt; and go to the &lt;em&gt;src&lt;/em&gt; folder for the project we are using. In that folder, should appear o .tcl file. Type:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sdaccel &amp;#34;some_name&amp;#34;.tcl
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It will run and the results will appear on the folder.&lt;/p&gt;
&lt;p&gt;Note: if you prefer a &lt;a href=&#34;https://www.youtube.com/watch?v=3pFlAyPXCKo&#34;&gt;video tutorial on YouTube&lt;/a&gt;, Bruno made a really good one.&lt;/p&gt;
&lt;p&gt;Hope it was helpful.&lt;/p&gt;
&lt;p&gt;Post written by Guilherme Lucas.
You can see some of my work at &lt;a href=&#34;https://github.com/Guilhermeslucas&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting Up SuperVessel and SSH connection to Machines on Debian Based</title>
      <link>https://openpower.ic.unicamp.br/post/supervessel/</link>
      <pubDate>Fri, 19 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/supervessel/</guid>
      <description>&lt;h1 id=&#34;setting-up-supervessel-and-ssh-connection-to-the-machines-on-debian-based&#34;&gt;Setting Up SuperVessel and SSh connection to the Machines on Debian Based&lt;/h1&gt;
&lt;p&gt;SuperVessel is a cloud based plataform created by IBM Research - China
It allows you to set up containers on the cloud to run experiments, 
test aplications, do some data analysis and so on. One great feature
of SuperVessel is to allow FPGA and GPU acelleration for C/C++
aplications.&lt;/p&gt;
&lt;h2 id=&#34;creating-an-acount-on-supervessel&#34;&gt;Creating an acount on SuperVessel&lt;/h2&gt;
&lt;p&gt;First, go to the page below:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;https://ptopenlab.com/cloudlabconsole/?cm_mc_uid=35942743919214714482383&amp;amp;cm_mc_sid_50200000=1471628149#/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When you reach this adress, you will see that the first item of the
Service Zone is for &lt;strong&gt;SuperVessel Cloud&lt;/strong&gt;. Click on &lt;strong&gt;Apply VM -&amp;gt; Direct Acces&lt;/strong&gt;.
After doing that, you can &lt;strong&gt;login&lt;/strong&gt;, or &lt;strong&gt;create an account&lt;/strong&gt;. You can login as &lt;strong&gt;Community user&lt;/strong&gt; . Do one of these
steps and you have an SuperVessel account. This wil allow you to use all the other services on the page, like Acceleration and Big Data Services.&lt;/p&gt;
&lt;h2 id=&#34;setting-up-a-machine&#34;&gt;Setting up a Machine&lt;/h2&gt;
&lt;p&gt;After creating an account, you&amp;rsquo;re good to launch a machine. On the left side of the page, click on &lt;strong&gt;Instances&lt;/strong&gt;. On the up menu of the page, there is a &lt;strong&gt;Current Region&lt;/strong&gt; box. Make sure it is assigned to Beijing so we can access the machines via SSH easily.
Now, click on &lt;strong&gt;Launch Instance&lt;/strong&gt;. This should redirect you to a page with the specs of the machine on it. On the first drop-down menu, select &lt;strong&gt;Launch Docker Image&lt;/strong&gt; and choose the specs that best fit your needs and then click on the button on the bottom of the forms to launch the instance and wait. It will appear a box with the instance&amp;rsquo;s information. If you want to access the machine from the browser, go to &lt;strong&gt;More Actions -&amp;gt; Console&lt;/strong&gt;. The informations to log in appear on the top of the terminal.&lt;/p&gt;
&lt;h2 id=&#34;connecting-vpn&#34;&gt;Connecting VPN&lt;/h2&gt;
&lt;p&gt;First, install the VPNC:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get install vpnc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, create a SuperVessel conf file with the following command:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo vim /etc/vpnc/supervessel.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note: you can use any editor, just don&amp;rsquo;t forget to run with sudo or as root user.
The content of this file has to be:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;IPSec gateway 36.110.51.131
IPSec ID Gemini    
IPSec secret G3m!ni1bmVpn           
Xauth username PoXXXX (change PoXXXX to your own VPN account)    
Xauth password secret_password (change secret_passsword to your own VPN password) 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Xauth username and password have to be changed to your personal informattion, that you can find at the person symbol ate the upper left of the SuperVessel page, that you used to create an instance. Click on &lt;strong&gt;VPN Conf&lt;/strong&gt; and put the Beijing fields on the &lt;strong&gt;supervessel.conf&lt;/strong&gt; file.
Now, run the vpnc:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo vpnc-connect supervessel.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A message like that should appear:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;VPNC started in background (pid: 12434)...
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;running-ssh&#34;&gt;Running SSH&lt;/h2&gt;
&lt;p&gt;Now, on the &lt;strong&gt;Instances&lt;/strong&gt; page, find the &lt;strong&gt;External IP(VPN)&lt;/strong&gt; field. Now run:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh opuser@ExternalIP 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note: change ExternalIP with the number you just saw. You can use ssh -X to xforward and ssh -C to compress connection.&lt;/p&gt;
&lt;p&gt;After you logout, don&amp;rsquo;t forget to run :&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo vpnc-disconnect
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That should do the work!&lt;/p&gt;
&lt;p&gt;Post written by Guilherme Lucas.
You can see some of my work at &lt;a href=&#34;https://github.com/Guilhermeslucas&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a continuous integration platform using Jenkins and GitHub</title>
      <link>https://openpower.ic.unicamp.br/post/building-a-continuous-integration-platform-using-jenkins-and-github/</link>
      <pubDate>Wed, 15 Jun 2016 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/building-a-continuous-integration-platform-using-jenkins-and-github/</guid>
      <description>&lt;p&gt;Continuous integration allows code to be tested automatically every time it’s changed, detecting errors as early as possible. In this tutorial a CI using a GitHub repository will be approached.&lt;/p&gt;
&lt;h1 id=&#34;step-1-installing-and-setting-up-jenkins-and-git&#34;&gt;Step 1: Installing and setting up Jenkins and Git&lt;/h1&gt;
&lt;p&gt;To install Jenkins, execute the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add -
sudo sh -c &#39;echo deb http://pkg.jenkins.io/debian-stable binary/ &amp;gt; /etc/apt/sources.list.d/jenkins.list&#39;
sudo apt-get update
sudo apt-get install jenkins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To install git, simply execute:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Access Jenkins through http://localhost:8080 and follow the instructions for the initial setup. Choose &lt;strong&gt;Install suggested plugins&lt;/strong&gt; when asked.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plugins.png&#34; alt=&#34;Plugins&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;step-2-creating-a-job&#34;&gt;Step 2: Creating a job&lt;/h1&gt;
&lt;p&gt;In Jenkins dashboard, click on &lt;strong&gt;New Item&lt;/strong&gt;, give your project a name and select &lt;strong&gt;Freestyle project&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You may choose &lt;strong&gt;Discard old builds&lt;/strong&gt; in order to avoid using too much storage in the long term.&lt;/p&gt;
&lt;p&gt;Check &lt;strong&gt;GitHub project&lt;/strong&gt; and enter the GitHub URL of the project. Use the format &lt;em&gt;&lt;a href=&#34;https://github.com/YOUR-USERNAME/YOUR-REPOSITORY&#34;&gt;https://github.com/YOUR-USERNAME/YOUR-REPOSITORY&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In source code management section, choose &lt;strong&gt;Git&lt;/strong&gt; and enter the repository URL the same way as above.&lt;/p&gt;
&lt;h2 id=&#34;step-21-choosing-the-build-trigger&#34;&gt;Step 2.1: Choosing the build trigger&lt;/h2&gt;
&lt;p&gt;Under &lt;strong&gt;Build Triggers&lt;/strong&gt; it is possible to choose to build periodically or when a change is pushed into GitHub. Although building only when GitHub changes is more efficient, it is required to your Jenkins server to be accessible through the internet, and the you must own the repository. Building periodically may waste resources, but it is simpler to configure.&lt;/p&gt;
&lt;h3 id=&#34;step-211-build-periodically&#34;&gt;Step 2.1.1: Build Periodically&lt;/h3&gt;
&lt;p&gt;Check &lt;strong&gt;Build Periodically&lt;/strong&gt; and define the period using the proper syntax found when clicking the &lt;strong&gt;?&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Complete the job creating by adding a build step (e.g. a shell script to compile and run a test) and jump to step 4&lt;/p&gt;
&lt;p&gt;The test input and expected output should be in the repository.&lt;/p&gt;
&lt;h3 id=&#34;step-212-build-when-a-change-is-pushed-into-github&#34;&gt;Step 2.1.2: Build when a change is pushed into GitHub&lt;/h3&gt;
&lt;p&gt;Check build when a change is pushed into GitHub&lt;/p&gt;
&lt;p&gt;Complete the job creating by adding a build step (e.g. a shell script to compile and run a test) and follow to step 3&lt;/p&gt;
&lt;p&gt;The test input and expected output should be in the repository.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;job_configuration.png&#34; alt=&#34;Job Configuration&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;step-3-configuring-github-plugin---skip-if-building-periodically&#34;&gt;Step 3: Configuring GitHub plugin - Skip if building periodically&lt;/h1&gt;
&lt;p&gt;Go to &lt;strong&gt;Manage Jenkins&lt;/strong&gt; → &lt;strong&gt;Configure System&lt;/strong&gt; → &lt;strong&gt;GitHub&lt;/strong&gt; section → &lt;strong&gt;Advanced&lt;/strong&gt; → &lt;strong&gt;Manage additional GitHub Actions&lt;/strong&gt; → &lt;strong&gt;Convert login and password to token&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A new sub-section will appear right above.&lt;/p&gt;
&lt;p&gt;Select &lt;strong&gt;From login and password&lt;/strong&gt;, fill your login and password from GitHub and press &lt;strong&gt;Create token credentials&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;create_token.png&#34; alt=&#34;Create Token&#34;&gt;&lt;/p&gt;
&lt;p&gt;Above this sub-section, click &lt;strong&gt;Add GitHub server&lt;/strong&gt;. Keep the &lt;strong&gt;API URL&lt;/strong&gt; unchanged.&lt;/p&gt;
&lt;p&gt;Under &lt;strong&gt;Credentials&lt;/strong&gt; dropdown menu, select the token just created and test your connection.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;github_server.png&#34; alt=&#34;Github Server&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;step-4-testing-it&#34;&gt;Step 4: Testing it&lt;/h1&gt;
&lt;p&gt;If using periodical build, click the &lt;strong&gt;Build now&lt;/strong&gt; icon to test. If the test fails, check the console output to find the issue (e.g. missing compiler).&lt;/p&gt;
&lt;p&gt;If using GitHub trigger, change a file in the repository. The build should start automatically in a few seconds.&lt;/p&gt;
&lt;h1 id=&#34;step-5-adding-slave-machines---optional&#34;&gt;Step 5: Adding slave machines - Optional&lt;/h1&gt;
&lt;p&gt;As your projects grow, you may run out of resources in your machine. A possible solution is to add one or more slave machines, which will be responsible for building your projects, while the current machine will become the master and manage everything (the master will still be able to run jobs if desired).&lt;/p&gt;
&lt;p&gt;The slave machine doesn&amp;rsquo;t need Jenkins installed on it. There are many ways to connect the slave with the master, here, SSH will be used.&lt;/p&gt;
&lt;p&gt;Install Java and Git in the slave using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install default-jre
sudo apt-get install git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create a directory to be used by Jenkins, in this case will be the same path used by default in the master machine: /var/lib/jenkins&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo mkdir /var/lib/jenkins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Change the ownership of the directory to the same user used to login using SSH&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chown ubuntu:ubuntu /var/lib/jenkins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Back to the master machine:&lt;/p&gt;
&lt;p&gt;Go to &lt;strong&gt;Manage Jenkins&lt;/strong&gt; → &lt;strong&gt;Manage Nodes&lt;/strong&gt; → &lt;strong&gt;New Node&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Name your node and select &lt;strong&gt;Permanent Agent&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The recommended &lt;strong&gt;# of executors&lt;/strong&gt; is the number of cores in the slave machine&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Remote root directory&lt;/strong&gt; is the path to the directory created.&lt;/p&gt;
&lt;p&gt;If necessary to divide the slave machines into different groups, label them (e.g. the OS running in the machine, the CPU architecture)&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Launch method&lt;/strong&gt; used here will be SSH, but other methods are also fine.&lt;/p&gt;
&lt;p&gt;Simply enter your host and create a credential using your username and password, or username and private key.&lt;/p&gt;
&lt;p&gt;Press &lt;strong&gt;Save&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;slave_node.png&#34; alt=&#34;Slave Node&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-51-restricting-machines-where-projects-can-be-run&#34;&gt;Step 5.1: Restricting machines where projects can be run&lt;/h2&gt;
&lt;p&gt;If your slaves have different environments, your should restrict the machines where each project will run.&lt;/p&gt;
&lt;p&gt;Under the &lt;strong&gt;project&lt;/strong&gt; settings, check &lt;strong&gt;Restrict where this project can be run&lt;/strong&gt; and type the machine name, use a label, or even use a more complex rule using logical operators (click the &lt;strong&gt;?&lt;/strong&gt; for more information)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;restrict_where_this_project_can_be_run.png&#34; alt=&#34;Restrict where this project can be run&#34;&gt;&lt;/p&gt;
&lt;p&gt;To prevent the master machine to run projects, go to &lt;strong&gt;Manage Jenkins&lt;/strong&gt; → &lt;strong&gt;Manage Nodes&lt;/strong&gt; → &lt;strong&gt;master&lt;/strong&gt; → &lt;strong&gt;Configure&lt;/strong&gt; → &lt;strong&gt;# of executors&lt;/strong&gt; and set to 0.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Install IBM SDK on Ubuntu 16.04/14.04 Power Machines</title>
      <link>https://openpower.ic.unicamp.br/post/sdk/</link>
      <pubDate>Mon, 30 May 2016 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/sdk/</guid>
      <description>&lt;h1 id=&#34;downloading-packages&#34;&gt;Downloading Packages&lt;/h1&gt;
&lt;p&gt;You can use a script to download the necessary packages in the link above:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/at_downloader/?cm_mc_uid=92476109699314629396752&amp;amp;cm_mc_sid_50200000=1464625581
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Download the script and change its permission with the command above:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;chmod +x &amp;lt;script name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then run the script with:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./&amp;lt;script name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Please download the packages for Ubuntu 14.10. Then, the folder will be full of .deb
files. The next step is to install some of these packages using dpkg.&lt;/p&gt;
&lt;h1 id=&#34;instaling-packages-and-toolchain&#34;&gt;Instaling Packages and Toolchain&lt;/h1&gt;
&lt;p&gt;Now, you need to install some of these. This is simple, but you have to do it following
the order above. The command for each of those is&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dpkg -i &amp;lt;package name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The correct order is (the X is the version of the software):&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;advance-toolchain-atX.X-runtime-X.X-X
advance-toolchain-atX.X-devel-X.X-X
advance-toolchain-atX.X-perf-X.X-X
advance-toolchain-atX.X-mcore-libs-X.X-X
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can ignore the errors and move on.&lt;/p&gt;
&lt;h1 id=&#34;installing-ibm-sdk&#34;&gt;Installing IBM SDK&lt;/h1&gt;
&lt;p&gt;After all the dependencies issues are solved, download fdpr_wrap, fdpr-pro, pthread-mon, ibm-sdk-lop and ibm-sdk-lop-remote-dependencies on
this link:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;https://www-304.ibm.com/webapp/set2/sas/f/lopdiags/sdkdownload.html#4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Install each of these packages with dpkg again, running:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo dpkg -i &amp;lt;package name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;respecting the sequence above.&lt;/p&gt;
&lt;p&gt;Note: to run the ibm-sdk-loop on the Power Machines using ssh, you will have to connect 
to the server using&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh -XC -c blowfish-cbc,arcfour &amp;lt;user&amp;gt;@&amp;lt;host&amp;gt; -p &amp;lt;port_number&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The blowfish-cbc,arcfour will make your connection even better.
This command is necessary to xforward the image of the sdk running.
Note2: if you get the &amp;ldquo;no matching cipher found&amp;rdquo; error, here you go the solution:&lt;/p&gt;
&lt;p&gt;run the command above:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh -Q cipher localhost | paste -d , -s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now its time to change the sshd_config file on the server(super privileges needed).
Add on the /etc/ssh/sshd_config a line with:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Ciphers &amp;lt;output of the last command&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Reboot the machine to make this alterations running:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo shutdown -r now
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Post written by Guilherme Lucas.
You can see some of my work at &lt;a href=&#34;https://github.com/Guilhermeslucas&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimizing C/C&#43;&#43; applications</title>
      <link>https://openpower.ic.unicamp.br/post/sdk_opt/</link>
      <pubDate>Mon, 30 May 2016 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/sdk_opt/</guid>
      <description>&lt;h1 id=&#34;optimizing-cc-applications-with-ibm-sdk-build-advisor&#34;&gt;Optimizing C/C++ Applications with IBM SDK Build Advisor&lt;/h1&gt;
&lt;p&gt;This is a brief text about how to use the IBM SDK Build Advisor to optimize C/C++ aplications on Power Servers.
You can get the project and learn how to run on the link below:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;https://github.com/Guilhermeslucas/cmp
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;running-seismic-applications-without-optimization-flags&#34;&gt;Running seismic applications without optimization flags&lt;/h2&gt;
&lt;p&gt;Here are some results on Power Machine before the optimization process.&lt;br&gt;
real    0m46.837s&lt;br&gt;
real    0m48.391s&lt;br&gt;
real    0m52.570s&lt;br&gt;
real    0m49.249s&lt;br&gt;
real    0m48.863s&lt;/p&gt;
&lt;h2 id=&#34;importing-a-cc-project-to-ibm-sdk&#34;&gt;Importing a C\C++ Project to IBM SDK&lt;/h2&gt;
&lt;p&gt;Before you begin, make sure there is a Makefile inside your project. Now, inside the SDK:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;File &amp;gt; Import&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;In the import window, expand &lt;strong&gt;C\C++&lt;/strong&gt; and click in &lt;strong&gt;Existing Code as Makefile Project&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Now go to &lt;strong&gt;Browse&lt;/strong&gt; next to the &lt;strong&gt;Existing code Location&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Type a name for your project&lt;/li&gt;
&lt;li&gt;Locate the code and then click &lt;strong&gt;OK&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Back to the &lt;strong&gt;Import Existing Code&lt;/strong&gt; window, click the Advanced Toolchain Version corresponding to the one you have installed on the Power Machine.&lt;/li&gt;
&lt;li&gt;Click &lt;strong&gt;Finish&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;using-the-build-advisor&#34;&gt;Using the Build Advisor&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Right Click on the project, go to &lt;strong&gt;Properties&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Select the build advisor&lt;/li&gt;
&lt;li&gt;Enable &lt;strong&gt;Enable extra advice&lt;/strong&gt; and then &lt;strong&gt;Finish&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Right click on the project and build. The suggestions will appear.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;final-results&#34;&gt;Final results&lt;/h2&gt;
&lt;p&gt;After using the flags that the SDK suggested&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;-std=c99 -Ofast -fpeel-loops -flto -fopenmp -mcmodel=medium -ftree-vectorize -mcpu=power8 -mtune=power8 -funroll-loops
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I got the following results:&lt;br&gt;
real	0m3.177s&lt;br&gt;
real	0m2.573s&lt;br&gt;
real	0m3.066s&lt;br&gt;
real	0m2.954s&lt;br&gt;
real	0m2.930s&lt;/p&gt;
&lt;p&gt;As you can see, Build Advisor is very effective.&lt;/p&gt;
&lt;p&gt;Post written by Guilherme Lucas.
You can see some of my work at &lt;a href=&#34;https://github.com/Guilhermeslucas&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Instalação de Seismic Unix e Cmp_toy em arquitetura Intel</title>
      <link>https://openpower.ic.unicamp.br/post/ic/</link>
      <pubDate>Fri, 20 May 2016 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/ic/</guid>
      <description>&lt;h1 id=&#34;instalação-do-su-e-do-cmp_toy-na-máquina-pessoal&#34;&gt;Instalação do SU e do Cmp_toy na máquina pessoal&lt;/h1&gt;
&lt;h2 id=&#34;instalação-do-su&#34;&gt;Instalação do SU&lt;/h2&gt;
&lt;p&gt;Seismic Unix é um conjunto de ferramentas extremamente úteis para o processamento de dados sísmicos. Para instalá-lo no Ubuntu 14.04, precisei baixar algumas bibliotecas. Segue quais são e como instalá-las:&lt;/p&gt;
&lt;p&gt;&amp;lt;X11/Xlib.h&amp;gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get install libx11-dev
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&amp;lt;X11/Intrinsic.h&amp;gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;lt;X11/Intrinsic.h&amp;gt; - sudo apt-get install libxt-dev
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Também precisamos do CMake para completar a instalação do Seismic Unix. Rode:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get install cmake
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Link do repositório do cmp_toy:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;github.com/gga-cepetro/cmp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Agora para realmente terminar a instalção, basta rodar os seguintes comandos:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;install_dir=~/src/cwp
mkdir -p $install_dir &amp;amp;&amp;amp; cd $install_dir
export CWPROOT=$PWD
echo &amp;#34;export CWPROOT=$PWD&amp;#34; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;#39;export PATH=$PATH:$CWPROOT/bin&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
wget ftp://ftp.cwp.mines.edu/pub/cwpcodes/cwp_su_all_44R1.tgz
tar zxf cwp_su_all_44R1.tgz
cd src
sed -i &amp;#39;s/^XDRFLAG/#XDRFLAG/&amp;#39; Makefile.config
make install ; make xtinstall
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Agora para testar se o software, basta executar&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;suplane | suximage
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Uma imagem com três planos deve ser apresentada. Ela parece ser um pouco esquista, a princípio, mas se uma janela com uma imagem foi aberta, então a instalação foi realizada com sucesso.&lt;/p&gt;
&lt;h2 id=&#34;instalação-do-cmp_toy&#34;&gt;Instalação do cmp_toy&lt;/h2&gt;
&lt;p&gt;Agora para instalar o cmp_toy e obter as curvas desejadas, precisamos executar os seguintes comandos, após obter o cmp_toy.tar.gz :&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;tar -xzf cmp_toy.tar.gz
mkdir build
cd build
cmake ..
make
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Agora que o software está instalado, vamos testá-lo. É necessário mudar para o diretório pai desse que estamos e rodar o script de teste, que usa uma imagem criada extamente para esse teste:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd ..
./test-cmp.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A saída desse comando (ao completar 100%) deve seguir o seguinte padrão, com números possivelmente diferentes:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[100%] Processing CDP 300
real	0m56.573s
user	0m56.589s
sys	0m0.008s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Agora, para testar a imagem gerada, basta rodar o seguinte comando:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;suximage &amp;lt; cmp.stack.su
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;O output desse comando deve ser uma imagem com o plot de algumas curvas.&lt;/p&gt;
&lt;p&gt;Post escrito por Guilherme Lucas. 
Mais um pouco do meu trabalho no meu Github &lt;a href=&#34;https://github.com/Guilhermeslucas&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Instalação de Seismic Unix e Cmp_toy em arquitetura Power</title>
      <link>https://openpower.ic.unicamp.br/post/power/</link>
      <pubDate>Fri, 20 May 2016 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/power/</guid>
      <description>&lt;h1 id=&#34;tutorial-de-instalação-do-cmp_toy-em-máquinas-power&#34;&gt;Tutorial de instalação do cmp_toy em Máquinas Power&lt;/h1&gt;
&lt;p&gt;Esse é um breve tutorial de como foi para instalar e rodar o código sísmico cmp_toy nas máquinas Power, acessado pelo sistema de Minicloud.
Todo o processo foi feito usando uma máquina com Ubuntu 16.04 instalado, mas também deve funcionar em máquinas com sistemas Debian Based.&lt;/p&gt;
&lt;h2 id=&#34;resolução-de-problemas-nos-pacotes&#34;&gt;Resolução de problemas nos pacotes&lt;/h2&gt;
&lt;p&gt;Ao logar na máquina, tive alguns problemas com pacotes quebrados. Para arrumar esse problema usei os comandos comandos do dpkg e do apt-get, respectivamente:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo dpkg --configure -a
sudo apt-get -f install
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;primeiros-softwares-e-pacotes-necessários&#34;&gt;Primeiros Softwares e Pacotes necessários&lt;/h2&gt;
&lt;p&gt;O primeiro software que precisei, foi o editor de texto Vim, muito poderoso e eficiente, ainda mais quando estamos acessando uma máquina remotamente. Para instalá-lo basta executar:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get install vim
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Após copiar o meu .vimrc para a máquina remota, baixei os dois compiladores necessários para rodar o código. Pra esse, preciso do compilador de C e C++, e por preferências pessoais instalei o gcc e g++. Segue os comandos para instalação de cada um deles:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get install gcc
sudo apt-get install g++
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Link do repositório do cmp_toy:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;github.com/gga-cepetro/cmp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Durante a instalação é necessário rodar o CMake, que também não esta instalado. Para acertar esse problema, rode:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo apt-get install cmake
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Vale lembrar que todos os comandos desde o início do desse tutorial devem ser feitos logado na máquina remota.&lt;/p&gt;
&lt;h2 id=&#34;trocando-arquivos-remotamente-e-instalando-do-software&#34;&gt;Trocando arquivos remotamente e instalando do software&lt;/h2&gt;
&lt;p&gt;Como fazemos acesso às máquinas com o comando &lt;code&gt;ssh -p&lt;/code&gt; , ou seja, acessamos por meio de uma porta específica, temos que executar o comando scp de maneira diferente também, para copiar um arquivo local para uma máquina remota. Nesse caso, queremos copiar o arquivo cmp_toy.tar.gz (você deve estar no diretório desse arquivo, ou seja, na sua máquina física e não logado nas máquinas remotas).&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;scp -P &amp;lt;numero da porta&amp;gt; cmp_toy.tar.gz  seu_usuario@host_remoto:/algum/diretorio/remoto
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Agora, se conectado na máquina remota, e vá até o diretório onde mandou o arquivo. Voce deve encontrar o cmp_toy.tar.gz. Agora para instalá-lo, rode os seguintes comandos:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;tar -xzf cmp_toy.tar.gz
cd cmp_toy
mkdir build
cd build
cmake ..
make
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Agora que a instalação do software foi feita com sucesso, precisamos testá-lo. Para isso, basta ir para o diretório pai e rodar o script de teste, que usa uma imagem pronta para teste.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd ..
./test-cmp.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Após um tempinho, você deve receber uma saída que segue o seguinte padrão (não necessariamente com os mesmos números):&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[100%] Processing CDP 300

real	0m59.968s
user	0m59.908s
sys	0m0.056s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Basicamente, os passos são esses. Tentei fazer esse tutorial da maneira mais detalhada possível. Se ainda restarem dúvidas, não exitem em entrar em contato.&lt;/p&gt;
&lt;p&gt;Post escrito por Guilherme Lucas.
Mais um pouco do meu trabalho no meu Github &lt;a href=&#34;https://github.com/Guilhermeslucas&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up an OpenStack-based cloud with Power8 | Part 04 – Glance</title>
      <link>https://openpower.ic.unicamp.br/post/openstack_setup_4/</link>
      <pubDate>Wed, 16 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/openstack_setup_4/</guid>
      <description>&lt;p&gt;Glance is the Openstack Image Service and enables users to discover, register, and retrieve virtual machine images. This service allows users to query virtual machine images information and retrieve the image itself using a REST API and must be installed in the controller node.&lt;/p&gt;
&lt;p&gt;#Prerequisites&lt;/p&gt;
&lt;p&gt;Load the OpenRC file:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;source adm-credentiansl.sh 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create a database for Glance:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql -u root -p
CREATE DATABASE glance;
GRANT ALL PRIVILEGES ON glance.* TO &amp;#39;glance&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;glance&amp;#39;;
GRANT ALL PRIVILEGES ON glance.* TO &amp;#39;glance&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;glance&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create the keystone entities, service and endpoint:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;openstack user create --password-prompt glance
openstack role add --project service --user glance admin
openstack service create --name glance --description &amp;#34;OpenStack Image service&amp;#34; image
openstack endpoint create --publicurl http://controller:9292 \
          --internalurl http://controller:9292  --adminurl http://controller:9292 \
          --region RegionOne image
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Install and Configure&lt;/p&gt;
&lt;p&gt;Install the packages:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt-get install glance python-glanceclient 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Edit the file &lt;em&gt;/etc/glance/glance-api.cnf&lt;/em&gt; as following:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[DEFAULT]
...
notification_driver = noop
verbose = True

[database]
connection = mysql://glance:GLANCE_DBPASS@controller/glance

[keystone_authtoken]
auth_uri = http://controller:5000
auth_url = http://controller:35357
auth_plugin = password
project_domain_id = default
user_domain_id = default
project_name = service
username = glance
password = GLANCE_PASS

[paste_deploy]
flavor = keystone

[glance_store]
default_store = file
filesystem_store_datadir = /var/lib/glance/images/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Also edit the file &lt;em&gt;/etc/glance/glance-registry.cnf&lt;/em&gt;:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[DEFAULT]
...
notification_driver = noop
verbose = True

[database]
connection = mysql://glance:GLANCE_DBPASS@controller/glance
[keystone_authtoken]
auth_uri = http://controller:5000
auth_url = http://controller:35357
auth_plugin = password
project_domain_id = default
user_domain_id = default
project_name = service
username = glance
password = GLANCE_PASS

[paste_deploy]
flavor = keystone
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Populate the image service database:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;su -s /bin/sh -c &amp;#34;glance-manage db_sync&amp;#34; glance
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Finalize the installation process:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;service glance-registry restart
service glance-api restart
rm -f /var/lib/glance/glance.sqlite
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Greenlet Fix&lt;/p&gt;
&lt;p&gt;The Greenlet version that is in the Ubuntu repository has problems with PPC64le architecture, therefore we need to manually download and install a newer version of the library.&lt;/p&gt;
&lt;p&gt;Download and unpack the package code:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget https://github.com/python-greenlet/greenlet/archive/master.zip -D greenlet.zip
unzip greenlet.zip -D 
cd greenlet
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Install the package:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;export CFLAGS=-O1;
./setup.py install
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart the glance services:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;service glance-registry restart
service glance-api restart
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Upload an image to the Image Server&lt;/p&gt;
&lt;p&gt;Configure the server to use the API version 2.0 and reload the credentials:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;echo &amp;#34;export OS_IMAGE_API_VERSION=2&amp;#34; | tee -a adm-credentials.sh
source adm-credentials.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As an example upload Ubuntu 14.04.02 PPC64le to the server:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;glance image-create --name=&amp;#34;ubuntu1404-ppc64le&amp;#34; --disk-format=qcow2  --container-format=bare \
       --is-public=true \
       -copy-from https://cloud-images.ubuntu.com/releases/14.04/14.04.2/ubuntu-14.04-server-cloudimg-ppc64el-disk1.img
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check the list of images:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;glance image-list
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Setting up an OpenStack-based cloud with Power8 | Part 03 – Keystone</title>
      <link>https://openpower.ic.unicamp.br/post/openstack_setup_3/</link>
      <pubDate>Wed, 09 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/openstack_setup_3/</guid>
      <description>&lt;p&gt;This service provides a central directory of users mapped to the OpenStack services. It&amp;rsquo;s used to provide an authentication and authorization service for other OpenStack services. In addition to the identity service, we will install two more packages, the Apache HTTP server and the Memcahed, responsible, respectively, for receiving requests and store the authentication tokens.&lt;/p&gt;
&lt;p&gt;#Prerequisites&lt;/p&gt;
&lt;p&gt;All the keystone data will be stored in a database, acess the mysql and execute the following commands:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;mysql -u root -p
CREATE DATABASE keystone;
GRANT ALL PRIVILEGES ON keystone.* TO &amp;#39;keystone&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;keystone&amp;#39;;
GRANT ALL PRIVILEGES ON keystone.* TO &amp;#39;keystone&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;keystone&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Install and Configure&lt;/p&gt;
&lt;p&gt;The version Kilo uses a WSGI server to listen the requests to keystone, we choose to use the Apache Server running a WSGI mod.&lt;/p&gt;
&lt;p&gt;Execute the following commands to disable keystone automatic start and install the packages:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;echo &amp;#34;manual&amp;#34; &amp;gt; /etc/init/keystone.override
apt-get install keystone python-openstackclient apache2 libapache2-mod-wsgi \
        memcached python-memcache
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Edit the following sections in the file /etc/keystone/keystone.conf:&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;[DEFAULT]
...
admin_token = ADMIN_TOKEN
verbose = True

[database]
connection = mysql://keystone:KEYSTONE_DBPASS@controller/keystone

[memcache]
servers = localhost:11211

[token]
provider = keystone.token.providers.uuid.Provider
driver = keystone.token.persistence.backends.memcache.Token

[revoke]
driver = keystone.contrib.revoke.backends.sql.Revoke
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create the file /etc/apache2/sites-available/wsgi-keystone.conf with the following content:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;Listen 5000
Listen 35357

&amp;lt; VirtualHost *:5000 &amp;gt;
    WSGIDaemonProcess keystone-public processes=5 threads=1 user=keystone display-name=%{GROUP}
    WSGIProcessGroup keystone-public
    WSGIScriptAlias / /var/www/cgi-bin/keystone/main
    WSGIApplicationGroup %{GLOBAL}
    WSGIPassAuthorization On
    &amp;lt; IfVersion &amp;gt;= 2.4 &amp;gt;
      ErrorLogFormat &amp;#34;%{cu}t %M&amp;#34;
    &amp;lt; /IfVersion &amp;gt;
    LogLevel info
    ErrorLog /var/log/apache2/keystone-error.log
    CustomLog /var/log/apache2/keystone-access.log combined
&amp;lt; /VirtualHost &amp;gt;
&amp;lt; VirtualHost *:35357 &amp;gt;
    WSGIDaemonProcess keystone-admin processes=5 threads=1 user=keystone display-name=%{GROUP}
    WSGIProcessGroup keystone-admin
    WSGIScriptAlias / /var/www/cgi-bin/keystone/admin
    WSGIApplicationGroup %{GLOBAL}
    WSGIPassAuthorization On
    &amp;lt; IfVersion &amp;gt;= 2.4 &amp;gt;
      ErrorLogFormat &amp;#34;%{cu}t %M&amp;#34;
    &amp;lt; /IfVersion &amp;gt;
    LogLevel info
    ErrorLog /var/log/apache2/keystone-error.log
    CustomLog /var/log/apache2/keystone-access.log combined
&amp;lt; /VirtualHost &amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Install and configure the WSGI mod for Apache:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;ln -s /etc/apache2/sites-available/wsgi-keystone.conf /etc/apache2/sites-enabled
mkdir -p /var/www/cgi-bin/keystone
curl http://git.openstack.org/cgit/openstack/keystone/plain/httpd/keystone.py?h=stable/kilo \
     | tee /var/www/cgi-bin/keystone/main /var/www/cgi-bin/keystone/admin
chown -R keystone:keystone /var/www/cgi-bin/keystone
chmod 755 /var/www/cgi-bin/keystone/*
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart the Apache service:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;rm -f /var/lib/keystone/keystone.db
service apache2 restart
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Create the service endpoint&lt;/p&gt;
&lt;p&gt;To really have the Keystone service working is needed to create a service endpoint to listen requests:&lt;/p&gt;
&lt;p&gt;Export the following lines to obtain administrator privileges on Keystone:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;export OS_TOKEN=ADMIN
export OS_URL=http://controller:35357/v2.0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Registry the service:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;openstack service create --name keystone --description &amp;#34;OpenStack Identity&amp;#34; identity
openstack endpoint create --publicurl http://controller:5000/v2.0 \
          --internalurl http://controller:5000/v2.0 --adminurl http://controller:35357/v2.0 \
          --region RegionOne identity
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Create the environment entities&lt;/p&gt;
&lt;p&gt;Each of the services that compose OpenStack uses the keystone as the authentication point, this process involves a combination of various entities (users, projects, etc.). You can better understand the functioning of Keystone at the &lt;a href=&#34;http://docs.openstack.org/kilo/install-guide/install/apt/content/keystone-concepts.html&#34;&gt;documentation page&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;Create the Admininstration and Demo projetct:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;openstack project create --description &amp;#34;Admin Project&amp;#34; admin
openstack project create --description &amp;#34;Demo Project&amp;#34; demo
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create users and roles and after make sure each user is registred in one role:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;openstack role create admin
openstack role create user
openstack user create --password-prompt admin
openstack user create --password-prompt demo
openstack role add --project admin --user admin admin
openstack role add --project demo --user demo user
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Each service that will be installed is represent as an user in Keystone, they will be part of an project that will contain all the services:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;openstack project create --description &amp;#34;Service Project&amp;#34; service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#OpenRC files&lt;/p&gt;
&lt;p&gt;To simplify the keystone authentication process create a file that contains the credenditals and export to the system.&lt;/p&gt;
&lt;p&gt;Create the file adm-credentials.sh and add the following:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;export OS_PROJECT_DOMAIN_ID=default
export OS_USER_DOMAIN_ID=default
export OS_PROJECT_NAME=admin
export OS_TENANT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=SENHA_ADMIN
export OS_AUTH_URL=http://controller:35357/v3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Load the file content:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt;source adm-credentials.sh
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Setting up an OpenStack-based cloud with Power8 | Part 02 – Environment Setup</title>
      <link>https://openpower.ic.unicamp.br/post/openstack_setup_2/</link>
      <pubDate>Fri, 21 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/openstack_setup_2/</guid>
      <description>&lt;p&gt;The environment will consist of two Power8 machines with Ubuntu 15.04 installed, one of the machines will contain the core cloud services (controller node), and the other one the virtualization services (compute node). In this guide we are going to install the newest OpenStack release, the Kilo version. However, before installing the cloud services it&amp;rsquo;s necessary to properly set up the environment, this post will cover all the datails.&lt;/p&gt;
&lt;p&gt;#Passwords&lt;/p&gt;
&lt;p&gt;As a convention, passwords for each service will be the service name in lowercase, do not forget that in a real environment passwords must be chosen carefully.&lt;/p&gt;
&lt;p&gt;#Network&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s possible to install OpenStack with two different network architectures, legacy networking (nova-network) and Neutron. Initially we will use nova-network, our network environment is represented as shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/cULbdw1.png&#34; alt=&#34;Nova-network&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note that we have two networks, the 10.0.0.0/24 is the management network (where the nodes will establish comunicate) and the 10.0.2.0/24 is the external network (each created VM will have an IP external acessible).&lt;/p&gt;
&lt;p&gt;Edit the file &lt;em&gt;/etc/hosts&lt;/em&gt; on all machines and add the following:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#controller
10.0.0.10 controller
#compute
10.0.0.11 compute01
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Network Time Protocol (NTP)&lt;/p&gt;
&lt;p&gt;In order to synchronize services installed on different nodes we will install NTP.&lt;/p&gt;
&lt;p&gt;First of all install NTP on all machines:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt-get install ntp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;##On controller&lt;/p&gt;
&lt;p&gt;Edit the file &lt;em&gt;/etc/ntp.conf&lt;/em&gt; and add or edit the follwing lines:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;server 0.ubuntu.pool.ntp.org iburst
restrict -4 default kod notrap nomodify
restrict -6 default kod notrap nomodify
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart the NTP service:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;service ntp restart
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;##On compute&lt;/p&gt;
&lt;p&gt;Edit the file &lt;em&gt;/etc/ntp.conf&lt;/em&gt; and change the server to:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;server controller iburst
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart the NTP service:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;service ntp restart
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Openstack and system packages&lt;/p&gt;
&lt;p&gt;We have to configure the package respository to point to the Openstack Kilo release and verify if the system is up-to-date. Perform the followig step on all nodes.&lt;/p&gt;
&lt;p&gt;Install Ubuntu keyring and set the Kilo repository:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt-get install ubuntu-cloud-keyring
echo &amp;#34;deb http://ubuntu-cloud.archive.canonical.com/ubuntu&amp;#34; \
&amp;#34;trusty-updates/kilo main&amp;#34; &amp;gt; /etc/apt/sources.list.d/cloudarchive-kilo.list
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Upgrade the packages on your system:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt-get update
apt-get dist-upgrade
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#SQL database&lt;/p&gt;
&lt;p&gt;The SQL database will be installed only on controlle node, the openstack services mostly use a database to store all the information they need. We choose to install MySQL server.&lt;/p&gt;
&lt;p&gt;Install packages:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt-get install mysql-server python-mysqldb
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Edit the file &lt;em&gt;/etc/mysql/mysql.conf.d/mysqld.conf&lt;/em&gt; in the [mysqld] section:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[mysqld]
...
bind-address = 10.0.0.10
default-storage-engine = innodb
innodb_file_per_table
collation-server = utf8_general_ci
init-connect = &amp;#39;SET NAMES utf8&amp;#39;
character-set-server = utf8
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart the Mysql service:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;service mysql restart
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Execute the following mysql script to secure the database service:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;mysql_secure_installation
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;##Message Queue&lt;/p&gt;
&lt;p&gt;Openstack uses the strategy of a queue message to coordinate the actions related to the services, in other words, a message queue running on the controller node coordinates the comunication between the services in order to have all the services properly. In this guide we will use a message queue server called RabbitMQ.&lt;/p&gt;
&lt;p&gt;Install the packages:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apt-get install rabbitmq-server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create the openstack user:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;rabbitmqctl add_user openstack RABBIT_PASS
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As mentioned in password section, replace &lt;em&gt;RABBIT_PASS&lt;/em&gt; by &lt;em&gt;rabbit&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Configure permissions to openstack user:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;rabbitmqctl set_permissions openstack &amp;#34;.*&amp;#34; &amp;#34;.*&amp;#34; &amp;#34;.*&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;##Next steps&lt;/p&gt;
&lt;p&gt;With the environment properly configured we can setup the OpenStack services, in the next post we will configure the identity service, known as Keystone.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up an OpenStack-based cloud with Power8 | Part 01 – Introduction</title>
      <link>https://openpower.ic.unicamp.br/post/openstack_setup_1/</link>
      <pubDate>Thu, 20 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/openstack_setup_1/</guid>
      <description>&lt;p&gt;#Introduction&lt;/p&gt;
&lt;p&gt;In this series we are going to detail all the necessary steps to setup an OpenStack-based cloud with IBM POWER8 machines from the scratch, but first of all, let&amp;rsquo;s take a look at some basic questions like what is OpenStack and why one would want to install and use it?&lt;/p&gt;
&lt;p&gt;#What is OpenStack?&lt;/p&gt;
&lt;p&gt;OpenStack is a free and open-source set of connected components aiming to serve as an cloud computing operating system capable of managing large pools of compute, storage and networking resources, all managed through a administrator dashboard. It&amp;rsquo;s robustness and reliability as one of the most active open-source project today makes it an really good choice for offering cloud computing services (&lt;a href=&#34;https://en.wikipedia.org/wiki/Cloud_computing#Infrastructure_as_a_service_.28IaaS.29&#34;&gt;IaaS&lt;/a&gt;) on standarized hardware, and due to its simplicity and massive scalability it can be used as an solution for a large amout of users, from a small home environments with few machines to large datacenters with hundreds of machines.&lt;/p&gt;
&lt;p&gt;The OpenStack project began first in 2010 as an joint project of Rackspace Hosting and NASA, today, the project itself is managed by the OpenStack Foundation and have more than 500 supporters among companies and research centers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/PNQ4Dro.png&#34; alt=&#34;OpenStack Services&#34;&gt;&lt;/p&gt;
&lt;p&gt;#Components&lt;/p&gt;
&lt;p&gt;The main project is implemented in a modular architecture with many components, each one performing its own responsibility in the system. The diagram below can be found at the OpenStack official documentation:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/QiQGJHe.png&#34; alt=&#34;OpenStack components connections&#34;&gt;&lt;/p&gt;
&lt;p&gt;##Horizon (Dashboard)&lt;/p&gt;
&lt;p&gt;This component responsibility consists in providing a web-based interface to easily access the OpenStack services.&lt;/p&gt;
&lt;p&gt;##Compute (Nova)&lt;/p&gt;
&lt;p&gt;The main part of any IaaS system, the Nova project performs the controller role, managing and automating pools of computer resources. It supports many virtualization technologies and is it responsibility to manage the virtual machines on the system.&lt;/p&gt;
&lt;p&gt;##Networking (Neutron)&lt;/p&gt;
&lt;p&gt;Manages the networks and IP adresses, providing users total control over network configurations. Standard network models works with separate VLANs for each user to distribute the network access, the Neutron component treats the question differently, managing the IP adressess, allowing a more flexible and maintainable network usage.&lt;/p&gt;
&lt;p&gt;##Object Storage (Swift)&lt;/p&gt;
&lt;p&gt;The Swift component stores and retrieves unstructured data object through the HTTP based APIs.&lt;/p&gt;
&lt;p&gt;##Block Storage (Cinder)&lt;/p&gt;
&lt;p&gt;Provides persistent storage to running services, its implemented in such a way that makes creating and managing block storage very easy.&lt;/p&gt;
&lt;p&gt;##Identity Service (Keystone)&lt;/p&gt;
&lt;p&gt;This provides a central directory of users mapped to the OpenStack services. It is used to provide an authentication and authorization service for other OpenStack services.&lt;/p&gt;
&lt;p&gt;##Image Service (Glance)&lt;/p&gt;
&lt;p&gt;This provides the discovery, registration and delivery services for the disk and server images. It stores and retrieves the virtual machine disk image.&lt;/p&gt;
&lt;p&gt;##Telemetry (Ceilometer)&lt;/p&gt;
&lt;p&gt;It monitors the usage of the Cloud services and decides the billing accordingly. This component is also used to decide the scalability and obtain the statistics regarding the usage.&lt;/p&gt;
&lt;p&gt;##Orchestration (Heat)&lt;/p&gt;
&lt;p&gt;This component manages multiple Cloud applications through an OpenStack-native REST API and a CloudFormation-compatible Query API.&lt;/p&gt;
&lt;p&gt;#Why would I use OpenStack?&lt;/p&gt;
&lt;p&gt;In sight of all the features listed above and all the benefits that OpenStack can offer to its users and administrators we choose it to serve as infrastructure to our POWER8-based cloud, the steps to setup and manage the system will be discussed throughout the next series posts, keep in touch!&lt;/p&gt;
&lt;p&gt;#Sources:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/OpenStack&#34;&gt;Wikipedia OpenStack article&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.openstack.org&#34;&gt;Official OpenStack documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up a Debian Gateway Virtual Machine on PowerKVM</title>
      <link>https://openpower.ic.unicamp.br/post/debian_gateway/</link>
      <pubDate>Sat, 08 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/debian_gateway/</guid>
      <description>&lt;p&gt;There are many reasons why one would want to build its custom router instead of buying one. Control and flexibility are two reasons, and we need both when dealing with large traffic. The purpose of this guide is to give a step-by-step solution starting on how to build a virtual machine. For this, we will assume that PowerKVM is already up and running along with its network configurations.&lt;/p&gt;
&lt;p&gt;So, for this guide we will need:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A PowerKVM machine&lt;/li&gt;
&lt;li&gt;Two network cards&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this case, &lt;strong&gt;eth0&lt;/strong&gt; will be our internal network interface and &lt;strong&gt;eth1&lt;/strong&gt; our external network interface. Both of them will be bridged to the virtual machine and this configuration can be made through Kimchi&amp;rsquo;s web interface.&lt;/p&gt;
&lt;h1 id=&#34;creating-a-debian-virtual-machine&#34;&gt;Creating a Debian Virtual Machine&lt;/h1&gt;
&lt;h2 id=&#34;downloading-the-right-iso&#34;&gt;Downloading the right ISO&lt;/h2&gt;
&lt;p&gt;First we&amp;rsquo;ll download Debian&amp;rsquo;s 8.1 DVD Image for PPC64el architecture. It can be found on &lt;a href=&#34;http://cdimage.debian.org/debian-cd/8.1.0/ppc64el/iso-dvd/&#34;&gt;this link&lt;/a&gt; and should be stored in /var/lib/kimchi/isos/ folder.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd /var/lib/kimchi/isos
wget http://cdimage.debian.org/debian-cd/8.1.0/ppc64el/iso-dvd/debian-8.1.0-ppc64el-DVD-1.iso
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then run &lt;em&gt;md5sum&lt;/em&gt; to see if the file is corrupted:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;wget http://cdimage.debian.org/debian-cd/8.1.0/ppc64el/iso-dvd/MD5SUMS
md5sum -c MD5SUMS
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The result should be:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;debian-8.1.0-ppc64el-DVD-1.iso: OK
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Otherwise, try downloading again.&lt;/p&gt;
&lt;h2 id=&#34;bringing-to-life&#34;&gt;Bringing to Life&lt;/h2&gt;
&lt;p&gt;Now that we have our ISO, we&amp;rsquo;ll create an &lt;em&gt;qcow2&lt;/em&gt; image using &lt;em&gt;qemu&lt;/em&gt; to act as a hard drive. Those images should be stored in &lt;em&gt;/var/lib/libvirt/images/&lt;/em&gt;.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;qemu-img create -f qcow2 -o preallocation=metadata storage.qcow2 10G
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, we can start the installation using &lt;em&gt;virt-install&lt;/em&gt;:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;virt-install -r 12228 --os-variant=debianwheezy --network bridge=virbr0,model=virtio --accelerate -n debian --vcpus=maxvcpus=16,sockets=2,cores=2,threads=4 -f ./storage.qcow2 --graphics vnc,listen=0.0.0.0 -c /var/lib/kimchi/isos/debian-8.1.0-ppc64el-DVD-1.iso
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you&amp;rsquo;re using a different OS, you can list all available options with:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;virt-install --os-variant list
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Instalation will start. In this case, it was done throught Kimchi&amp;rsquo;s web monitor, but can be done using libvirt. Proceed normally. After it&amp;rsquo;s finished, you can start your VM and login with:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;virsh start debian
virsh console debian
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#Network Configuration&lt;/p&gt;
&lt;p&gt;As said before, &lt;strong&gt;eth0&lt;/strong&gt; and &lt;strong&gt;eth1&lt;/strong&gt; will be bridged to the VM through Kimchi&amp;rsquo;s web interface, where &lt;strong&gt;eth0&lt;/strong&gt; is our internal network interface and &lt;strong&gt;eth1&lt;/strong&gt;, external network.&lt;/p&gt;
&lt;p&gt;##Setting IPs
We&amp;rsquo;ll edit &lt;em&gt;/etc/network/interfaces&lt;/em&gt; file and assign static IP&amp;rsquo;s both internal and external. Your external address and gateway should be provided by your ISP.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;nano /etc/network/interfaces
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;auto lo
iface lo inet loopback

# The primary network interface
allow-hotplug eth0
iface eth0 inet static
   address 10.0.0.1
   netmask 255.255.255.0

allow-hotplug eth1
iface eth1 inet static
   address 0.0.0.0
   netmask 255.255.255.0
   gateway 0.0.0.0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Edit your &lt;em&gt;/etc/resolv.conf&lt;/em&gt; if needed by your ISP:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;nano /etc/resolv.conf
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;nameserver ISP_server;
search ISP_address;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After restarting your network service, you should have something like this:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;systemctl restart networking &amp;amp;&amp;amp; ifconfig

eth0      Link encap:Ethernet  HWaddr 52:54:00:37:bc:11
          inet addr:10.0.0.1  Bcast:10.0.0.255  Mask:255.255.255.0

eth1      Link encap:Ethernet  HWaddr 52:54:00:7b:74:6f
          inet addr: 0.0.0.0  Bcast:0.0.0.0  Mask:255.255.255.0

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;See if it&amp;rsquo;s working by pinging internal and external addresses:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ping www.cnn.com 
ping 10.0.0.5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;##Routing
Start by flushing all previous configurations, if they exist.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;iptables -F
iptables -t nat -F
iptables -t mangle -F
iptables -X
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We&amp;rsquo;ll now allow established connections, outgoing connections and setup masquerade as follows:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;iptables -A INPUT -i lo -j ACCEPT
iptables -A FORWARD -i eth1 -o eth0 -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A FORWARD -i eth0 -o eth1 -j ACCEPT
iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now, we&amp;rsquo;ll allow IP Forwarding:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And your Iptables should look like this:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;iptables -L
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Chain INPUT (policy ACCEPT)
target     prot opt source               destination
ACCEPT     all  --  anywhere             anywhere

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination
ACCEPT     all  --  anywhere             anywhere             state RELATED,ESTABLISHED
ACCEPT     all  --  anywhere             anywhere

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now a client should successfully connect to the internet.&lt;/p&gt;
&lt;p&gt;##Making it Permanent
Now we want to apply these iptables configurations everytime we start this machine. This can be done by saving them in a file and restoring on the next boot.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;iptables-save &amp;gt;&amp;gt; /etc/iptables.rules
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On &lt;em&gt;/etc/network/interfaces&lt;/em&gt;, add this line underneath “iface lo inet loopback”:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;nano /etc/network/interfaces
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;pre-up iptables-restore &amp;lt; /etc/iptables.rules
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;#That&amp;rsquo;s it&lt;/p&gt;
&lt;p&gt;By now you should have a basic Linux gateway for your network. Much more advanced configuration can be done that can add enormous flexibility. It&amp;rsquo;s up to you to start exploring and unleash the true power of having a dedicated machine as your router.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
