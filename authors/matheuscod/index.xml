<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Matheus Fernandes | OpenPOWER@UNICAMP</title>
    <link>https://openpower.ic.unicamp.br/authors/matheuscod/</link>
      <atom:link href="https://openpower.ic.unicamp.br/authors/matheuscod/index.xml" rel="self" type="application/rss+xml" />
    <description>Matheus Fernandes</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 21 Apr 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://openpower.ic.unicamp.br/img/icon-192.png</url>
      <title>Matheus Fernandes</title>
      <link>https://openpower.ic.unicamp.br/authors/matheuscod/</link>
    </image>
    
    <item>
      <title>Building Docker for POWER</title>
      <link>https://openpower.ic.unicamp.br/post/building-docker-for-power/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/building-docker-for-power/</guid>
      <description>&lt;p&gt;This blogpost aims to teach how to build and create a Docker .deb and .rpm packages starting from Docker 20.10 release, considering that since that version the Docker Engine and Docker CLI are built directly from the source repositories.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Moby-logo.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;requirements&#34;&gt;&lt;em&gt;Requirements&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;We used Ubuntu 20.04 for this tutorial for both .deb and .rpm builds.&lt;br&gt;
First, make sure you have both &lt;em&gt;git&lt;/em&gt; and the &lt;em&gt;make&lt;/em&gt; package on your machine.&lt;br&gt;
You can install then with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install make
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install unzip
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After that, we need to install Docker-CE. To do that, just add our POWER packages repository to your machine:&lt;/p&gt;
&lt;p&gt;Edit the file &lt;code&gt;/etc/apt/sources.list&lt;/code&gt; by adding the following line:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;deb https://oplab9.parqtec.unicamp.br/pub/repository/debian/ ./&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Download our &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/key/openpower-gpgkey-public.asc&#34;&gt;GPG key&lt;/a&gt;, and use the command below to add it to the system:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-key add openpower-gpgkey-public.asc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After that, update the package list and install docker-ce:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install docker-ce
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;More information about our repository in: &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;POWER Repository&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;build-and-packaging&#34;&gt;Build and Packaging&lt;/h1&gt;
&lt;p&gt;We&amp;rsquo;ll need to download docker-cli and moby (current name of the docker engine) and clone the repositories from scan-cli-plugin and docker-ce-packaging.&lt;br&gt;
Clone the following docker repositories:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/docker/scan-cli-plugin.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/docker/docker-ce-packaging.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Download the desired version (we&amp;rsquo;ll use 20.10.6) of the cli and moby by downloading its releases (you can use &lt;code&gt;git clone&lt;/code&gt; to build the master branch too):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download the cli source code and change its zip name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://github.com/docker/cli/archive/refs/tags/v20.10.6.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv v20.10.6.zip cli.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Download the moby source code and change its zip name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget https://github.com/moby/moby/archive/refs/tags/v20.10.6.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv v20.10.6.zip moby.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Unzip the downloaded source-codes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;unzip cli.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;unzip moby.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Change the folders name&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv cli-20.10.6 cli
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mv moby-20.10.6 moby
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Because the Docker Build uses containerd.io, we need to modify two files on docker-ce-packaging in order to use the community version of the same software, which is probably already installed on your machine if you installed Docker-CE from our repository(&lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;POWER Repository&lt;/a&gt;).&lt;br&gt;
Besides that&lt;/p&gt;
&lt;p&gt;Modify the files with python3 by running the following script:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Running Patching Script...&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deb_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;docker-ce-packaging/deb/common/control&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deb_ver &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;containerd (&amp;gt;= 1.2.1)&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rpm_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;docker-ce-packaging/rpm/SPECS/docker-ce.spec&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rpm_ver &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Requires: containerd &amp;gt;= 1.2.1&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Update debian containerd dependency&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Patching DEB...&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(deb_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;containerd.io \([^)]*\)&amp;#39;&lt;/span&gt;, deb_ver, data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; new, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Nothing was changed in the file.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;open(deb_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(new)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Update rpm containerd dependency&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Patching RPM...&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rpm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(rpm_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rpm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Requires: containerd.io [^\n]*&amp;#39;&lt;/span&gt;, rpm_ver, data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; new, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Nothing was changed in the file.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;open(rpm_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(new)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DONE Patching&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After the patch is done, we need to create specific folders inside &lt;code&gt;docker-ce-packaging&lt;/code&gt; and copy the other cloned repositories into that folders.&lt;/p&gt;
&lt;p&gt;From the outside of &lt;em&gt;docker-ce-packaging&lt;/em&gt;, do that with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create the folders&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p docker-ce-packaging/src/github.com/docker/cli
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p docker-ce-packaging/src/github.com//docker/docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p docker-ce-packaging/src/github.com/docker/scan-cli-plugin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Copy cli, moby and scan-cli-plugin&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo cp -r cli/* docker-ce-packaging/src/github.com/docker/cli
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo cp -r moby/* docker-ce-packaging/src/github.com/docker/docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo cp -r scan-cli-plugin/* docker-ce-packaging/src/github.com/docker/scan-cli-plugin
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;making-deb-packages&#34;&gt;Making .deb packages&lt;/h2&gt;
&lt;p&gt;Systems available:&lt;br&gt;
&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;ubuntu-buster, ubuntu-bionic, ubuntu-focal, ubuntu-groovy, ubuntu-hirsute, ubuntu-xenial&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;Debian:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;debian-bullseye, debian-buster&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;Raspbian:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;raspbian-bullseye, raspbian-buster&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Make the packages with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd docker-ce-packaging/deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;20.10.6 make ubuntu-focal
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;They will be available at: &lt;code&gt;docker-ce-packaging/deb/debbuild/&lt;/code&gt;&lt;br&gt;
In our example, the .deb files will be at&lt;br&gt;
&lt;code&gt;docker-ce-packaging/deb/debbuild/ubuntu-focal&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;files.png&#34; alt=&#34;deb files&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;making-rpm-packages&#34;&gt;Making .rpm packages&lt;/h2&gt;
&lt;p&gt;Edit the file &lt;code&gt;docker-ce-packaging/rpm/gen-rpm-ver&lt;/code&gt;&lt;br&gt;
by changing the characters &lt;code&gt;||&lt;/code&gt; to &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; in line 46&lt;/p&gt;
&lt;p&gt;Systems available:&lt;br&gt;
&lt;strong&gt;CentOS:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;centos-7, centos-8&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;Fedora:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;fedora-32, fedora-33, fedora-34&lt;/em&gt;&lt;br&gt;
&lt;strong&gt;RHEL:&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;rhel-7&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Make the packages with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd docker-ce-packaging/rpm
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;20.10.6 make centos-8
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;They will be available at: &lt;code&gt;docker-ce-packaging/rpm/rpmbuild/&lt;/code&gt;&lt;br&gt;
In our example, the .rpm files will be at&lt;br&gt;
&lt;code&gt;docker-ce-packaging/rpm/rpmbuild/centos-8/SRPMS&lt;/code&gt; and&lt;br&gt;
&lt;code&gt;docker-ce-packaging/rpm/rpmbuild/centos-8/RPMS/ppc64le&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;files-rpm.png&#34; alt=&#34;rpm files&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;&lt;em&gt;References&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Docker CLI: &lt;a href=&#34;https://github.com/docker/cli&#34;&gt;https://github.com/docker/cli&lt;/a&gt;&lt;br&gt;
Docker Engine: &lt;a href=&#34;https://github.com/moby/moby&#34;&gt;https://github.com/moby/moby&lt;/a&gt;&lt;br&gt;
scan-cli-plugin: &lt;a href=&#34;https://github.com/docker/scan-cli-plugin&#34;&gt;https://github.com/docker/scan-cli-plugin&lt;/a&gt;&lt;br&gt;
Docker-CE Packaging: &lt;a href=&#34;https://github.com/docker/docker-ce-packaging&#34;&gt;https://github.com/docker/docker-ce-packaging&lt;/a&gt;&lt;br&gt;
OpenPOWER@UNICAMP POWER Repository: &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;https://openpower.ic.unicamp.br/project/power-repository/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PowerBoard plugin for TensorBoard</title>
      <link>https://openpower.ic.unicamp.br/post/powerboard-plugin-for-tensorboard/</link>
      <pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/powerboard-plugin-for-tensorboard/</guid>
      <description>&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;First we need to talk about the motivation behind this plugin. The architecture Power was designed for use in artificial intelligence and deep learning. Investigating tools for deep learning and machine learning we found TensorBoard. TensorBoard is a tool to view models which were created in TensorFlow, the TensorBoard is a toolkit that allows graphic visualization of your models, making it easier to understand the used model, debug bottlenecks and, as a result, optimize it. In this blog post, we’ll show how to use the plugin we’ve created, which adds a new feature to the TensorBoard, this plugin assists on debugging bottlenecks in conjunction with the trace-viewer.&lt;/p&gt;
&lt;h3 id=&#34;powerboard&#34;&gt;PowerBoard&lt;/h3&gt;
&lt;p&gt;PowerBoard is a plugin designed to show the power that is consumed while the neural network is trained, doing that  allows the trace-viewer a better understanding of the model and helps to debug the bottlenecks.&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.6 &amp;gt;=&lt;/li&gt;
&lt;li&gt;TensorFlow 2.2 &amp;gt;=&lt;/li&gt;
&lt;li&gt;TensorBoard 2.2 &amp;gt;=&lt;/li&gt;
&lt;li&gt;Pandas 1.2.1 &amp;gt;=&lt;/li&gt;
&lt;li&gt;ipmitool&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;If you&amp;rsquo;re having trouble installing tensorflow follow the link to a blog post that teaches you how to install tensorflow in the Power architecture:
&lt;a href=&#34;https://openpower.ic.unicamp.br/post/profiling-using-tensorboard-profiler/&#34;&gt;https://openpower.ic.unicamp.br/post/profiling-using-tensorboard-profiler/&lt;/a&gt;
&lt;a href=&#34;https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power/&#34;&gt;https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For the installation of PowerBoard Plugin acess the site  &lt;a href=&#34;https://pypi.org/project/powerboard/&#34;&gt;https://pypi.org/project/powerboard/&lt;/a&gt;, or use the following pip command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install powerboard
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now you&amp;rsquo;re able to use the powerboard. The powerboard possesses an implementation library called libipmi, which is responsible for accessing the low level register to obtain the power consumption. For this, do the following import:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; powerboard &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; libipmi
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;libipmi&#34;&gt;libipmi:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The function &lt;code&gt;start() &lt;/code&gt; : This function is responsible for measuring the power consumption and time of each aquisition.&lt;/li&gt;
&lt;li&gt;The function &lt;code&gt;stop() &lt;/code&gt; : This function is responsible for stopping the aquisition of data.&lt;/li&gt;
&lt;li&gt;The function &lt;code&gt;dbToCSV(&amp;lt;PATH&amp;gt;)&lt;/code&gt;: The implementation of the function gets the data and saves it to a database, when the database is full the implementation saves all data in a csv file. For this, the argument PATH is the path to a directory were the data will be stored. My suggestion is to default the path to &amp;ldquo;./data&amp;rdquo; like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;libipmi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dbToCSV(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;./data&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now you are able to test the plugin, for this I&amp;rsquo;ll show an example of the code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datetime &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datetime
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; packaging &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; version
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; powerboard &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; libipmi 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datasets, layers, models
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stamp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;now()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%Y%m&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;-%H%M%S&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;logdir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;logs/Nfit/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; stamp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;writer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create_file_writer(logdir)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trace_on(profiler&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(train_images, train_labels), (test_images, test_labels) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datasets&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cifar10&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_data()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Normalize pixel values to be between 0 and 1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;train_images, test_images &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_images &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;, test_images &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;class_names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;airplane&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;automobile&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bird&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;deer&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;frog&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ship&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;truck&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPooling2D((&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MaxPooling2D((&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;losses&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SparseCategoricalCrossentropy(from_logits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;libipmi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;start()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;history &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(train_images, train_labels, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(test_images, test_labels))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;test_loss, test_acc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;evaluate(test_images,  test_labels, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;libipmi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stop()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;libipmi&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dbToCSV(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;./data&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; writer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;as_default():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trace_export(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;convolution&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      step&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      profiler_outdir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;logdir)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;before you run the script let&amp;rsquo;s make a directory in tmp files, so go to  &lt;code&gt;/tmp&lt;/code&gt; by doing &lt;code&gt; cd /tmp&lt;/code&gt; and make a directory inside. I&amp;rsquo;ll create the &amp;ldquo;teste&amp;rdquo; directory inside of tmp, as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd /tmp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir teste
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now go to the directory which the script was saved and run the script. Now copy the following directory into the &lt;code&gt;/tmp/teste&lt;/code&gt; by doing:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp -r demo_logs /tmp/teste
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp -r logs /tmp/teste
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now run the TensorBoard:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; tensorboard --logdir  /tmp/teste
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now let&amp;rsquo;s have some fun by cracking our heads to understand the bottlenecks using the trace-viewer and powerboard tools.
the following image shows the powerboard.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;power2.png&#34; alt=&#34;powerboard&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 1: PowerBoard.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now I&amp;rsquo;ll show the trace-viewer overview.
&lt;img src=&#34;trace-viewer2.png&#34; alt=&#34;TRACE-VIEWER&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 2: Trace-viewer overview.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let&amp;rsquo;s zoom in the image. You may control the graph by clicking in the button &lt;code&gt;w&lt;/code&gt; to zoom in , &lt;code&gt;s&lt;/code&gt; to zoom out, &lt;code&gt;d&lt;/code&gt; to scroll right and &lt;code&gt;e&lt;/code&gt; to scroll left.
&lt;img src=&#34;trace2.png&#34; alt=&#34;TRACE-VIEWER&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 3: Trace-viewer zoom in.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The trace-viewer cracks, parallels and executes all operations in CPU and/or GPU to train our neural network. If you&amp;rsquo;re using GPU the documentation of TensorBoard says &amp;ldquo;As a general rule of thumb, it is a good idea to always keep the device (GPU/TPU) active.
Use the tf.data API to optimize the input pipeline. In this case, let&amp;rsquo;s cache the training dataset and prefetch the data to ensure that there is always data available for the GPU to process. See here for more details on using tf.data to optimize your input pipelines&amp;rdquo;. In the trace-viewer we have the trace-context to aid in a better understanding of what is happening.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Go to: &lt;a href=&#34;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&#34;&gt;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&lt;/a&gt; for a complete documentation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;trace-context.png&#34; alt=&#34;TRACE-VIEWER CONTEXT&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 4: Trace-viewer: trace context.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Click on the first occurrence of the traceContext and look at &amp;lsquo;slice&amp;rsquo;, this part of the trace viewer shows all the arguments of the function, such as the time spent on this function.
&lt;img src=&#34;traceContext.png&#34; alt=&#34;TRACE-VIEWER CONTEXT1&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 5: Trace context: inside of slice.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that we are at the epoch number &amp;ldquo;0&amp;rdquo; and step_name &amp;ldquo;0&amp;rdquo;, that is, in this part of the x-axis the graph indicates the first image to train our neural network. If we proceed to the next trace context it will follow to the next images to be trained. When the epoch value changes to 1 it means that we have finished training our neural network for the first time, and a new epoch will begin. Note that the size of the set of images is selected by the batch_size slice of our code, that is, we take the total number of images from the dataset and divide them by batch_size, in general the batch_size are powers of 2.
&lt;img src=&#34;traceContext2.png&#34; alt=&#34;TRACE-VIEWER CONTEXT1&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 6: Trace context: the next interation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now the next part is understanding the power consumption and relationships with the code. For this the following image shows the last interation of 1 complete epoch:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;traceContext3.png&#34; alt=&#34;TRACE-VIEWER CONTEXT1&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 7: Trace context: the last interation of epoch 0.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that a full epoch takes about 22 seconds, as shown by the powerboard tab. Symmetry in the graph is expected, but it does not occur. Also note that between times 27.31 s and 28.78 s we have a sudden increase in power, so we will go in the trace-viewer to look at what is being carried out during this interval. In the meantime, we note that there is the following set of images from the training in epoch 1 [185-258]. Returning this set to epoch 0 it corresponds to the time interval between 9.35 s and 11.13 s.
It is possible to conclude that theoretically the epochs should be symmetrical in terms of operations, that is, the energy expenditure should be the same, but it is noticed that something beyond the code is supplying this increase in extra power consumption by the same part of operations. Perhaps a new approach at a lower level would be needed to reach better conclusions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Installing Tensorflow on POWER</title>
      <link>https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power/</link>
      <pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power/</guid>
      <description>&lt;p&gt;TensorFlow is a very popular open-source library for Machine Learning and in this post we will see two ways (from a Community Supported Build and from the IBM Watson Machine Learning Community Edition) of installing it on POWER.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;tf-logo.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;installing-tensorflow-from-the-community-supported-build&#34;&gt;&lt;em&gt;Installing TensorFlow from the Community Supported Build&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;On the TensorFlow repository README on GitHub (&lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;) there is a list of community builds of TensorFlow, in which includes CPU and GPU builds for POWER.&lt;/p&gt;
&lt;p&gt;We will be using the links available on there to install TensorFlow on POWER.&lt;/p&gt;
&lt;h3 id=&#34;before-installation&#34;&gt;Before Installation&lt;/h3&gt;
&lt;p&gt;Install the build-essential package with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get install build-essential
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;download-and-install-anaconda-package-manager&#34;&gt;Download and Install Anaconda package manager:&lt;/h3&gt;
&lt;p&gt;We&amp;rsquo;ll use Anacona to install TensorFlow within a virtual environment.&lt;/p&gt;
&lt;p&gt;Download: &lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;https://www.anaconda.com/products/individual&lt;/a&gt;&lt;br&gt;
Remember to check the script sha256sum: &lt;a href=&#34;https://docs.anaconda.com/anaconda/install/hashes/&#34;&gt;https://docs.anaconda.com/anaconda/install/hashes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To install Anaconda Individual Edition, you just need to run the script downloaded and follow the inscructions that it provides.&lt;/p&gt;
&lt;p&gt;Create Virtual Environment and activate it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create --name tf_env python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.6 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate tf_env 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We&amp;rsquo;ll be using python3.6 for this environment installation.&lt;/p&gt;
&lt;p&gt;To install Anaconda Individual Edition, you just need to run the script downloaded and follow the inscructions that it provides.&lt;/p&gt;
&lt;h3 id=&#34;download-and-install-a-tensorflow-build&#34;&gt;Download and Install a TensorFlow build:&lt;/h3&gt;
&lt;p&gt;The Community Supported Builds from TensorFlow repository README provides both TF Release 1.15 and 2.x versions for both CPU-only and GPU.&lt;/p&gt;
&lt;p&gt;In this tutorial we will be installing a 2.x CPU-only version, altough the same process can be use for the GPU version.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Access &lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt; and select the needed build.&lt;br&gt;
We&amp;rsquo;ll use the Release 2.x CPU (&lt;a href=&#34;https://powerci.osuosl.org/job/TensorFlow2_PPC64LE_CPU_Release_Build/&#34;&gt;https://powerci.osuosl.org/job/TensorFlow2_PPC64LE_CPU_Release_Build/&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;builds.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Download the needed version and pay attention to the requirements (for instance, our selected build was built for GLIBC 2.17 and above).&lt;br&gt;
We&amp;rsquo;ll download the cp36 version, since we created a virtual conda environment for python 3.6.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;downloads.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;After the .whl file was downloaded, we&amp;rsquo;ll install it with pip within our conda environment.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;attention&#34;&gt;Attention&lt;/h2&gt;
&lt;p&gt;When installing TensorFlow, it is possible that some requirements errors occurs. If that happens, just install the missing library and try instaling TensorFlow again.&lt;/p&gt;
&lt;p&gt;For intance, we needed to install scipy 1.4.1 and h5py before the installation succeeded, and that can be done with Anaconda with the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda install -c conda-forge scipy&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1.4.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda install -c conda-forge h5py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Installing TensorFlow from the .whl file with pip inside the conda environment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install tensorflow_cpu-2.2.0-cp36-cp36m-linux_ppc64le.whl
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After the installation is completed, check TensorFlow within a python shell with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__version__)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;alternative-installing-tensorflow-with-watson-machine-learning-community-edition&#34;&gt;&lt;em&gt;[ALTERNATIVE] Installing TensorFlow with Watson Machine Learning Community Edition&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;IBM Watson Machine Learning Community Edition also provides a TensorFlow installation through Anaconda, which will be taught in this tutorial.&lt;/p&gt;
&lt;h3 id=&#34;download-and-install-anaconda-package-manager-1&#34;&gt;Download and Install Anaconda package manager:&lt;/h3&gt;
&lt;p&gt;Download: &lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;https://www.anaconda.com/products/individual&lt;/a&gt;&lt;br&gt;
Remember to check the script sha256sum: &lt;a href=&#34;https://docs.anaconda.com/anaconda/install/hashes/&#34;&gt;https://docs.anaconda.com/anaconda/install/hashes/&lt;/a&gt;&lt;br&gt;
To install Anaconda Individual Edition, you just need to run the script downloaded and follow the inscructions that it provides.&lt;/p&gt;
&lt;h3 id=&#34;add-wmlce-channel-to-anaconda&#34;&gt;Add WMLCE Channel to Anaconda&lt;/h3&gt;
&lt;p&gt;After the installation, add WMLCE (IBM Watson Machine Learning Community Edition) channel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda config --prepend channels &lt;span style=&#34;color:#ae81ff&#34;&gt;\ &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Create an Anaconda Python3.6 environment for WMLCE and activate it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Currently (09/2020) WMLCE only works with python version 3.6&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create --name wmlce_env python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.6 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate wmlce_env 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;install-tensorflow&#34;&gt;Install TensorFlow&lt;/h3&gt;
&lt;p&gt;For CPU-only use, install TensorFlow with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda install tensorflow
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For GPU use, install TensorFlow with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda install tensorflow
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TF is now installed and ready for use.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference:&lt;/h2&gt;
&lt;p&gt;Anaconda:&lt;br&gt;
&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;https://www.anaconda.com/products/individual&lt;/a&gt;&lt;br&gt;
TensorFlow GitHub repository:&lt;br&gt;
&lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;&lt;br&gt;
IBM Watson Machine Learning Community Edition:&lt;br&gt;
&lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/SS5SF7_1.6.1/navigation/welcome.html&#34;&gt;https://www.ibm.com/support/knowledgecenter/SS5SF7_1.6.1/navigation/welcome.html&lt;/a&gt;&lt;br&gt;
WMLCE softwares list:&lt;br&gt;
&lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/SS5SF7_1.6.1/navigation/wmlce_software_pkgs.html&#34;&gt;https://www.ibm.com/support/knowledgecenter/SS5SF7_1.6.1/navigation/wmlce_software_pkgs.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Measuring energy power consumption on POWER9 through IPMI sensors</title>
      <link>https://openpower.ic.unicamp.br/post/power-consumption-on-power/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/power-consumption-on-power/</guid>
      <description>&lt;p&gt;In this post, we will show how to get data on power consumption in a POWER9 bare-metal machine and how to plot this data using python.&lt;/p&gt;
&lt;p&gt;To measure the power consumption, a program called ipmitool will be used, once it give us the access to ipmi sensor data.&lt;/p&gt;
&lt;p&gt;In order to get a good span of values, a Image Classification script was used, which its code and execution procedure can be found here: &lt;a href=&#34;https://openpower.ic.unicamp.br/post/ai-profiling-for-power/&#34;&gt;https://openpower.ic.unicamp.br/post/ai-profiling-for-power/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;using-ipmitool-to-get-sensors-data&#34;&gt;Using ipmitool to get sensors data&lt;/h2&gt;
&lt;p&gt;In order to get a list of IPMI sensors, use the following command.&lt;/p&gt;
&lt;p&gt;Command: &lt;code&gt;sudo ipmitool sensor list&lt;/code&gt;
Output fields meaning with example:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Sensor ID&lt;/th&gt;
&lt;th&gt;Sensor Reading&lt;/th&gt;
&lt;th&gt;Sensor Reading Unit&lt;/th&gt;
&lt;th&gt;Status&lt;/th&gt;
&lt;th&gt;Lower Non-Recoverable&lt;/th&gt;
&lt;th&gt;Lower Critical&lt;/th&gt;
&lt;th&gt;Lower Non-Critical&lt;/th&gt;
&lt;th&gt;Upper Non-Critical&lt;/th&gt;
&lt;th&gt;Upper Critical&lt;/th&gt;
&lt;th&gt;Upper Non-Recoverable&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CPU1 Temp&lt;/td&gt;
&lt;td&gt;34.000&lt;/td&gt;
&lt;td&gt;degrees C&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;5.000&lt;/td&gt;
&lt;td&gt;5.000&lt;/td&gt;
&lt;td&gt;10.000&lt;/td&gt;
&lt;td&gt;88.000&lt;/td&gt;
&lt;td&gt;90.000&lt;/td&gt;
&lt;td&gt;92.000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To get a single sensor data, use the command:&lt;br&gt;
&lt;code&gt;ipmitool sensor get &amp;lt;Sensor ID&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Example:&lt;br&gt;
&lt;code&gt;sudo ipmitool sensor get CPU1\ Temp&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Locating sensor record...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Sensor ID              : CPU1 Temp &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0xb&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Entity ID             : 65.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Sensor Type &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Threshold&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;  : Temperature
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Sensor Reading        : &lt;span style=&#34;color:#ae81ff&#34;&gt;36&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;+/- 1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; degrees C
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Status                : ok
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Lower Non-Recoverable : 5.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Lower Critical        : 5.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Lower Non-Critical    : 10.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Upper Non-Critical    : 88.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Upper Critical        : 90.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Upper Non-Recoverable : 92.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Positive Hysteresis   : 2.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Negative Hysteresis   : 2.000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Assertion Events      : 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Assertions Enabled    : ucr+ 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Deassertions Enabled  : ucr+
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The power measurement was collected by using the following python script, which not only calls ipmitool, but also parse the data into a csv file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; subprocess
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; csv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;duration &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;file_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sensors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;:]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;time_begin &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(file_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.csv&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; file_out:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    write &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; csv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;writer(file_out)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    first_row &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sensor_ID&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Entity_ID&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sensor_Type_Threshold_&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sensor_Reading&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Status&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Lower_Non_Recoverable&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Lower_Critical&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Lower_Non_Critical&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Upper_Non_Critical&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Upper_Critical&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Upper_Non_Recoverable&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Positive_Hysteresis&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Negative_Hysteresis&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Assertion_Events&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Assertions_Enabled&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Deassertions_Enabled&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Time_elapsed&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    write&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;writerow(first_row)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    end &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; float(duration)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; end &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sens &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sensors:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            command &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sudo&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ipmitool&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sensor&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;get&amp;#39;&lt;/span&gt;, sens]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            process &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; subprocess&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    command,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    stdout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;subprocess&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;PIPE,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    universal_newlines&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; process&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stdout
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            current_row &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            current_row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(sens)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(output)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                output[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output[i]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;:&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                output[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output[i][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,len(output[i])):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    output[i][j] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output[i][j]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(output[i][j]) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        current_row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(output[i][j][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        current_row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            current_row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{:.5f}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; time_begin))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            write&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;writerow(current_row)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This was the python command used:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python3 sensorsIPMI&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;py &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt; pwr&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;csv Total\ Power CPU1\ Power CPU2\ Power PCIE\ CPU1\ Pwr PCIE\ CPU2\ Pwr
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;plot-the-data&#34;&gt;Plot the data&lt;/h2&gt;
&lt;p&gt;In order to plot the data, a jupyter notebook was used.&lt;br&gt;
Which is available here:&lt;br&gt;
&lt;a href=&#34;https://colab.research.google.com/github/Unicamp-OpenPower/openpower/blob/master/content/post/power-consumption-on-power/pwrAnalysis.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The following graphs were ploted in the notebook:
All sensors:&lt;br&gt;
&lt;img src=&#34;all_sensors.png&#34; alt=&#34;All sensors&#34;&gt;
Total Power:&lt;br&gt;
&lt;img src=&#34;total.png&#34; alt=&#34;All sensors&#34;&gt;
CPU1 Power:&lt;br&gt;
&lt;img src=&#34;cpu1.png&#34; alt=&#34;All sensors&#34;&gt;
CPU2 Power:&lt;br&gt;
&lt;img src=&#34;cpu2.png&#34; alt=&#34;All sensors&#34;&gt;
PCIE CPU1 Power:&lt;br&gt;
&lt;img src=&#34;pcie_cpu1.png&#34; alt=&#34;All sensors&#34;&gt;
PCIE CPU2 Power:&lt;br&gt;
&lt;img src=&#34;pcie_cpu2.png&#34; alt=&#34;All sensors&#34;&gt;&lt;/p&gt;
&lt;p&gt;IPMI on OpenPOWER source:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/developerworks/library/l-openpower-firmware-ipmi/index.html&#34;&gt;https://www.ibm.com/developerworks/library/l-openpower-firmware-ipmi/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/9006-22C/p9eih/p9eih_ipmi_syshealth.htm&#34;&gt;https://www.ibm.com/support/knowledgecenter/9006-22C/p9eih/p9eih_ipmi_syshealth.htm&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Although made for a different hardware vendor, a good source for ipmitool commands can be found on the following url:
&lt;a href=&#34;https://docs.oracle.com/cd/E19464-01/820-6850-11/IPMItool.html&#34;&gt;https://docs.oracle.com/cd/E19464-01/820-6850-11/IPMItool.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Profiling using Tensorboard-Profiler</title>
      <link>https://openpower.ic.unicamp.br/post/profiling-using-tensorboard-profiler/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/profiling-using-tensorboard-profiler/</guid>
      <description>&lt;p&gt;This blog post will show how to install tensorflow 2.2 in POWER, how to use profiler and make a comparison between different architectures ( x86, POWER 8 and 9).&lt;/p&gt;
&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;
&lt;p&gt;In this part I&amp;rsquo;ll show how to setup your Virtual Machine (VM) and install tensorflow 2.2 in POWER. My PIP version is 20.3 and my version of python is 3.8.&lt;/p&gt;
&lt;p&gt;First we need to install some libraries to install tensorflow 2.2.&lt;/p&gt;
&lt;p&gt;Installing dependecies of scipy:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sudo apt-get install libblas-dev liblapack-dev libatlas-base-dev gfortran
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Installing h5py:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sudo apt install python3-h5py  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Installing keras using pip:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install -U --user keras_applications --no-deps
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install -U --user keras_preprocessing --no-deps
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we are able to install tensorflow 2.2. For this, access the site (&lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;) to download .whl file (this file is used to install tensorflow using pip comand). First go in Community Supported Builds Section, and click in Artifacts release 2.x of Linux ppc64le CPU Stable Release.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;gitTensorflow.png&#34; alt=&#34;Tensorflow installation&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 1: Tensorflow 2.2 cpu- only installation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After clicking we are directed to jenkins, where we click in tensorflow_cpu-2.2.0-cp38-cp38-linux_ppc64le.whl. Note that &amp;ldquo;cp38&amp;rdquo; indicates that the tensorflow should be installed in python 3.8. However, if you are using different versions of python you can download the version corresponding to your python version. But in this tutorial I&amp;rsquo;ll show how to setup using python 3.8.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Tensorflowbuild.png&#34; alt=&#34;Tensorflow installationpt2&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Figure 2: Download .whl tensorflow 2.2 build.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For download in VM, copy the link (tensorflow_cpu-2.2.0-cp38-cp38-linux_ppc64le.whl) and use the command below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    wget https://powerci.osuosl.org/job/TensorFlow2_PPC64LE_CPU_Release_Build/lastSuccessfulBuild/artifact/tensorflow_pkg/tensorflow_cpu-2.2.0-cp38-cp38-linux_ppc64le.whl  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now for installation of the tensorflow using pip command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install tensorflow_cpu-2.2.0-cp38-cp38-linux_ppc64le.whl  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more information you can visit &lt;a href=&#34;https://www.tensorflow.org/install/source&#34;&gt;https://www.tensorflow.org/install/source&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now we need to install tensorboard, tensorboard-plugin-profiler and tensorflow-datasets.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install --upgrade tensorboard
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install tensorflow-datasets
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pip3 install -U tensorboard_plugin_profile
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;get-access-to-power-8-vm-in-minicloud&#34;&gt;Get access to POWER 8 VM in minicloud&lt;/h2&gt;
&lt;p&gt;Here is a brief tutorial on how to access POWER 8 virtual machine in minicloud, first access &lt;a href=&#34;https://openpower.ic.unicamp.br/minicloud/&#34;&gt;https://openpower.ic.unicamp.br/minicloud/&lt;/a&gt; and click in &lt;strong&gt;Request Access&lt;/strong&gt;  and answer the google forms to get access. Here is a link that may help you to get access to an instance on minicloud &lt;a href=&#34;https://github.com/Unicamp-OpenPower/minicloud/wiki&#34;&gt;https://github.com/Unicamp-OpenPower/minicloud/wiki&lt;/a&gt;. In the next section I&amp;rsquo;ll show to access tensorboard by terminal.&lt;/p&gt;
&lt;h2 id=&#34;ssh-connection&#34;&gt;SSH connection&lt;/h2&gt;
&lt;p&gt;You&amp;rsquo;ll need to connect to VM via ssh using the &lt;code&gt;-L 6006:localhost:6006&lt;/code&gt; flag. To be able to use tensorboard in the terminal, your command should be like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh ubuntu@minicloud.parqtec.unicamp.br -i ~/.ssh/your-key.pem -p &amp;lt;vm-port&amp;gt; -L 6006:localhost:6006&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For using tensorboard in the terminal we use this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tensorboard --logdir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;lt;name_of_log_directory&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we are able to open the link in your favorite browser.&lt;/p&gt;
&lt;h2 id=&#34;compare-tensorboard-profiler-in-different-architectures&#34;&gt;Compare Tensorboard-Profiler in different architectures&lt;/h2&gt;
&lt;p&gt;In this section, we will be profiling using Tensorboard-Profiler in different architectures and showing the results. First, we will standardize the test file. For this, download the file available in &lt;a href=&#34;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&#34;&gt;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&lt;/a&gt; and modify the line:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;model.fit(ds_train,
          epochs=2,
          validation_data=ds_test,
          callbacks = [tboard_callback])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;to:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;model.fit(ds_train,
          epochs=5,
          validation_data=ds_test,
          callbacks = [tboard_callback])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now we are ready to execute the script and debug performance bottlenecks using Tensorboard-Profiler.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sometimes when running Tensorflow we get some errors like: AttributeError: partially initialized module &amp;rsquo;tensorflow&amp;rsquo; has no attribute &amp;lsquo;&lt;strong&gt;version&lt;/strong&gt;&amp;rsquo; (most likely due to a circular import). To fix this error you can use the flag -m.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    python3 -m &amp;lt;your-python-file&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After running the script in different architectures we obtain the following results:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Input pipeline analyzer:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data preprocessing (ms)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Table 1: Data preprocessing in different architectures&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;X86&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;POWER8&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;POWER9&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;390&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;180&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;164&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Reading data from files in advance (including caching, prefetching, interleaving) (in ms):&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Table 2: Reading data from files in advance in different architectures&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;X86&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;POWER8&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;POWER9&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;6.7&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;~ 0&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;~0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Tensorflow stats:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Operations which consume more time:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Table 3: Operations which consume more time in x86&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Operation&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Occurrences&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;total time (us)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;112,868&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch::ParallelMap&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.907&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;106,162&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch::ParallelMap::ParallelMap&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.907&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;104,103&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Decode Png&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;decode_image/cond_jpeg/else/_1/cond_png/then/_0/DecodePng&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.910&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;79,162&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table 4: Operations which consume more time in POWER8&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Operation&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Occurrences&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;total time (us)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;131,659&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch::ParallelMap&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.673&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;23,513&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MatMul&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;gradient_tape/sequential/dense/MatMul&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;16,335&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.673&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;15,375&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table 5: Operations which consume more time in POWER9&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Operation&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Occurrences&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;total time (us)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;114,562&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;_FusedMatMul&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;sequential/dense/Relu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;21&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;30,306&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch::ParallelMap&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.676&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;20,957&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dataset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Iterator::Model::MapAndBatch::Prefetch&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2.675&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;16,722&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now we can analyze the dada and compare beteween different architectures. First we note that x86 consumes more time for data preprocessing and reading data from files in advance (Tables 1 and 2). In Tensorflow stats we can crack the entire code in operations but I&amp;rsquo;ll show only the top 4 time-consuming operations in tables 3, 4 and 5. However, you can get all operations in tensorboard-profiler in section Tensorflow Stats.
From tables 3, 4 and 5 we obtain that the type of operation differs a little, for example in table 3 we have Decode Png in top 4, whereas in power architectures (Tables 4 and 5) we have matmul. But in all 3 architectures Dataset is highly time-consuming.&lt;/p&gt;
&lt;p&gt;An interesting function in tensorboard-profiler is &lt;strong&gt;Recommendation for Next Step&lt;/strong&gt;. This function highlights some otimizations that could improve your program, for exemple, when I execute my program in POWER 8 we have some recommendations like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your program is HIGHLY input-bound because 68.8% of the total step time sampled is waiting for input. Therefore, you should first focus on reducing the input time&lt;/li&gt;
&lt;li&gt;7.3 % of the total step time sampled is spent on All Others time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next tools to use for reducing the input time&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;input_pipeline_analyzer (especially Section 3 for the breakdown of input operations on the Host)&lt;/li&gt;
&lt;li&gt;trace_viewer (look at the activities on the timeline of each Host Thread near the bottom of the trace view)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AI Profiling for POWER</title>
      <link>https://openpower.ic.unicamp.br/post/ai-profiling-for-power/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/ai-profiling-for-power/</guid>
      <description>&lt;p&gt;Although there is plenty information on AI profiling for x86_64 and ARM architectures, there is almost none on POWER.&lt;/p&gt;
&lt;p&gt;With that motivation in mind, this post aim to share some results on this subject.&lt;/p&gt;
&lt;p&gt;The program profiled was a python script that had a pre-trained ResNet50 with ImageNet weights, which was obtained from TensorFlow API.&lt;br&gt;
It aimed to classify 500 hot-dogs images downloaded from the ImageNet.&lt;br&gt;
The profiling was done using Perf for collecting PMU data and ipmitool for energy consumption data.&lt;/p&gt;
&lt;p&gt;Requirements for the pyhton script:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bare-metal machine&lt;/li&gt;
&lt;li&gt;ipmitool&lt;/li&gt;
&lt;li&gt;python 3.6&lt;/li&gt;
&lt;li&gt;TensorFlow 2.1.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Machine Stats:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;POWER9 Processor&lt;/li&gt;
&lt;li&gt;CPU(s): 128&lt;/li&gt;
&lt;li&gt;On-line CPU(s) list: 0-127&lt;/li&gt;
&lt;li&gt;Thread(s) per core: 4&lt;/li&gt;
&lt;li&gt;Core(s) per socket: 16&lt;/li&gt;
&lt;li&gt;Socket(s): 2&lt;/li&gt;
&lt;li&gt;NUMA node(s): 2&lt;/li&gt;
&lt;li&gt;Model: 2.2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find information on how to install TensorFlow on POWER in this post: &lt;a href=&#34;https://openpower.ic.unicamp.br/post/building-tensorflow-on-power/&#34;&gt;https://openpower.ic.unicamp.br/post/building-tensorflow-on-power/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Eleven tests were executed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications.resnet50 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ResNet50
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.preprocessing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; image
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow.keras.applications.resnet50 &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocess_input, decode_predictions
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datetime &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datetime
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;begin &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#folder = sys.argv[1]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;length &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;731&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;length &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (length &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;731&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Using maximum length: 731&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lenght &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;731&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;again &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argv[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;folder_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hot_dog&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ResNet50(weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;images &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(length):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    img_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; folder_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(i) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_img(img_path, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    images&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;img_to_array(img))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    images[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(images[i], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    images[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; preprocess_input(images[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(again):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(length):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(images[i])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;#print(decode_predictions(prediction[i], top=1)[0][0][1])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        strPrediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; decode_predictions(prediction, top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (strPrediction &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hotdog&amp;#39;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            count &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;#print(str(i) + &amp;#34; -&amp;gt; &amp;#34; + strPrediction)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Begin: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utcnow()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%H:%M:%S&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;End: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utcnow()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%H:%M:%S&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RIGHTS: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(count))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;WRONGS: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(again&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;length &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; count))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ACC: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(count&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(again&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;length)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Time Elapsed: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;s&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; begin))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Because the model is pre-trained, it obtained the same classification accuracy for every test.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;RIGHTS: 433
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;WRONGS: 67
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;profiling-using-perf&#34;&gt;Profiling using perf.&lt;/h3&gt;
&lt;p&gt;Perf is a profiling program included with the Linux kernel. Here it was used to instrument CPU performance counters.&lt;/p&gt;
&lt;p&gt;PMUs used:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;branches,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;branch-misses,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-misses,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cache-references,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cycles,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;instructions,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;idle-cycles-backend,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;idle-cycles-frontend.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following graphs shows the data fetched from those PMUs.&lt;br&gt;
Graphs:&lt;br&gt;
CPU Cycles:&lt;br&gt;
&lt;img src=&#34;cycles.png&#34; alt=&#34;CPU Cycles&#34;&gt;
Instructions:&lt;br&gt;
&lt;img src=&#34;instructions.png&#34; alt=&#34;Instructions&#34;&gt;
Cache-references:&lt;br&gt;
&lt;img src=&#34;cache-references.png&#34; alt=&#34;Cache-references&#34;&gt;
Cache-misses:&lt;br&gt;
&lt;img src=&#34;cache-misses.png&#34; alt=&#34;Cache-misses&#34;&gt;
Branches:&lt;br&gt;
&lt;img src=&#34;branches.png&#34; alt=&#34;Branches&#34;&gt;
Branch-misses:&lt;br&gt;
&lt;img src=&#34;branch-misses.png&#34; alt=&#34;Branch-misses&#34;&gt;
Time Elapsed:&lt;br&gt;
&lt;img src=&#34;time-elapsed.png&#34; alt=&#34;Time Elapsed&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;energy-consumption&#34;&gt;Energy consumption.&lt;/h3&gt;
&lt;p&gt;Make sure you are running on a bare-metal machine.&lt;/p&gt;
&lt;p&gt;How to use the ipmitool to get power consumption data:
Install ipmitool through:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get install ipmitool
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then run the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo ipmitool dcmi power reading
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Which is going to give you the output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Instantaneous power reading:                   262 Watts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Minimum during sampling period:                248 Watts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Maximum during sampling period:                263 Watts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Average power reading over sample period:      257 Watts
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    IPMI timestamp:                           Sun Nov  8 19:51:18 2020
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Sampling period:                          00000005 Seconds.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Power reading state is:                   activated
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This command was executed continuosly for 1500 seconds using a python script that would parse the results into a csv file.&lt;/p&gt;
&lt;p&gt;Altough the sampling period was used for reference in order to plot the following graph, it does not represent an accurate time series in the x axis.
For a better undertanding of power consumption profiling on POWER with ML algorithms, see the following post: &lt;a href=&#34;https://openpower.ic.unicamp.br/post/power-consumption-on-power/&#34;&gt;https://openpower.ic.unicamp.br/post/power-consumption-on-power/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;That said, the data was used to plot the following graph:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;powerConsumption.png&#34; alt=&#34;Energy Consumption&#34;&gt;&lt;/p&gt;
&lt;p&gt;It is possible to see the average of energy consumption for each test and, at the end, the energy consumption going back to a normal state.
It can also be observed that there is an increase close to 100W when a test begins to run.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello Minikube for ppc64le</title>
      <link>https://openpower.ic.unicamp.br/post/hello-minikube/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/hello-minikube/</guid>
      <description>&lt;p&gt;This tutorial shows you how to create a cluster for the Power architecture (ppc64le) using Minikube.&lt;/p&gt;
&lt;p&gt;The tutorial was performed on Ubuntu 20.10 (ppc64le), the packages were downloaded using the package repository from &lt;a href=&#34;https://openpower.ic.unicamp.br/project/power-repository/&#34;&gt;OpenPower Lab @ Unicamp&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;dependencies&#34;&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;The following packages are required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Minikube&lt;/li&gt;
&lt;li&gt;Kubectl&lt;/li&gt;
&lt;li&gt;Docker-ce&lt;/li&gt;
&lt;li&gt;Conntrack&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can use the commands below to solve the dependencies:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install docker-ce conntrack minikube kubectl
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Optionally, Kubeadm and Kubelet can be installed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;create-a-minikube-cluster&#34;&gt;Create a minikube cluster&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Start Minikube&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo minikube start --driver&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;none
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;The default drive is Docker, however the minikube does not recognize that Docker is available for ppc64le architecture and has an error.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To make &amp;rsquo;none&amp;rsquo; the default drive, use the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo minikube config set driver none
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;You may need to run the command:: &lt;code&gt;sudo sysctl fs.protected_regular=0&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Check Status&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo minikube status
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output is similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minikube
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;type: Control Plane
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;host: Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubelet: Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiserver: Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubeconfig: Configured
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Open the Kubernetes dashboard in a browser&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo minikube dashboard
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-a-deployment&#34;&gt;Create a Deployment&lt;/h2&gt;
&lt;p&gt;There are two structures in Kubernetes: Pod and Deployment. Pod can be a group of one or more Containers, while a Deployment checks, manages and restarts the pods. That is, the deployment is recommended when it will be used in a large group of pods.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a Deployment&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl create deployment hello-node --image&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;minicloud/node-server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://hub.docker.com/r/minicloud/node-server&#34;&gt;minicloud/node-server&lt;/a&gt;&lt;/em&gt;: is a public docker image created for the ppc64le architecture. The files used to build the image are in the &lt;a href=&#34;https://github.com/Unicamp-OpenPower/nodeServer&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;View the Deployment:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl get deployments
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output is similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME         READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-node   1/1     &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;            &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;           6m28s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;View the Pod:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl get pods
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output is similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                          READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-node-5dd47b76c8-l5vs2   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          6m51s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-a-service&#34;&gt;Create a Service&lt;/h2&gt;
&lt;p&gt;In order to be able to directly access the Pod, it is necessary to create a service.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a Service&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl expose deployment hello-node --type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;NodePort --port&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;View the Service&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo kubectl get services
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output is similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;          AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-node   NodePort    10.102.223.224   &amp;lt;none&amp;gt;        8080:31253/TCP   8s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubernetes   ClusterIP   10.96.0.1        &amp;lt;none&amp;gt;        443/TCP          14m
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Open the service in the browser: &lt;a href=&#34;http://localhost:8080/&#34;&gt;http://localhost:8080/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;hello-minikube.png&#34; alt=&#34;Hello Minikube in browser&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If it is not possible to access this port, change the 8080, for the 5 digit port that appears in the view. In that case it would be port 31253.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;clean-up&#34;&gt;Clean up&lt;/h2&gt;
&lt;p&gt;Now you can clean up the resources you created in your cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete service hello-node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete deployment hello-node
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Optionally, stop the Minikube:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minikube stop
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Optionally, delete the Minikube:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;minikube delete
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;tutorial-for-others-architectures&#34;&gt;Tutorial for others architectures&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/tutorials/hello-minikube/&#34;&gt;Hello Minikube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building Tensorflow on POWER - CPU only</title>
      <link>https://openpower.ic.unicamp.br/post/building-tensorflow-on-power/</link>
      <pubDate>Tue, 16 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://openpower.ic.unicamp.br/post/building-tensorflow-on-power/</guid>
      <description>&lt;p&gt;TensorFlow is a widespread software library for numerical computation using data flow graphs. It is very common on machine learning and deep neural networks projects. Therefore, today we are going to see how to install it on POWER with CPU only configuration.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;tf-logo.png&#34; alt=&#34;tf logo&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;update-032021&#34;&gt;&lt;em&gt;Update 03/2021&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;If you only want to install TensorFlow on POWER (and not build it), there is an easier way which is taught in the following tutorial: &lt;a href=&#34;https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power&#34;&gt;https://openpower.ic.unicamp.br/post/installing-tensorflow-on-power&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;outdated-&#34;&gt;&lt;em&gt;OUTDATED&lt;/em&gt; :&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;OUTDATED 09/2020&lt;/em&gt; The following tutorial is an outdated way of building TensorFlow on Power. If you still want to build TensorFlow from source by following this tutorial, proceed with caution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Before installing TensorFlow, there are a couple of details we have to pay attention to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Due to Bazel, one of TF dependencies, the operating system must be Ubuntu 14.04 or Ubuntu 16.04.&lt;/li&gt;
&lt;li&gt;We are going to use Python 2.7, since TF doesn&amp;rsquo;t seem to be supported by Python 3.5 &lt;strong&gt;on POWER&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;tensorflow-dependencies&#34;&gt;Tensorflow Dependencies&lt;/h1&gt;
&lt;p&gt;You can use the commands below to solve most of the dependencies:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install python-numpy python-dev python-pip python-wheel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;bazel-installation&#34;&gt;Bazel installation&lt;/h1&gt;
&lt;p&gt;Bazel is one of the TF dependencies, but its installation is less intuitive than the others due to its community not officially supporting POWER architecture. That said, we must compile it from the Source. First of all, we need to install its own dependencies by the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install unzip build-essential python openjdk-8-jdk protobuf-compiler zip g++ zlib1g-dev
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It is also important to add enviroment variables on .bashrc for JDK.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vi .bashrc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	export JAVA_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/usr/lib/jvm/java-8-openjdk-ppc64el
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	export JRE_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;JAVA_HOME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/jre
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	export CLASSPATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;.:&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;JAVA_HOME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/lib:&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;JRE_HOME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/lib
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	export PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;JAVA_HOME&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/bin:$PATH
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For compiling Bazel, we are going to download and unpack its distribution archive (the zip file from the release page &lt;a href=&#34;https://github.com/bazelbuild/bazel/releases&#34;&gt;https://github.com/bazelbuild/bazel/releases&lt;/a&gt;. The .sh is not compatible with ppc64le) and compile it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir bazel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd bazel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget -c https://github.com/bazelbuild/bazel/releases/download/0.11.1/bazel-0.11.1-dist.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;unzip bazel-0.11.1-dist.zip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./compile.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;if you want to download other version of bazel, this link must be switched by the one you are intenting to use.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Update 09/2020&lt;/em&gt;: It is also possible to perform the installation by following this &lt;a href=&#34;https://openpower.ic.unicamp.br/blog/installing-bazel-from-repository.html&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As we can see, this tutorial was tested with bazel 0.11.1, but feel free to try other version and see if it works properly.&lt;/p&gt;
&lt;p&gt;Also, if you are having any trouble about lack of resources, you can take a look on &amp;lsquo;Build issues and Support Websites&amp;rsquo; to see if there&amp;rsquo;s any link that could help you. Anticipating: if you don&amp;rsquo;t have memory enough and your Bazel can&amp;rsquo;t complete the compile step, you might have a problem with the garbage collector of JAVA (and there&amp;rsquo;s a link which explains how to deal with it).&lt;/p&gt;
&lt;h1 id=&#34;installing-tensorflow&#34;&gt;Installing Tensorflow&lt;/h1&gt;
&lt;p&gt;Since we are going to use the current version of TF, we need to clone it from the official GitHub and execute the configuration script.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/tensorflow/tensorflow
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ~/tensorflow
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./configure
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;On this step, we have to specify the pathname of all relevant TF dependencies and other build configuration options. On most of them we can use the answers suggested on each question. Here, I will show how it was done for this tutorial. (Yours might be a little different, depending on the pathnames)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify the location of python. &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Default is /usr/bin/python&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: /usr/bin/python2.7
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Found possible Python library paths:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  /usr/local/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  /usr/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please input the desired Python library path to use.  Default is &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;/usr/lib/python2.7/dist-packages&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: /usr/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Using python library path: /usr/local/lib/python2.7/dist-packages
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Y/N Answers given: All of them as suggested in each question.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please specify optimization flags to use during compilation when bazel option &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--config=opt&amp;#34;&lt;/span&gt; is specified &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Default is -march&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;native&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: -mcpu&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;native
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Configuration finished
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To build and install TF, we use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bazel build --copt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;-mcpu=native&amp;#34;&lt;/span&gt; --jobs &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --local_resources 2048,0.5,1.0 //tensorflow/tools/pip_package:build_pip_package
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg &lt;span style=&#34;color:#75715e&#34;&gt;#creates the pip package&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install /tmp/tensorflow_pkg/tensorflow-1.5.0rc0-cp27-cp27mu-linux_ppc64le.whl &lt;span style=&#34;color:#75715e&#34;&gt;#installs the pip package.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;This name depends on your operating system, Python version and CPU only vs. GPU support. Therefore, check it out its name before this step.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By this moment, your TF must be working. Remember not to import it into its own directory: you have to chance directory before executing Python.&lt;/p&gt;
&lt;h1 id=&#34;build-issues-and-support-websites&#34;&gt;Build Issues and Support Websites:&lt;/h1&gt;
&lt;p&gt;While testing this tutorial, I could separate some useful issues reports and links to help some of the troubles you might have on the way.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/14540&#34;&gt;https://github.com/tensorflow/tensorflow/issues/14540&lt;/a&gt; It solves a protobuf problem I had. It seems pretty common on PPC TF installation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/349&#34;&gt;https://github.com/tensorflow/tensorflow/issues/349&lt;/a&gt; This one is about local resources. If you are running out of memory (your build fails on C++ compilation rules), you have to specify your resources on the command line when you build TF. On the tutorial, it is already done.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/install/install_sources&#34;&gt;https://www.tensorflow.org/install/install_sources&lt;/a&gt; An official tutorial about how to install TF from Sources&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bazel.build/versions/master/install-compile-source.html&#34;&gt;https://docs.bazel.build/versions/master/install-compile-source.html&lt;/a&gt; An official tutorial about how to install Bazel from Sources.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/Building_TensorFlow_on_OpenPOWER_Linux_Systems?lang=en&#34;&gt;https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/Building_TensorFlow_on_OpenPOWER_Linux_Systems?lang=en&lt;/a&gt; IBM source about Tensorflow installation. Provides interesting information about bazel installation on PPC and how to install TF with GPU support. It also points to an IBM Bazel modified to PPC (which we are not using in this tutorial, but you can take a look on it).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/7979#issuecomment-283559640&#34;&gt;https://github.com/tensorflow/tensorflow/issues/7979#issuecomment-283559640&lt;/a&gt; An issue about enviroment variables: on the configuration step, if it does not recognize some of the TF variables, this might help you to solve the problem.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bazelbuild/bazel/issues/1308&#34;&gt;https://github.com/bazelbuild/bazel/issues/1308&lt;/a&gt; An issue about Bazel: &amp;ldquo;The system is out of resources&amp;rdquo;. You might need to add a command line on compile file to change the garbage collector size. On the issue on git, it&amp;rsquo;s suggested to change it to 384, but, at least on one of the computers I tried to compile, I needed to change it to 512 (in other words, change -J-Xmx384m on the solution line to -J-Xmx512m). It&amp;rsquo;s important to see that ideally we should not have to change the source code, but it solves the problem. Another option is to increase the memory of your system if it&amp;rsquo;s possible (recommended).&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
