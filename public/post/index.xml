<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | OpenPOWER@UNICAMP</title>
    <link>/post/</link>
      <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 19 May 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Posts</title>
      <link>/post/</link>
    </image>
    
    <item>
      <title>Installing spaCy on POWER8 or POWER9.</title>
      <link>/post/installing-spacy-power/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      <guid>/post/installing-spacy-power/</guid>
      <description>

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;SpaCy_logo.svg&#34; alt=&#34;Bazel Logo&#34; width=&#34;40%&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://spacy.io&#34; target=&#34;_blank&#34;&gt;spaCy&lt;/a&gt; is an open-source software library for advanced Natural Language Processing, written in Python and Cython. The library is published under the MIT license and currently offers statistical neural network models for English, German, Spanish, Portuguese, French, Italian, Dutch and multi-language NER, as well as tokenization for various other languages.&lt;/p&gt;

&lt;p&gt;Its installation is very straightforward using the &lt;a href=&#34;https://pypi.org/project/pip/&#34; target=&#34;_blank&#34;&gt;pip&lt;/a&gt; package manager. However, you will not succeed if you try to make it into a POWER processor. This is due to a problem with the headers of the Numpy library when using the pip. Thus, the easiest way to install spaCy is by using another package manager, &lt;a href=&#34;https://www.anaconda.com&#34; target=&#34;_blank&#34;&gt;Conda&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Conda is an open source, cross-platform, language-agnostic package manager and environment management system. It is released under the Berkeley Software Distribution License by Continuum Analytics.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;installing-python-3-7&#34;&gt;Installing Python 3.7&lt;/h1&gt;

&lt;p&gt;To install spaCy, you will need to have python 3.7. To verify that you have it installed, simply use the command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python3.7 --version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have not installed it, use the package manager of your system to install.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Start by updating the packages and installing the prerequisites:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt update
sudo apt install software-properties-common
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add the deadsnakes PPA to your sources list:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo add-apt-repository ppa:deadsnakes/ppa
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Once the repository is enabled, install Python 3.7 with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install python3.7
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;installing-conda&#34;&gt;Installing Conda&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; Download the &lt;a href=&#34;https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-ppc64le.sh&#34; target=&#34;_blank&#34;&gt;Anaconda installer for POWER8 and POWER9&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Enter the following on the download directory:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bash Anaconda3-2019.03-Linux-ppc64le.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; The installer prompts “In order to continue the installation process, please review the license agreement.” Click Enter to view license terms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.&lt;/strong&gt; Using Enter, scroll to the bottom of the license terms and enter “Yes” to agree to them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.&lt;/strong&gt; Click Enter to accept the default install location.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6.&lt;/strong&gt; Enter &amp;ldquo;yes&amp;rdquo; to initialize Anaconda3 by running conda init.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7.&lt;/strong&gt; Close and open your terminal window for the installation to take effect.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;source ~/.bashrc.
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;installing-spacy&#34;&gt;Installing spaCy&lt;/h1&gt;

&lt;p&gt;You only need to use the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install -c conda-forge spacy
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>How use scikit-learn and Jupyter remotely</title>
      <link>/post/how-use-scikit-learn-and-jupyter-remotely/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      <guid>/post/how-use-scikit-learn-and-jupyter-remotely/</guid>
      <description>

&lt;h2 id=&#34;introduction-and-prerequisites&#34;&gt;Introduction and Prerequisites&lt;/h2&gt;

&lt;p&gt;In this tutorial I will show how to use Jupyter in your browser to control scikit-learn running inside a VM.
First of all you need build and connect to VM, which is showed in &lt;a href=&#34;https://github.com/Unicamp-OpenPower/minicloud/wiki/Getting-Started-with-Minicloud&#34; target=&#34;_blank&#34;&gt;this tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;ssh-connection&#34;&gt;SSH connection&lt;/h2&gt;

&lt;p&gt;Now you need connect to VM via ssh using &lt;code&gt;-L 8888:localhost:8888&lt;/code&gt; flag, which will bind your computer port 8888 to port 8888 from VM:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh ubuntu@minicloud.parqtec.unicamp.br -i ~/.ssh/your-key.pem -p &amp;lt;vm-port&amp;gt; -L 8888:localhost:8888&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;instalation-and-executing&#34;&gt;Instalation and executing&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s update O.S., then install jupyter and sklearn:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;   sudo apt update
   sudo apt upgrade -y
   sudo apt  sudo apt install jupyter python3-sklearn python3-pandas -y
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Initiate jupyter notebook with &lt;code&gt;&amp;amp;&lt;/code&gt; flag, which will allow jupyter run in backgroud:
&lt;img src=&#34;jupyter-token.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;

&lt;p&gt;Open link showed by jupyter on your favorite browser:
&lt;img src=&#34;jupyter1.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;And now you are ready to use scikit-learn using jupyter remotely.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Installing Bazel on Power and Other Unsupported Architectures/Systems</title>
      <link>/post/installing-bazel-power-other-architectures-systems/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      <guid>/post/installing-bazel-power-other-architectures-systems/</guid>
      <description>

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;bazel-logo.svg&#34; alt=&#34;Bazel Logo&#34; width=&#34;40%&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Bazel is a free software tool that allows for the automation of building and testing of software. Similar to build tools like Make, Maven, and Gradle, Bazel builds software applications from source code using a set of rules.&lt;/p&gt;

&lt;p&gt;It uses a human-readable, high-level build language. Bazel supports projects in multiple languages and builds outputs for multiple platforms and supports large codebases across multiple repositories, and large numbers of users.&lt;/p&gt;

&lt;p&gt;In designing Bazel, emphasis has been placed on build speed, correctness, and reproducibility. The tool uses parallelization to speed up parts of the build process. It includes a Bazel Query language that can be used to analyze build dependencies in complex build graphs&lt;/p&gt;

&lt;p&gt;Bazel must have Power support in the future, making its installation possible through community-supported methods. However, currently, if you want to install on Power or other architectures or systems that do not have support, you need compiling Bazel from source.&lt;/p&gt;

&lt;div id=&#34;building&#34;&gt;So let&#39;s see how to install Bazel on architectures and systems not officially supported. I will use Ubuntu 14.04 as the basis of this tutorial, but it can be easily adapted to other Linux systems.&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;building-bazel-from-scratch-bootstrapping&#34;&gt;Building Bazel from scratch (bootstrapping)&lt;/h1&gt;

&lt;p&gt;Here we will see how to do self-compilation. If you are using Ubuntu 14.04 or Ubuntu 16.04 in ppc64le, you can skip right to: &lt;a href=&#34;#ready&#34; title=&#34;Using ready binaries&#34;&gt;Using ready binaries&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;First, install the prerequisites:&lt;/strong&gt;&lt;br /&gt;
Pkg-config&lt;br /&gt;
Zip, Unzip&lt;br /&gt;
G++&lt;br /&gt;
Zlib1g-dev&lt;br /&gt;
JDK 8 (you must install version 8 of the JDK. Versions other than 8 are not supported)&lt;br /&gt;
Python (versions 2 and 3 are supported, installing one of them is enough)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# add-apt-repository ppa:openjdk-r/ppa  
# apt-get update  
# apt-get install pkg-config zip unzip g++ zlib1g-dev openjdk-8-jdk python  
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Next, download the Bazel binary installer named bazel-&lt;version&gt;-dist.zip from the &lt;a href=&#34;https://github.com/bazelbuild/bazel/releases&#34; target=&#34;_blank&#34;&gt;Bazel releases page on GitHub&lt;/a&gt;:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://github.com/bazelbuild/bazel/releases/download/&amp;lt;version&amp;gt;/bazel-&amp;lt;version&amp;gt;-dist.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There is a single architecture-independent distribution archive. There are no architecture-specific or OS-specific distribution archives.&lt;/p&gt;

&lt;p&gt;You have to use the distribution archive to bootstrap Bazel. You cannot use a source tree cloned from GitHub (the distribution archive contains generated source files that are required for bootstrapping and are not part of the normal Git source tree).&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Unpack the zip file somewhere on disk:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unzip bazel-&amp;lt;version&amp;gt;-dist.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Run the compilation script:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bash ./compile.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This may take several minutes&amp;hellip;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;div id=&#34;ready&#34;&gt;And this should be the output:  &lt;/div&gt; 

&lt;p&gt;&lt;img src=&#34;build-successful.png&#34; alt=&#34;Bazel Logo&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;using-ready-binaries&#34;&gt;Using ready binaries&lt;/h1&gt;

&lt;p&gt;If you are using Ubuntu 14.04 or Ubuntu 16.04 in ppc64le, you can use our already compiled versions of the binaries.&lt;/p&gt;

&lt;p&gt;Make sure you have the JDK 8 installed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  java -version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;If you do not have it, you need to install it:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# add-apt-repository ppa:openjdk-r/ppa
# apt-get update
# apt-get install openjdk-8-jdk
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We have released the last 10 versions of Bazel already compiled in this link: &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/bazel/&#34; target=&#34;_blank&#34;&gt;https://oplab9.parqtec.unicamp.br/pub/ppc64el/bazel/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Download the desired version:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://oplab9.parqtec.unicamp.br/pub/ppc64el/bazel/ubuntu_&amp;lt;version&amp;gt;/bazel_bin_&amp;lt;version&amp;gt;
# mv bazel_bin_&amp;lt;version&amp;gt; bazel
# chmod +x bazel
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;installing-bazel&#34;&gt;Installing Bazel&lt;/h1&gt;

&lt;p&gt;Finally, the compiled output is placed into output/bazel (or it is in the current directory if you have downloaded the binary). This is a self-contained Bazel binary, without an embedded JDK. You can copy it anywhere or use it in-place. For convenience we recommend copying this binary to a directory that&amp;rsquo;s on your PATH (such as /usr/local/bin on Linux).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# mv output/bazel /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# mv bazel /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;When using Bazel for the first time, it will extract the installation and prepare everything. To do this, simply use the command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;From now on, Bazel is installed and to use it simply use the command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  bazel &amp;lt;command&amp;gt; &amp;lt;options&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;using-bazel-to-compile-bazel&#34;&gt;Using Bazel to compile Bazel&lt;/h1&gt;

&lt;p&gt;Once installed, you can use Bazel itself to compile a new version. To do this, simply download the desired version (as seen in &lt;a href=&#34;#building&#34; title=&#34;Building Bazel from scratch&#34;&gt;Building Bazel from scratch&lt;/a&gt;) or even the developing version on &lt;a href=&#34;https://github.com/bazelbuild/bazel&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; and use the following command in the directory of the downloaded files:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  Bazel build //src:bazel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bazel.build/&#34; target=&#34;_blank&#34;&gt;https://docs.bazel.build/&lt;/a&gt;
&lt;br&gt;
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Building a opensuse openstack image</title>
      <link>/post/opensuse-tutorial/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      <guid>/post/opensuse-tutorial/</guid>
      <description>

&lt;p&gt;This tutorial I will show how create a openstack image (.qcow2) of opensuse from a ISO image using qemu.
In this tutorial will be used opensuse Tumbleweed ppc64 le (because it&amp;rsquo;s the most challenging), but similiar process can be done for leap (15 and 42.3) and Tumbleweed ppc64be.&lt;/p&gt;

&lt;h2 id=&#34;preparing-environment&#34;&gt;Preparing environment&lt;/h2&gt;

&lt;p&gt;First we need download opensuse image from repository (&lt;a href=&#34;https://software.opensuse.org/distributions/tumbleweed&#34; target=&#34;_blank&#34;&gt;Tumbleweed&lt;/a&gt;, &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/pub/ppc64el/opensuse/&#34; target=&#34;_blank&#34;&gt; leap 15&lt;/a&gt; and  &lt;a href=&#34;http://download.opensuse.org/ports/ppc/distribution/leap/42.3/iso/&#34; target=&#34;_blank&#34;&gt;leap 42.3&lt;/a&gt;) and sha256 of respective image.&lt;/p&gt;

&lt;p&gt;Execute sha256:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sha256sum openSUSE-Tumbleweed-DVD-ppc64le-Current.iso
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Compare sha256sum output with sha256 downloaded:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;715d9f89d90eb795b6a64ffe856aa5b7f3a64c7195a9ede8abea14a9d4f69e67
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install qemu using:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt update
sudo apt install qemu-kvm libvirt-clients libvirt-daemon-system -y
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we need create a disk .qcow2 to install our O.S. with this command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;qemu-img create -f qcow2 openSUSE-Tumbleweed-ppc64le.qcow2 5G
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Execute qemu to run the instaler:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo qemu-system-ppc64le -enable-kvm -m 1024 -cdrom openSUSE-Tumbleweed-DVD-ppc64le-Current.iso -drive file=openSUSE-Tumbleweed-ppc64le.qcow2,media=disk,if=virtio -nographic -smp cores=1,threads=1 -monitor pty -serial stdio -nodefaults -netdev user,id=enp0s1 -device virtio-net-pci,netdev=enp0s1 -boot order=d
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;installing-opensuse&#34;&gt;Installing openSUSE&lt;/h2&gt;

&lt;p&gt;Select your language (using tab and arrows):
&lt;img src=&#34;Language-selection-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 1: Language selection screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select te most suitable bundle for your goal:
&lt;img src=&#34;Bundle-selector-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 2: Bundle selector screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select expert partitioner:
&lt;img src=&#34;Partioner-selection-screen.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Partioner-selection-screen2.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 3-4: Partioner selection screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select the hard drive that you want install opensuse:
&lt;img src=&#34;Drive-selector-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 5: Drive selector screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Add new partition selecting &lt;code&gt;add&lt;/code&gt; button:
&lt;img src=&#34;Partition-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 6: Partition screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Set &lt;code&gt;partition size&lt;/code&gt; to &lt;code&gt;8 MiB&lt;/code&gt;:
&lt;img src=&#34;Partition-size-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 7: Partition size screen (Boot)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select &lt;code&gt;raw partition&lt;/code&gt;:
&lt;img src=&#34;Partition-role-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 8: Partition role screen (Boot)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select file system as &lt;code&gt;Ext4&lt;/code&gt; (or other filesystem of your preference):
&lt;img src=&#34;File-System-type.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 9: File System type (Boot)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select partition as &lt;code&gt;PReP Boot Partition&lt;/code&gt; and &lt;code&gt;next&lt;/code&gt;:
&lt;img src=&#34;Partition-type.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 10: Partition type (Boot)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;The boot partition was create and now we will create O.S. partition, select &lt;code&gt;add&lt;/code&gt; and inside Patition size screen select &lt;code&gt;Maximum Size&lt;/code&gt;:
&lt;img src=&#34;Partition-size-screen-2.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 11: Partition size screen (O.S) &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select &lt;code&gt;Operating System&lt;/code&gt; option:
&lt;img src=&#34;Partition-role-screen-2.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 12: Partition role screen (O.S) &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select file system as &lt;code&gt;Ext4&lt;/code&gt; again (or other filesystem of your preference):
&lt;img src=&#34;File-System-type-2.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 13: File System type (O.S) &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Left selected &lt;code&gt;Linux Native&lt;/code&gt;:
&lt;img src=&#34;Partition-type-2.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 14: Partition type (O.S) &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Left &lt;code&gt;Mount device&lt;/code&gt; as &lt;code&gt;/&lt;/code&gt; and select &lt;code&gt;next&lt;/code&gt;:
&lt;img src=&#34;Mount-point.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 15: Mount point &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Partition configuration will look like this:
&lt;img src=&#34;Final-partion-configuration.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 16: Final partion configuration &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;We will receive warning message but we can ignore it and select &lt;code&gt;yes&lt;/code&gt;:
&lt;img src=&#34;Warning-message.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 17: Warning message &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Next&lt;/code&gt; again:
&lt;img src=&#34;Sumary-partition-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 18: Sumary partition screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Select your clock and time zone:
&lt;img src=&#34;Clock-and-time-zone-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 19: Clock and time zone screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Put you username and password:
&lt;img src=&#34;Clock-and-time-zone-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 20: Local user screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Accept instalation and install:
&lt;img src=&#34;Summary-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 21: Summary screen &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Instalation-screen.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 22: Instalation screen &lt;/p&gt;&lt;/p&gt;

&lt;h2 id=&#34;preparing-image&#34;&gt;Preparing image&lt;/h2&gt;

&lt;p&gt;Update all packages and install necessary ones (you can also uninstall unnecessary packages):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo zypper update
sudo zypper install cloud-init growpart yast2-network yast2-services-manager acpid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove hard-coded MAC address:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo cat /dev/null &amp;gt; /etc/udev/rules.d/70-persistent-net.rules
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enable ssh and cloud-init:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl enable cloud-init
sudo systemctl enable sshd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Disable firewall:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl stop firewalld
sudo systemctl disable firewalld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inside &lt;code&gt;/etc/default/grub&lt;/code&gt; file, set grub timeout to 0:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GRUB_TIMEOUT=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Grub-configuration.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 23: Grub configuration &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Update grub:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo exec grub2-mkconfig -o /boot/grub2/grub.cfg &amp;quot;$@&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;only-for-opensuse-tumbleweed-le-be&#34;&gt;Only for openSUSE Tumbleweed Le/Be&lt;/h2&gt;

&lt;p&gt;Opensuse Tumbleweed ppc64 Le/Be lacks some parameters on cloud-init.service, this causes instability on boot, which, sometimes, causes network connection errors. This problem was &lt;a href=&#34;https://bugzilla.opensuse.org/show_bug.cgi?id=1111441&#34; target=&#34;_blank&#34;&gt;reported&lt;/a&gt; and hopefully will be solved when you read this tutorial.&lt;/p&gt;

&lt;p&gt;Edit &lt;code&gt;cloud-init.service&lt;/code&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo vim /etc/systemd/system/cloud-init.target.wants/cloud-init.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add lines bellow after &lt;code&gt;After=systemd-networkd-wait-online.service&lt;/code&gt; line:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Requires=wicked.service
After=wicked.service
After=dbus.service
Conflicts=shutdown.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Configuration-of-cloud-init.service.png&#34; width=&#34;100%&#34;/&gt;
&lt;p style=&#34;text-align: center;&#34;&gt; Figure 24: Configuration of cloud-init.service &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Reload cloud-init service:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl restart cloud-init
sudo systemctl daemon-reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because Leap 42.3 ppc64Le&amp;rsquo;s configuration fits better for a cloud role, so we will replace cloud.cfg of Tumbleweed by Leap42.3&amp;rsquo;s cloud.cfg:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo vim /etc/cloud/cloud.cfg
&lt;/code&gt;&lt;/pre&gt;

&lt;script src=&#34;https://gist.github.com/Igortorrente/6d770e47d589db89fe2f1b49218f1c58.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;cleaning-image&#34;&gt;Cleaning image&lt;/h2&gt;

&lt;p&gt;Now delete all remaining data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat /dev/null &amp;gt; ~/.bash_history &amp;amp;&amp;amp; history -c &amp;amp;&amp;amp; sudo su
cat /dev/null &amp;gt; /var/log/wtmp
cat /dev/null &amp;gt; /var/log/btmp
cat /dev/null &amp;gt; /var/log/lastlog
cat /dev/null &amp;gt; /var/run/utmp
cat /dev/null &amp;gt; /var/log/auth.log
cat /dev/null &amp;gt; /var/log/kern.log
cat /dev/null &amp;gt; ~/.bash_history &amp;amp;&amp;amp; history -c &amp;amp;&amp;amp; sudo poweroff
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;adding-to-openstack&#34;&gt;Adding to openstack&lt;/h2&gt;

&lt;p&gt;And finaly add image to openstack:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;glance image-create --file openSUSE-Tumbleweed-ppc64le.qcow2 --container-format bare --disk-format qcow2 --property hw_video_model=vga --name &amp;quot;openSUSE Tumbleweed ppc64le&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If all the steps worked, you should see these messages at the next boot.
&lt;img src=&#34;Boot.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up a FTP Server with Access List and Disk Quota</title>
      <link>/post/ftp-server-setup-with-acl-and-quota/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      <guid>/post/ftp-server-setup-with-acl-and-quota/</guid>
      <description>

&lt;p&gt;In this guide, we will show how to setup a public FTP server with directory access control and disk quota per-user.
We used Ubuntu Server 16.04, running on ppc64le architecture, but it should work on other architectures as well, because no exclusive software was used, only open source software.&lt;/p&gt;

&lt;h1 id=&#34;disk-space&#34;&gt;Disk space&lt;/h1&gt;

&lt;p&gt;You will need an &lt;code&gt;ext4&lt;/code&gt; partition with enough space, that can be mounted on &lt;code&gt;/&lt;/code&gt; or on &lt;code&gt;/var/www&lt;/code&gt;. If you need help, look at &lt;a href=&#34;https://www.howtogeek.com/106873/how-to-use-fdisk-to-manage-partitions-on-linux/&#34; target=&#34;_blank&#34;&gt;this tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After that, create the directories that will be used in the web and ftp servers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mkdir /var/www/html
sudo mkdir /var/www/html/pub
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set the permissions to these directories:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo chown nobody:nogroup /var/www/html
sudo chmod a-w /var/www/html
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;http-server-apache&#34;&gt;HTTP Server (apache)&lt;/h1&gt;

&lt;p&gt;We intend that our files can be accessed through a web browser. In that case, we will need a HTTP Server, like Apache.&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Install the package &lt;code&gt;apache2&lt;/code&gt;, with the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install apache2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the service to make sure that the web server works:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo systemctl restart apache2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;content&#34;&gt;Content&lt;/h2&gt;

&lt;p&gt;You can create a welcome page in HTML with links to &lt;code&gt;/pub&lt;/code&gt; folder, to show the files though the browser. Your page &lt;code&gt;index.html&lt;/code&gt; need to be in the directory &lt;code&gt;/var/www/html&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For reference, you can look at our web page in &lt;a href=&#34;https://oplab9.parqtec.unicamp.br/&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;ssl-certificate-certbot&#34;&gt;SSL Certificate (certbot)&lt;/h1&gt;

&lt;p&gt;Certbot is a client that deploy free SSL certificates from Let&amp;rsquo;s Encrypt to any web server.
If you already have a SSL certificate, you can &lt;a href=&#34;#firewall-ufw&#34;&gt;&lt;em&gt;skip this part&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;installation-1&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Run these commands to install the package &lt;code&gt;certbot&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install software-properties-common
sudo add-apt-repository ppa:certbot/certbot
sudo apt-get update
sudo apt-get install python-certbot-apache
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;We need to configure the web server to work with the certificate. Run this command to use the Certbot certificate with the Apache web server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo certbot --apache
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The certificate expires in 90 days, so you need to renew this certificate periodically. To schedule the execution of &lt;code&gt;certobot renew&lt;/code&gt; command, we will use &lt;code&gt;cronjob&lt;/code&gt;, a time-base job scheduler. To use the scheduler, run this command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo crontab -e
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And add the following line in the end of the file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0 0 * * * sudo certbot renew
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save the file.
After that, the renew command is scheduled to run everyday.&lt;/p&gt;

&lt;h1 id=&#34;firewall-ufw&#34;&gt;Firewall (ufw)&lt;/h1&gt;

&lt;p&gt;The UFW is an easy frontend interface for iptables. We need to configure the firewall to work with the other installed software.&lt;/p&gt;

&lt;h2 id=&#34;installation-2&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Install the package &lt;code&gt;ufw&lt;/code&gt; to manage the firewall, with the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install ufw
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuration-1&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Forwarding the ports:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo ufw allow 20/tcp
sudo ufw allow 21/tcp
sudo ufw allow 990/tcp
sudo ufw allow 60000:60500/tcp
sudo ufw allow ssh
sudo ufw allow &#39;Apache Full&#39;
sudo ufw status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart to conclude the steps:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo ufw disable
sudo ufw enable
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;ftp-server-vsftpd&#34;&gt;FTP Server (vsftpd)&lt;/h1&gt;

&lt;p&gt;We will use the vsftpd software to run the FTP server, the default in the Ubuntu, CentOS, Fedora, NimbleX, Slackware and RHEL Linux distributions.&lt;/p&gt;

&lt;h2 id=&#34;installation-3&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Install the package &lt;code&gt;vsftpd&lt;/code&gt; with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install vsftpd
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuration-2&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Backup your original file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo cp /etc/vsftpd.conf /etc/vsftpd.orig
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the configuration file with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo nano /etc/vsftpd.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Example config file:
&lt;script src=&#34;https://gist.github.com/lcnzg/233a7b406f2528cb0d517fc6fbeed5c9.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;In the previous config, we allowed read permission for anonymous.&lt;/p&gt;

&lt;p&gt;To create the userlist that have permission to access the FTP server, and allow the anonymous user, use the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo touch /etc/vsftpd.userlist
sudo echo &amp;quot;anonymous&amp;quot; &amp;gt;&amp;gt; /etc/vsftpd.userlist
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;disabling-shell-for-ftp-users&#34;&gt;Disabling shell for ftp users&lt;/h2&gt;

&lt;p&gt;With these commands, we will create a new shell with no functionalities, to restrict the access of the FTP users:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo touch /bin/ftponly
sudo echo -e &#39;#!/bin/sh\necho &amp;quot;This account is limited to FTP access only.&amp;quot;&#39; &amp;gt;&amp;gt; /bin/ftponly
sudo chmod a+x /bin/ftponly
sudo echo &amp;quot;/bin/ftponly&amp;quot; &amp;gt;&amp;gt; /etc/shells
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the FTP server service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo systemctl restart vsftpd
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;disk-quota&#34;&gt;Disk Quota&lt;/h1&gt;

&lt;p&gt;We will use a disk quota to limit the disk space used by the FTP users.&lt;/p&gt;

&lt;h2 id=&#34;installation-4&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Install the package &lt;code&gt;quota&lt;/code&gt; with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install quota
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuration-3&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Edit the &lt;code&gt;fstab&lt;/code&gt; file and add &lt;code&gt;usrquota&lt;/code&gt; option in the partition you chose earlier:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo nano /etc/fstab
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remount partition and enable the quota:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mount -o remount /var/www
sudo quotacheck -cum /var/www
sudo quotaon /var/www
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;defining-a-default-quota&#34;&gt;Defining a default quota&lt;/h2&gt;

&lt;p&gt;Create a new user to copy the quota settings for the new users:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo adduser ftpuser
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Insert a password.&lt;/p&gt;

&lt;p&gt;After that, you will need to edit the quota of &lt;code&gt;ftpuser&lt;/code&gt; with this command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo edquota ftpuser
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Put the values of soft and hard quota in these columns.&lt;/p&gt;

&lt;p&gt;Example: 10GB: 10000000 and 10485760 in block quota session.&lt;/p&gt;

&lt;p&gt;Let 0 if you don&amp;rsquo;t want to have a limit.&lt;/p&gt;

&lt;p&gt;Set the default quota user as &lt;code&gt;ftpuser&lt;/code&gt; to copy a quota for the new users:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo sed -i -e &#39;s/.*QUOTAUSER=&amp;quot;&amp;quot;.*/QUOTAUSER=&amp;quot;ftpuser&amp;quot;/&#39; /etc/adduser.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;

&lt;p&gt;There are a few commands useful for controlling the quota:
- &lt;code&gt;quota user&lt;/code&gt; shows the &lt;code&gt;user&lt;/code&gt; quota.
- &lt;code&gt;repquota -a&lt;/code&gt; shows the general quota report.
- &lt;code&gt;edquota user&lt;/code&gt; to edit &lt;code&gt;user&lt;/code&gt; quota.&lt;/p&gt;

&lt;h1 id=&#34;access-list-acl&#34;&gt;Access List (acl)&lt;/h1&gt;

&lt;p&gt;We will use Access List Control, or ACL, to have a better control of file permissions. With ACL we can set different file permissions, in different directories, to each FTP user.&lt;/p&gt;

&lt;h2 id=&#34;installation-5&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Install the package &lt;code&gt;acl&lt;/code&gt; with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install acl
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuration-4&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Edit the &lt;code&gt;fstab&lt;/code&gt; file and add &lt;code&gt;acl&lt;/code&gt; option in the &lt;code&gt;/var/www&lt;/code&gt; partition:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo nano /etc/fstab
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remount the partition to apply the changes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mount -o remount /var/www
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;commands-1&#34;&gt;Commands&lt;/h2&gt;

&lt;p&gt;The commands used to enable write permission to &lt;code&gt;$USER&lt;/code&gt; in &lt;code&gt;$DIRECTORY&lt;/code&gt; were:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;setfacl -d -R -m u:$USER:rwX $DIRECTORY
setfacl -R -m u:$USER:rwX $DIRECTORY
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;adding-new-users&#34;&gt;Adding new users&lt;/h1&gt;

&lt;p&gt;We created the following script to manage the creation of new users:
&lt;script src=&#34;https://gist.github.com/lcnzg/54a44d87babcf3f33523fbcae152c47f.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chmod +x create_user.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add new users by running the script this way:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo ./create_user.sh &#39;user&#39; &#39;pass&#39; &#39;directory&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Directory instructions:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;for the root of FTP directory, use &lt;code&gt;.&lt;/code&gt; .&lt;/li&gt;
&lt;li&gt;for other directories, don&amp;rsquo;t write the initial and final slashes (ex: ppc64el/debian for /www/html/pub/ppc64el/debian/).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Should any problem with file permissions ocurr, use the &lt;code&gt;fix_acl.sh&lt;/code&gt; script, that will remake the permissions based on &lt;code&gt;acl.list&lt;/code&gt; file.&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/lcnzg/51258738564989bc8e2b0b7d25397b02.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Add execute permission to the script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chmod +x fix_acl.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run the script with sudo, this way:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo ./fix_acl.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-install-the-apache-web-server-on-ubuntu-16-04&#34; target=&#34;_blank&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-install-the-apache-web-server-on-ubuntu-16-04&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-setup-a-firewall-with-ufw-on-an-ubuntu-and-debian-cloud-server&#34; target=&#34;_blank&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-setup-a-firewall-with-ufw-on-an-ubuntu-and-debian-cloud-server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-vsftpd-for-a-user-s-directory-on-ubuntu-16-04&#34; target=&#34;_blank&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-set-up-vsftpd-for-a-user-s-directory-on-ubuntu-16-04&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Building Tensorflow on POWER - CPU only</title>
      <link>/post/building-tensorflow-on-power/</link>
      <pubDate>Tue, 16 Jan 2018 00:00:00 +0000</pubDate>
      <guid>/post/building-tensorflow-on-power/</guid>
      <description>

&lt;style&gt;
    [data-text] {
    }
    [data-text]::after {
      content: attr(data-text);
    }
&lt;/style&gt;

&lt;p&gt;TensorFlow is a widespread software library for numerical computation using data flow graphs. It is very common on machine learning and deep neural networks projects. Therefore, today we are going to see how to install it on POWER with CPU only configuration.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;tf-logo.png&#34; style=&#34;padding: 25px 0px&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Before installing TensorFlow, there are a couple of details we have to pay attention to:
1. Due to Bazel, one of TF dependencies, the operating system must be Ubuntu 14.04 or Ubuntu 16.04.
2. We are going to use Python 2.7, since TF doesn&amp;rsquo;t seem to be supported by Python 3.5 &lt;strong&gt;on POWER&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&#34;tensorflow-dependencies&#34;&gt;Tensorflow Dependencies&lt;/h1&gt;

&lt;p&gt;You can use the commands below to solve most of the dependencies:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;apt-get update
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;apt-get install python-numpy python-dev python-pip python-wheel
&lt;/pre&gt;&lt;/div&gt;

&lt;h1 id=&#34;bazel-installation&#34;&gt;Bazel installation&lt;/h1&gt;

&lt;p&gt;Bazel is one of the TF dependencies, but its installation is less intuitive than the others due to its community not officially supporting POWER architecture. That said, we must compile it from the Source. First of all, we need to install its own dependencies by the following commands:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;apt-get update
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;apt-get install unzip build-essential python openjdk-8-jdk protobuf-compiler zip g++ zlib1g-dev
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It is also important to add enviroment variables on .bashrc for JDK.&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;vi .bashrc
    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-ppc64el
    export JRE_HOME=${JAVA_HOME}/jre
    export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
    export PATH=${JAVA_HOME}/bin:$PATH
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For compiling Bazel, we are going to download and unpack its distribution archive (the zip file from the release page &lt;a href=&#34;https://github.com/bazelbuild/bazel/releases&#34; target=&#34;_blank&#34;&gt;https://github.com/bazelbuild/bazel/releases&lt;/a&gt;. The .sh is not compatible with ppc64le) and compile it.&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;mkdir bazel
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;cd bazel
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;wget -c https://github.com/bazelbuild/bazel/releases/download/0.11.1/bazel-0.11.1-dist.zip #if you want to download other version of bazel, this link must be switched by the one you are intenting to use.
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;unzip bazel-0.11.1-dist.zip
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;./compile.sh
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;As we can see, this tutorial was tested with bazel 0.11.1, but feel free to try other version and see if it works properly.&lt;/p&gt;

&lt;p&gt;Also, if you are having any trouble about lack of resources, you can take a look on &amp;lsquo;Build issues and Support Websites&amp;rsquo; to see if there&amp;rsquo;s any link that could help you. Anticipating: if you don&amp;rsquo;t have memory enough and your Bazel can&amp;rsquo;t complete the compile step, you might have a problem with the garbage collector of JAVA (and there&amp;rsquo;s a link which explains how to deal with it).&lt;/p&gt;

&lt;h1 id=&#34;installing-tensorflow&#34;&gt;Installing Tensorflow&lt;/h1&gt;

&lt;p&gt;Since we are going to use the current version of TF, we need to clone it from the official GitHub and execute the configuration script.&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;git clone https://github.com/tensorflow/tensorflow
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;cd ~/tensorflow
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;./configure
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On this step, we have to specify the pathname of all relevant TF dependencies and other build configuration options. On most of them we can use the answers suggested on each question. Here, I will show how it was done for this tutorial. (Yours might be a little different, depending on the pathnames)&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Please specify the location of python. [Default is /usr/bin/python]: &lt;strong&gt;/usr/bin/python2.7&lt;/strong&gt;
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python2.7/dist-packages]:&lt;strong&gt; /usr/lib/python2.7/dist-packages &lt;/strong&gt;

Using python library path: /usr/local/lib/python2.7/dist-packages

#Y/N Answers given: All of them as suggested in each question.

Please specify optimization flags to use during compilation when bazel option &#34;--config=opt&#34; is specified [Default is -march=native]: &lt;strong&gt;-mcpu=native&lt;/strong&gt;
Configuration finished
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To build and install TF, we use:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;bazel build --copt=&#34;-mcpu=native&#34; --jobs 1 --local_resources 2048,0.5,1.0 //tensorflow/tools/pip_package:build_pip_package
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg #creates the pip package
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;pip install /tmp/tensorflow_pkg/tensorflow-1.5.0rc0-cp27-cp27mu-linux_ppc64le.whl #installs the pip package. This name depends on your operating system, Python version and CPU only vs. GPU support. Therefore, check it out its name before this step.
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;By this moment, your TF must be working. Remember not to import it into its own directory: you have to chance directory before executing Python.&lt;/p&gt;

&lt;h1 id=&#34;build-issues-and-support-websites&#34;&gt;Build Issues and Support Websites:&lt;/h1&gt;

&lt;p&gt;While testing this tutorial, I could separate some useful issues reports and links to help some of the troubles you might have on the way.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/14540&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorflow/tensorflow/issues/14540&lt;/a&gt; It solves a protobuf problem I had. It seems pretty common on PPC TF installation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/349&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorflow/tensorflow/issues/349&lt;/a&gt; This one is about local resources. If you are running out of memory (your build fails on C++ compilation rules), you have to specify your resources on the command line when you build TF. On the tutorial, it is already done.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/install/install_sources&#34; target=&#34;_blank&#34;&gt;https://www.tensorflow.org/install/install_sources&lt;/a&gt; An official tutorial about how to install TF from Sources&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.bazel.build/versions/master/install-compile-source.html&#34; target=&#34;_blank&#34;&gt;https://docs.bazel.build/versions/master/install-compile-source.html&lt;/a&gt; An official tutorial about how to install Bazel from Sources.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/Building_TensorFlow_on_OpenPOWER_Linux_Systems?lang=en&#34; target=&#34;_blank&#34;&gt;https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/Building_TensorFlow_on_OpenPOWER_Linux_Systems?lang=en&lt;/a&gt; IBM source about Tensorflow installation. Provides interesting information about bazel installation on PPC and how to install TF with GPU support. It also points to an IBM Bazel modified to PPC (which we are not using in this tutorial, but you can take a look on it).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/7979#issuecomment-283559640&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorflow/tensorflow/issues/7979#issuecomment-283559640&lt;/a&gt; An issue about enviroment variables: on the configuration step, if it does not recognize some of the TF variables, this might help you to solve the problem.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bazelbuild/bazel/issues/1308&#34; target=&#34;_blank&#34;&gt;https://github.com/bazelbuild/bazel/issues/1308&lt;/a&gt; An issue about Bazel: &amp;ldquo;The system is out of resources&amp;rdquo;. You might need to add a command line on compile file to change the garbage collector size. On the issue on git, it&amp;rsquo;s suggested to change it to 384, but, at least on one of the computers I tried to compile, I needed to change it to 512 (in other words, change -J-Xmx384m on the solution line to -J-Xmx512m). It&amp;rsquo;s important to see that ideally we should not have to change the source code, but it solves the problem. Another option is to increase the memory of your system if it&amp;rsquo;s possible (recommended).&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Integrating OpenStack Ansible with Let’s Encrypt</title>
      <link>/post/integrating-openstack-ansible-with-lets-encrypt/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      <guid>/post/integrating-openstack-ansible-with-lets-encrypt/</guid>
      <description>

&lt;style&gt;
    [data-text] {
    }
    [data-text]::after {
      content: attr(data-text);
    }
&lt;/style&gt;

&lt;p&gt;Deploying HTTPS is essential for security, and OpenStack Ansible does it by default. However, if no certificates are provided, it will generate self-signed ones, which although are more secure than no SSL at all, it will trigger a warning when accessing the dashboard in the browser. Luckily, the Let’s Encrypt project provides signed SSL certificates for free.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;browser-warning.png&#34; width=&#34;80%&#34; style=&#34;padding: 25px 0px&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Let’s Encrypt requires your server to be validated before issuing the certificate. This means it will create a temporary file on your server and then try to access it from their servers, to verify that you control the domain you&amp;rsquo;re trying to get a certificate to.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;lets-encrypt-validation.png&#34; width=&#34;80%&#34; style=&#34;padding: 25px 0px&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;It can launch a temporary web server to do so, however, this will require to stop your usual web server (e.g. Apache) and lead to a few seconds of downtime. Alternatively, you can provide your web root path. Let’s Encrypt will create the files there, and they will be served directly by your usual web server. This approach does not lead to downtime, but presents some additional challenges when using it with OpenStack Ansible:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;OpenStack Ansible does not have a web root path out of the box to be used by Let’s Encrypt.&lt;/li&gt;
&lt;li&gt;SSL certificates must be provided to HAProxy, which runs on metal, while the Apache server to be used by Let’s Encrypt runs inside a container.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;openstack-ansible.png&#34; width=&#34;60%&#34; style=&#34;padding: 25px 0px&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h1 id=&#34;installing-openstack-ansible&#34;&gt;Installing OpenStack Ansible&lt;/h1&gt;

&lt;p&gt;Install OpenStack as usual, without providing any certificates. Self-signed ones will be therefore generated, and we will replace them later.&lt;/p&gt;

&lt;h1 id=&#34;enable-web-root&#34;&gt;Enable web root&lt;/h1&gt;

&lt;p&gt;We will not actually create a web root. Since Let’s Encrypt only requires writing on &lt;code&gt;your-domain.com/.well-known&lt;/code&gt; directory, we will create an alias to the &lt;code&gt;.well-known&lt;/code&gt; path.&lt;/p&gt;

&lt;p&gt;Attach to the horizon container. Replace the container name accordingly with your setup. If you don’t know the name, run &lt;code&gt;lxc-ls | grep horizon&lt;/code&gt; to get the container name.&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;lxc-attach -n infra1_horizon_container-XXXXXXXX
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Add the following line to &lt;code&gt;/etc/apache2/sites-enabled/openstack-dashboard.conf&lt;/code&gt;, inside the &lt;code&gt;&amp;lt;VirtualHost *:80&amp;gt;&lt;/code&gt; tag&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Alias /.well-known /var/www/html/.well-known 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the apache2 service:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;service apache2 restart
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, we can use &lt;code&gt;/var/www/html&lt;/code&gt; as our web root, at least from the Let’s Encrypt Certbot point of view.&lt;/p&gt;

&lt;h1 id=&#34;getting-the-certificates&#34;&gt;Getting the certificates&lt;/h1&gt;

&lt;p&gt;Now install the Let’s Encrypt Certbot. The intention is to only get the certificates files, not configure them in Apache. Use the following commands to do so:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;apt-get update
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;apt-get install software-properties-common
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;add-apt-repository ppa:certbot/certbot
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;apt-get update
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;apt-get install certbot 
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;certbot certonly
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When asked to choose an authentication method, choose &lt;code&gt;2&lt;/code&gt;&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;How would you like to authenticate with the ACME CA?
-------------------------------------------------------------------------------
1: Spin up a temporary webserver (standalone)
2: Place files in webroot directory (webroot)
-------------------------------------------------------------------------------
Select the appropriate number [1-2] then [enter] (press &amp;#39;c&amp;#39; to cancel): &lt;strong&gt;2&lt;/strong&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When asked for the webroot, input &lt;code&gt;/var/www/html&lt;/code&gt;&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Select the webroot for your-domain.com:
-------------------------------------------------------------------------------
1: Enter a new webroot
-------------------------------------------------------------------------------
Press 1 [enter] to confirm the selection (press &amp;#39;c&amp;#39; to cancel): 1
Input the webroot for unicamp.br: (Enter &amp;#39;c&amp;#39; to cancel): &lt;strong&gt;/var/www/html&lt;/strong&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After this, the certificate files will be placed on &lt;code&gt;/etc/letsencrypt/live/your-domain.com&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&#34;allow-the-container-to-copy-files-to-the-host&#34;&gt;Allow the container to copy files to the host&lt;/h1&gt;

&lt;p&gt;Generate an SSH key &lt;strong&gt;inside the container&lt;/strong&gt;:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;ssh-keygen -t rsa
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Print the public key and copy it to the clipboard:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;cat /root/.ssh/id_rsa.pub
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now append the container&amp;rsquo;s public key to the authorized_keys file &lt;strong&gt;in the host&lt;/strong&gt;:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;echo [PASTE THE COPIED KEY HERE] &gt;&gt; /root/.ssh/authorized_keys
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will allow the container to copy the certificates to the host using &lt;code&gt;scp&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;applying-the-certificates-in-haproxy&#34;&gt;Applying the certificates in HAProxy&lt;/h1&gt;

&lt;p&gt;To use them in HAProxy, we must concatenate some files. Replace &lt;code&gt;your-domain.com&lt;/code&gt; accordingly.
&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;cat /etc/letsencrypt/live/your-domain.com/privkey.pem &amp;gt; /etc/letsencrypt/live/your-domain.com/haproxy.key
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;cat /etc/letsencrypt/live/your-domain.com/cert.pem /etc/letsencrypt/live/your-domain.com/chain.pem /etc/letsencrypt/live/your-domain.com/privkey.pem &amp;gt; /etc/letsencrypt/live/your-domain.com/haproxy.pem
&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;Set the permissions properly:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;chmod 640 /etc/letsencrypt/live/your-domain.com/haproxy.key
&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;chmod 644 /etc/letsencrypt/live/your-domain.com/haproxy.pem
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Still inside the horizon container, copy the files we just generated to the host. Replace &lt;code&gt;your-domain.com&lt;/code&gt; and &lt;code&gt;HOST_IP_ADDRESS&lt;/code&gt; accordingly.&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;scp /etc/letsencrypt/live/your-domain.com/haproxy.* HOST_IP_ADDRESS:/etc/ssl/private
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now &lt;strong&gt;exit the container&lt;/strong&gt; and apply the new certificate:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;service haproxy reload
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;secure.png&#34; width=&#34;60%&#34; style=&#34;padding: 10px 0px 0px 0px&#34;/&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h1 id=&#34;renewing-the-certificates-automatically&#34;&gt;Renewing the certificates automatically&lt;/h1&gt;

&lt;p&gt;As Let’s Encrypt certificates are only valid for 90 days, it is highly advisable to schedule automatic renewing. We can do this using crontab inside the horizon container.&lt;/p&gt;

&lt;p&gt;Attach to the horizon container. Replace the container name accordingly with your setup. If you don’t know the name, run &lt;code&gt;lxc-ls | grep horizon&lt;/code&gt; to get the container name.&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;lxc-attach -n infra1_horizon_container-XXXXXXXX
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Open the crontab editor:&lt;/p&gt;

&lt;div class=&#34;codehilite&#34;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span data-text=&#34;# &#34;&gt;&lt;/span&gt;crontab -e
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Place this line at the end of the file, replacing &lt;code&gt;your-domain.com&lt;/code&gt; and &lt;code&gt;HOST_IP_ADDRESS&lt;/code&gt; accordingly.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;26 3 * * 5 certbot renew &amp;amp;&amp;amp; cat /etc/letsencrypt/live/your-domain.com/privkey.pem &amp;gt; /etc/letsencrypt/live/your-domain.com/haproxy.key &amp;amp;&amp;amp; cat /etc/letsencrypt/live/your-domain.com/cert.pem /etc/letsencrypt/live/your-domain.com/chain.pem /etc/letsencrypt/live/your-domain.com/privkey.pem &amp;gt; /etc/letsencrypt/live/your-domain.com/haproxy.pem &amp;amp;&amp;amp; scp /etc/letsencrypt/live/your-domain.com/haproxy.* HOST_IP_ADDRESS:/etc/ssl/private &amp;amp;&amp;amp; ssh HOST_IP_ADDRESS service haproxy reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will run every week, but it will only actually renew the certificate at most every 60 days, as only certificates that expire in less than 30 days are renewed. Running it more often than every 60 days makes it safer, as even if it fails to run once after the 60 days window, it will still run again before the certificate expire.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Install and initial configuration Buildbot on Fedora, Ubuntu and Debian</title>
      <link>/post/buildbot-tutorial/</link>
      <pubDate>Fri, 22 Sep 2017 00:00:00 +0000</pubDate>
      <guid>/post/buildbot-tutorial/</guid>
      <description>

&lt;p&gt;Buildbot its tool to automate compilation and tests. This tutorial we will install it on three important distro and run it.&lt;/p&gt;

&lt;h1 id=&#34;1-installation-dependencies&#34;&gt;1 - Installation dependencies:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Installation of necessary packages to correct installation of Buildbot bundle.&lt;/p&gt;

&lt;h2 id=&#34;fedora-25&#34;&gt;Fedora 25:&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo dnf install python-devel python-pip redhat-rpm-config make gcc
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;fedora-26&#34;&gt;Fedora 26:&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo dnf install python-pip redhat-rpm-config make gcc
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ubuntu-and-debian&#34;&gt;Ubuntu and Debian:&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install Python-dev build-essential python-pip 
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;2-installation-without-virtualenv&#34;&gt;2 - Installation without virtualenv:&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo pip install --upgrade pip 
sudo pip install &#39;buildbot[bundle]&#39; 
sudo pip install buildbot-grid-view 
sudo pip install buildbot-worker
sudo pip install setuptools-trial
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;2-5-installation-with-virtualenv-optional&#34;&gt;2.5 - Installation with virtualenv (optional):&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;First we need install virtual environment.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;fedora&#34;&gt;Fedora:&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo dnf install python-virtualenv 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ubuntu-and-debian-1&#34;&gt;Ubuntu and Debian:&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt install python-virtualenv 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Now we need activate the environment&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;virtualenv --no-site-packages YourSandbox
source YourSandbox/bin/activate
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;instalation&#34;&gt;Instalation:&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install --upgrade pip 
pip install &#39;buildbot[bundle]&#39; 
pip install buildbot-grid-view 
pip install buildbot-worker 
pip install setuptools-trial
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3-initial-master-setup&#34;&gt;3- Initial Master setup:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Creation of folder where Buildbot archives will stay:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p BuildBot 
cd BuildBot 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Creation of Master with name&lt;code&gt;[master]&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;buildbot create-master master 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Create-master.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The configuration of all functions of Buildbot its done in configuration file inside Master folder, to simplify we will use the sample configuration file provided in default template of Master &lt;code&gt;[master.cfg.sample]&lt;/code&gt;, but it’s needed be renamed to &lt;code&gt;[master.cfg]&lt;/code&gt; to be recognized by Buildbot:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mv master/master.cfg.sample master/master.cfg 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Here we will start Master daemon:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;buildbot start master 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Start-master.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;4-initial-worker-setup&#34;&gt;4- Initial Worker setup:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Here we will create a worker (previously slave) with name &lt;code&gt;[worker]&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;buildbot-worker create-worker worker localhost example-worker pass 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;Create-start-Worker.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;the-command-syntax&#34;&gt;The command syntax:&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;* buildbot-worker = Buildbot Worker program. 
* create-worker = Command to creation of Worker
* worker = Name of worker folder 
* localhost = Master location on the network (This example Master are in the same VM)
* example-worker = Name of worker 
* pass = Authentication password 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Start of worker daemon:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;buildbot-worker start worker 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Access address &lt;a href=&#34;http://localhost:8010/&#34; target=&#34;_blank&#34;&gt;http://localhost:8010/&lt;/a&gt; on your browser.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;Buildbot-interface.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to OpenCL2CUDA</title>
      <link>/post/opencl2cuda/</link>
      <pubDate>Wed, 07 Jun 2017 00:00:00 +0000</pubDate>
      <guid>/post/opencl2cuda/</guid>
      <description>

&lt;h1 id=&#34;introduction-to-opencl2cuda&#34;&gt;Introduction to OpenCL2CUDA&lt;/h1&gt;

&lt;p&gt;We all know that software is replacing many people functions. Said that, many very complicated data processing
are now made by computers, that are getting better and better ways to do those tasks. There are many libraries
and frameworks that helps programmers and engineers writing code to process some big amount of data. Two of these
well known libraries are OpenCL, developed for heterogeneous computing (gpu, processors, fpga), and CUDA, a NVIDIA
library created so people can write code to run on their GPUs. These libraries have some similar routines, cause there
are many steps you have to do on both of them. Thinking about it, I started writing a OpenCL to CUDA converter.&lt;/p&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;The implementation of this code still really simple, since all I am doing is searching for some OpenCL functions and
replacing it for its equivalent on CUDA. Besides, if its not a direct translation, the converter suggests some possible fixes
for you code. To find the suggestions on your code search for the #tranlation# word. We are using Python 3. To run this code
all you have to do is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chmod +x createCUDAkernel.py (just the first time)
./createCUDAkernel.py --opencl_name=&amp;quot;name of the opencl file&amp;quot; --main_name=&amp;quot;name of the C/C++ file&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;how-to-contribute&#34;&gt;How to contribute&lt;/h2&gt;

&lt;p&gt;Now, I am searching for CUDA and OpenCL codes that do the same thing, so I can go on this project. Besides, you can
&lt;a href=&#34;https://github.com/Guilhermeslucas/OpenCL2CUDA&#34; target=&#34;_blank&#34;&gt;fork&lt;/a&gt; the project on Github.&lt;/p&gt;

&lt;p&gt;Thanks a lot.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to PowerGraph</title>
      <link>/post/powergraph/</link>
      <pubDate>Tue, 30 May 2017 00:00:00 +0000</pubDate>
      <guid>/post/powergraph/</guid>
      <description>

&lt;h1 id=&#34;introduction-to-powergraph&#34;&gt;Introduction to PowerGraph&lt;/h1&gt;

&lt;p&gt;As computers evolve, people are trying new methods do analyse how good some machine
is when compared to another one. The amount of energy that some machine is
consuming, seems to be a nice measure, once we are willing to produce faster and
cheaper.
IPMI(Intelligent Platform Management Interface), on the other side,
is a set of computer interface specifications for an autonomous computer
subsystem that provides management and monitoring capabilities independently
of the host system. One of the measures that IPMI allow us to do is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dcmi power reading
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command shows the instant power consumption. With this tools, my team decided
to create a software that gets informations about the consumption of a machine
and exports it on a readable way. Thats how we did it:&lt;/p&gt;

&lt;h2 id=&#34;infrastructure&#34;&gt;Infrastructure&lt;/h2&gt;

&lt;p&gt;The infrastructure was not so complicated to configure. We have to download some
packages and set some configurations (process we are automating with Ansible). All
the system is deployed on Minicloud. The packages (all via apt) we are using are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ipmitool&lt;/li&gt;
&lt;li&gt;apache2&lt;/li&gt;
&lt;li&gt;python2.7&lt;/li&gt;
&lt;li&gt;python-pip&lt;/li&gt;
&lt;li&gt;git&lt;/li&gt;
&lt;li&gt;htop&lt;/li&gt;
&lt;li&gt;tmux&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Besides, we are using &lt;code&gt;crontab&lt;/code&gt; to be sure our service is still runing, and if
it is not, restart it. We are doing this verification every ten minutes with the&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-killer.sh```&#34;&gt;To solve all ```Python``` dependencies you can run:   

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pip install -r requirements.txt&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;### Apache configurations
Here you will install two modules in your apache server and change the virtual
host configuration file. Doing this you will be able to control your browser&#39;s cache.

In your server terminal run:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sudo a2enmod headers
sudo a2enmod expires
sudo service apache2 restart&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;After that, find your virtual host configuration file
(*/etc/apache2/sites-available/default/000-default.conf* if you are using ubuntu OS)
and insert the following lines, adjusting the parameters according to your needs:

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;Directory /var/www/html&gt;
   ExpiresActive On
   ExpiresDefault &amp;ldquo;access plus 10 minutes&amp;rdquo;
   ExpiresByType text/html &amp;ldquo;access plus 1 day&amp;rdquo;
   ExpiresByType text/javascript &amp;ldquo;access plus 1 day&amp;rdquo;&lt;/p&gt;

&lt;p&gt;# if it is your interest, you can set a specific expiration time for your csv file
   # ExpiresByType text/csv &amp;ldquo;access plus 30 seconds&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;FilesMatch &#34;file.csv&#34;&gt;
         Header set Cache-control &amp;ldquo;no-cache&amp;rdquo;
   &lt;/FilesMatch&gt;
&lt;/Directory&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## Back-end code
PowerGraph was totally developed using ```Python```. There are three main codes:   

- powergraph.py
- graph_csv.py
- csvcreator.py

Below, I will explain each code and its function.

### powergraph.py   
This is the code that keeps getting power info about a machine and save it to 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;tinyDB``` or prompt the result to user. You can run it using the command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python2.7 powergraph.py --host=&amp;quot;server address&amp;quot; --port=&amp;quot;server port&amp;quot; 
--user=&amp;quot;allowed user&amp;quot; --passwd=&amp;quot;password for this user&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can use the optional parameter &lt;code&gt;--store&lt;/code&gt; in order to save the infos
as json on tinydb. Without this parameter, the script will print on the terminal.
Besides, you can use &lt;code&gt;--feedback&lt;/code&gt; with store in order to see the measures
status.
If you want to set the time interval that a new csv file is generated, you can
use the flag &lt;code&gt;--csv_interval&lt;/code&gt;. The &lt;code&gt;--tail_length&lt;/code&gt; is used to set the
number of lines the csv file will have.&lt;/p&gt;

&lt;h3 id=&#34;csvcreator-py&#34;&gt;csvcreator.py&lt;/h3&gt;

&lt;p&gt;This is the code that converts the JSON stored on &lt;code&gt;tinyDB&lt;/code&gt; for a &lt;code&gt;csv&lt;/code&gt;
file. This code is really important, cause our front end is expecting a &lt;code&gt;csv&lt;/code&gt;
with two columns: timestamp and consumption.
In order to run this code, you have to store the data of &lt;code&gt;powergraph.py&lt;/code&gt; on the
database, as we explained before. To run this use:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python2.7 csvcreator.py --jsonfile=&amp;quot;generated_json_name&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are two optional arguments: &lt;code&gt;--date&lt;/code&gt;, to create the csv only with
the data from a specific day and &lt;code&gt;--name&lt;/code&gt;, with the name you want your&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-csv```&#34;&gt;
### graph_csv.py
This is the code that orchestrates the other ones. It is a multithread code that 
creates one thread always running with the ```powergraph.py``` code and another 
one generating a new thread with ```csvcreator``` running from time to time
updating the measures. To run this code use:

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;python2.7 graph_csv.py &amp;ndash;host=&amp;ldquo;server address&amp;rdquo; &amp;ndash;port=&amp;ldquo;server port&amp;rdquo;
&amp;ndash;user=&amp;ldquo;allowed user&amp;rdquo; &amp;ndash;passwd=&amp;ldquo;password for this user&amp;rdquo;
&amp;ndash;jsonfile=&amp;ldquo;path to bd jsonfile&amp;rdquo;
```&lt;/p&gt;

&lt;p&gt;Besides, you can use the following optional arguments:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;interval: interval between each ipmi measure (default=10)&lt;/li&gt;
&lt;li&gt;nread: number of ipmi measures to be done (default=infinity)&lt;/li&gt;
&lt;li&gt;csv_interval: interval that a new csv file is made (deafult=300s)&lt;/li&gt;
&lt;li&gt;tail_length: size of the csv files (default=300)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;front-end-code&#34;&gt;Front-end code&lt;/h2&gt;

&lt;p&gt;In order to create an interactive website that plot a graph from the csv file,
you first need to deal with the following dependencies:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;apache configurations&lt;/li&gt;
&lt;li&gt;javascript libraries&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After that, we have developed the code in &lt;strong&gt;javascript/graph.js&lt;/strong&gt; where
you can read and present in real time the data provided by the back-end.&lt;/p&gt;

&lt;h3 id=&#34;javascript-libraries&#34;&gt;Javascript libraries&lt;/h3&gt;

&lt;p&gt;Here we have three libraries included in our html file (index.html).&lt;/p&gt;

&lt;p&gt;The first one is the &lt;strong&gt;D3.js&lt;/strong&gt; library, a worldwide known tool to create
dynamic and interactive data visualizations, in other words, this is the engine
of the website. Insert in your html body the &lt;code&gt;&amp;lt;script src=&amp;quot;http://d3js.org/d3.v4.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;
to get the most recent code from D3.js.&lt;/p&gt;

&lt;p&gt;The next library, &lt;strong&gt;Moment.js&lt;/strong&gt;, is used to manipulate date objects and in our
case, for example, it allows us to show the time adjusted to the user&amp;rsquo;s location.
You can download the code from the following address &lt;a href=&#34;https://momentjs.com/downloads/moment.min.js&#34; target=&#34;_blank&#34;&gt;https://momentjs.com/downloads/moment.min.js&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;strong&gt;D3-tip&lt;/strong&gt; library just inserts tooltips in the graph for a better experience of use. This library was donwloaded from &lt;a href=&#34;https://github.com/Caged/d3-tip/blob/master/index.js&#34; target=&#34;_blank&#34;&gt;https://github.com/Caged/d3-tip/blob/master/index.js&lt;/a&gt;. It is also interesting that you take a look our style implementation for the tooltips from the file &lt;strong&gt;style/style.css&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;If you want to see the project working, acces this
&lt;a href=&#34;http://oplab134.parqtec.unicamp.br/powergraph&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;. If you want to contribute, acces the
&lt;a href=&#34;https://github.com/Unicamp-OpenPower/powergraph&#34; target=&#34;_blank&#34;&gt;github link&lt;/a&gt;. Hope you all enjoy
it. Thanks a lot!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Acessing a Docker Container outside Minicloud</title>
      <link>/post/external_docker/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      <guid>/post/external_docker/</guid>
      <description>

&lt;p&gt;#Acessing a Docker Container outside Minicloud
Docker containers are widely used nowadays for making software development and delivery easier, since it isolates the container from the rest of the system. This is very useful, cause the developer can install any software, depencies to run the project perfectly, delivering the &amp;ldquo;whole package&amp;rdquo; to anyone who wants to run it.
Some applications are expected to access or be accessed from outside, like a webserver, Jenkins, and so on. To do it, you have to map a container port with a server port.&lt;/p&gt;

&lt;h2 id=&#34;maping-a-container-port-with-a-server-port&#34;&gt;Maping a Container port with a server port&lt;/h2&gt;

&lt;p&gt;Is very simple and useful to do it. All you have to do is to include a parameter on command line when launching a container with &lt;code&gt;docker run&lt;/code&gt;, like this example running a Jenkins container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -i -t -p &amp;quot;physical machine port&amp;quot;:&amp;quot;container port&amp;quot; guilhermeslucas/jenkins:2.0 /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this example Jenkins container is running through port &amp;ldquo;container port&amp;rdquo; and you can access it by reaching the &amp;ldquo;physical machine port&amp;rdquo; of the server.&lt;/p&gt;

&lt;h2 id=&#34;acessing-docker-container-from-a-local-browser&#34;&gt;Acessing Docker Container from a local browser&lt;/h2&gt;

&lt;p&gt;Some applications are configured or managed using the browser. In this case, you can run the application on a server, but configure it using a ssh tunnel on your local machine. This is very simple too, just add a parameter on the ssh command line, mapping it correctly, like the example.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh user@host -L local-port:host:remote-port
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it can be used like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh guilherme@123.456.78.910 -L 8080:localhost:8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this example, the 8080 remote port will be forward to &lt;code&gt;localhost:8080&lt;/code&gt; and you can access it via browser.&lt;/p&gt;

&lt;p&gt;So, you&amp;rsquo;ll have to map a container port with a server port and forward this server port on your localhost, on any port not in use.&lt;/p&gt;

&lt;p&gt;This should do the work.&lt;/p&gt;

&lt;p&gt;Written by Guilherme Lucas. You can see some of my work at my &lt;a href=&#34;https://github.com/Guilhermeslucas&#34; target=&#34;_blank&#34;&gt;Github Page&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Brief tutorial about how to use the SDAccel service</title>
      <link>/post/sdaccel/</link>
      <pubDate>Thu, 06 Oct 2016 00:00:00 +0000</pubDate>
      <guid>/post/sdaccel/</guid>
      <description>

&lt;h1 id=&#34;how-to-use-the-sdaccel-service&#34;&gt;How to use the SDAccel Service&lt;/h1&gt;

&lt;p&gt;SDAccel is a service that allow the user to load C/C++ aplications and optmize it using FPGA acceleration.
To use this service, first go to the link below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://ny1.ptopenlab.com/sdaccel/auth/login/?next=/sdaccel/project/#/projects/b767365a-8402-41a5-97b4-d148c359b114/detail?_k=p64eew
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this page, you can enter your username and password to log in the SDAccel service. If you do not have on account,
just create one and get back to that link.&lt;/p&gt;

&lt;p&gt;You will be redirect to a page with the following tabs:
- &lt;em&gt;Overview&lt;/em&gt; : this page contains some explanation about how the SDAccel is built and the advantages of using a service like that.
- &lt;em&gt;Document&lt;/em&gt; : tutorials about SDAccel and some C/C++ code to run.
- &lt;em&gt;Project&lt;/em&gt; : manage your projects and upload some code.&lt;/p&gt;

&lt;p&gt;To create a new project, go to &lt;em&gt;Project&lt;/em&gt; -&amp;gt; &lt;em&gt;New Project&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Just put a any name and description and press &lt;em&gt;Submit&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Click on the project name (that should be blue) and you wil be redirect to a files page.&lt;/p&gt;

&lt;p&gt;Go to the &lt;em&gt;compile&lt;/em&gt; tab and wait a little till the loading is finished and, the &lt;em&gt;console password&lt;/em&gt; on the password place and hit &lt;em&gt;Enter&lt;/em&gt;.
A desktop environment will appear on the screen.&lt;/p&gt;

&lt;p&gt;Now, on the virtualized desktop, go to &lt;em&gt;Applications&lt;/em&gt; -&amp;gt; &lt;em&gt;System Tools&lt;/em&gt; -&amp;gt; &lt;em&gt;Terminal&lt;/em&gt;. Now type the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd
mkdir test
cd test
git clone https://github.com/Guilhermeslucas/SDAccel_Examples.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, close the terminal and click on the &lt;em&gt;SDAccel Icon&lt;/em&gt; on the desktop, and hit ok on the first window and &lt;em&gt;close the welcome tab&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;On the &lt;em&gt;Project Explorer&lt;/em&gt; -&amp;gt; &lt;em&gt;New&lt;/em&gt; -&amp;gt; &lt;em&gt;Xilinx SDAccel Project&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now, enter any string to be the &lt;em&gt;Project Name&lt;/em&gt; and change the locarion for the folder you placed the vadd project(just the &lt;em&gt;src&lt;/em&gt; folder, from de &lt;em&gt;SDACell_Examples&lt;/em&gt;.
I will name the project as &lt;em&gt;tutorial_code&lt;/em&gt;.
The next step, is to click with the right button of the button on the &lt;em&gt;project folder&lt;/em&gt; and hit &lt;em&gt;build project&lt;/em&gt;. It will ask you to create a solution.
Go ahed and create one. In order to do that click on &lt;em&gt;add&lt;/em&gt;(change the name if you want) -&amp;gt; &lt;em&gt;ok&lt;/em&gt; -&amp;gt; &lt;em&gt;&amp;gt;&amp;gt;&lt;/em&gt; -&amp;gt; &lt;em&gt;ok&lt;/em&gt;
Now, try to build the project again as we said above (it should take some seconds).&lt;/p&gt;

&lt;p&gt;Now, open a &lt;em&gt;terminal&lt;/em&gt; and go to the &lt;em&gt;src&lt;/em&gt; folder for the project we are using. In that folder, should appear o .tcl file. Type:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sdaccel &amp;quot;some_name&amp;quot;.tcl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It will run and the results will appear on the folder.&lt;/p&gt;

&lt;p&gt;Note: if you prefer a &lt;a href=&#34;https://www.youtube.com/watch?v=3pFlAyPXCKo&#34; target=&#34;_blank&#34;&gt;video tutorial on YouTube&lt;/a&gt;, Bruno made a really good one.&lt;/p&gt;

&lt;p&gt;Hope it was helpful.&lt;/p&gt;

&lt;p&gt;Post written by Guilherme Lucas.
You can see some of my work at &lt;a href=&#34;https://github.com/Guilhermeslucas&#34; target=&#34;_blank&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting Up SuperVessel and SSH connection to Machines on Debian Based</title>
      <link>/post/supervessel/</link>
      <pubDate>Fri, 19 Aug 2016 00:00:00 +0000</pubDate>
      <guid>/post/supervessel/</guid>
      <description>

&lt;h1 id=&#34;setting-up-supervessel-and-ssh-connection-to-the-machines-on-debian-based&#34;&gt;Setting Up SuperVessel and SSh connection to the Machines on Debian Based&lt;/h1&gt;

&lt;p&gt;SuperVessel is a cloud based plataform created by IBM Research - China
It allows you to set up containers on the cloud to run experiments,
test aplications, do some data analysis and so on. One great feature
of SuperVessel is to allow FPGA and GPU acelleration for C/C++
aplications.&lt;/p&gt;

&lt;h2 id=&#34;creating-an-acount-on-supervessel&#34;&gt;Creating an acount on SuperVessel&lt;/h2&gt;

&lt;p&gt;First, go to the page below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://ptopenlab.com/cloudlabconsole/?cm_mc_uid=35942743919214714482383&amp;amp;cm_mc_sid_50200000=1471628149#/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When you reach this adress, you will see that the first item of the
Service Zone is for &lt;strong&gt;SuperVessel Cloud&lt;/strong&gt;. Click on &lt;strong&gt;Apply VM -&amp;gt; Direct Acces&lt;/strong&gt;.
After doing that, you can &lt;strong&gt;login&lt;/strong&gt;, or &lt;strong&gt;create an account&lt;/strong&gt;. You can login as &lt;strong&gt;Community user&lt;/strong&gt; . Do one of these
steps and you have an SuperVessel account. This wil allow you to use all the other services on the page, like Acceleration and Big Data Services.&lt;/p&gt;

&lt;h2 id=&#34;setting-up-a-machine&#34;&gt;Setting up a Machine&lt;/h2&gt;

&lt;p&gt;After creating an account, you&amp;rsquo;re good to launch a machine. On the left side of the page, click on &lt;strong&gt;Instances&lt;/strong&gt;. On the up menu of the page, there is a &lt;strong&gt;Current Region&lt;/strong&gt; box. Make sure it is assigned to Beijing so we can access the machines via SSH easily.
Now, click on &lt;strong&gt;Launch Instance&lt;/strong&gt;. This should redirect you to a page with the specs of the machine on it. On the first drop-down menu, select &lt;strong&gt;Launch Docker Image&lt;/strong&gt; and choose the specs that best fit your needs and then click on the button on the bottom of the forms to launch the instance and wait. It will appear a box with the instance&amp;rsquo;s information. If you want to access the machine from the browser, go to &lt;strong&gt;More Actions -&amp;gt; Console&lt;/strong&gt;. The informations to log in appear on the top of the terminal.&lt;/p&gt;

&lt;h2 id=&#34;connecting-vpn&#34;&gt;Connecting VPN&lt;/h2&gt;

&lt;p&gt;First, install the VPNC:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install vpnc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, create a SuperVessel conf file with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo vim /etc/vpnc/supervessel.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note: you can use any editor, just don&amp;rsquo;t forget to run with sudo or as root user.
The content of this file has to be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IPSec gateway 36.110.51.131
IPSec ID Gemini    
IPSec secret G3m!ni1bmVpn           
Xauth username PoXXXX (change PoXXXX to your own VPN account)    
Xauth password secret_password (change secret_passsword to your own VPN password) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The Xauth username and password have to be changed to your personal informattion, that you can find at the person symbol ate the upper left of the SuperVessel page, that you used to create an instance. Click on &lt;strong&gt;VPN Conf&lt;/strong&gt; and put the Beijing fields on the &lt;strong&gt;supervessel.conf&lt;/strong&gt; file.
Now, run the vpnc:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo vpnc-connect supervessel.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A message like that should appear:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;VPNC started in background (pid: 12434)...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;running-ssh&#34;&gt;Running SSH&lt;/h2&gt;

&lt;p&gt;Now, on the &lt;strong&gt;Instances&lt;/strong&gt; page, find the &lt;strong&gt;External IP(VPN)&lt;/strong&gt; field. Now run:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh opuser@ExternalIP 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note: change ExternalIP with the number you just saw. You can use ssh -X to xforward and ssh -C to compress connection.&lt;/p&gt;

&lt;p&gt;After you logout, don&amp;rsquo;t forget to run :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo vpnc-disconnect
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That should do the work!&lt;/p&gt;

&lt;p&gt;Post written by Guilherme Lucas.
You can see some of my work at &lt;a href=&#34;https://github.com/Guilhermeslucas&#34; target=&#34;_blank&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a continuous integration platform using Jenkins and GitHub</title>
      <link>/post/building-a-continuous-integration-platform-using-jenkins-and-github/</link>
      <pubDate>Wed, 15 Jun 2016 00:00:00 +0000</pubDate>
      <guid>/post/building-a-continuous-integration-platform-using-jenkins-and-github/</guid>
      <description>

&lt;p&gt;Continuous integration allows code to be tested automatically every time it’s changed, detecting errors as early as possible. In this tutorial a CI using a GitHub repository will be approached.&lt;/p&gt;

&lt;h1 id=&#34;step-1-installing-and-setting-up-jenkins-and-git&#34;&gt;Step 1: Installing and setting up Jenkins and Git&lt;/h1&gt;

&lt;p&gt;To install Jenkins, execute the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add -
sudo sh -c &#39;echo deb http://pkg.jenkins.io/debian-stable binary/ &amp;gt; /etc/apt/sources.list.d/jenkins.list&#39;
sudo apt-get update
sudo apt-get install jenkins
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To install git, simply execute:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Access Jenkins through &lt;a href=&#34;http://localhost:8080&#34; target=&#34;_blank&#34;&gt;http://localhost:8080&lt;/a&gt; and follow the instructions for the initial setup. Choose &lt;strong&gt;Install suggested plugins&lt;/strong&gt; when asked.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;plugins.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;step-2-creating-a-job&#34;&gt;Step 2: Creating a job&lt;/h1&gt;

&lt;p&gt;In Jenkins dashboard, click on &lt;strong&gt;New Item&lt;/strong&gt;, give your project a name and select &lt;strong&gt;Freestyle project&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;You may choose &lt;strong&gt;Discard old builds&lt;/strong&gt; in order to avoid using too much storage in the long term.&lt;/p&gt;

&lt;p&gt;Check &lt;strong&gt;GitHub project&lt;/strong&gt; and enter the GitHub URL of the project. Use the format &lt;em&gt;&lt;a href=&#34;https://github.com/YOUR-USERNAME/YOUR-REPOSITORY&#34; target=&#34;_blank&#34;&gt;https://github.com/YOUR-USERNAME/YOUR-REPOSITORY&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In source code management section, choose &lt;strong&gt;Git&lt;/strong&gt; and enter the repository URL the same way as above.&lt;/p&gt;

&lt;h2 id=&#34;step-2-1-choosing-the-build-trigger&#34;&gt;Step 2.1: Choosing the build trigger&lt;/h2&gt;

&lt;p&gt;Under &lt;strong&gt;Build Triggers&lt;/strong&gt; it is possible to choose to build periodically or when a change is pushed into GitHub. Although building only when GitHub changes is more efficient, it is required to your Jenkins server to be accessible through the internet, and the you must own the repository. Building periodically may waste resources, but it is simpler to configure.&lt;/p&gt;

&lt;h3 id=&#34;step-2-1-1-build-periodically&#34;&gt;Step 2.1.1: Build Periodically&lt;/h3&gt;

&lt;p&gt;Check &lt;strong&gt;Build Periodically&lt;/strong&gt; and define the period using the proper syntax found when clicking the &lt;strong&gt;?&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Complete the job creating by adding a build step (e.g. a shell script to compile and run a test) and jump to step 4&lt;/p&gt;

&lt;p&gt;The test input and expected output should be in the repository.&lt;/p&gt;

&lt;h3 id=&#34;step-2-1-2-build-when-a-change-is-pushed-into-github&#34;&gt;Step 2.1.2: Build when a change is pushed into GitHub&lt;/h3&gt;

&lt;p&gt;Check build when a change is pushed into GitHub&lt;/p&gt;

&lt;p&gt;Complete the job creating by adding a build step (e.g. a shell script to compile and run a test) and follow to step 3&lt;/p&gt;

&lt;p&gt;The test input and expected output should be in the repository.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;job_configuration.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;step-3-configuring-github-plugin-skip-if-building-periodically&#34;&gt;Step 3: Configuring GitHub plugin - Skip if building periodically&lt;/h1&gt;

&lt;p&gt;Go to &lt;strong&gt;Manage Jenkins&lt;/strong&gt; → &lt;strong&gt;Configure System&lt;/strong&gt; → &lt;strong&gt;GitHub&lt;/strong&gt; section → &lt;strong&gt;Advanced&lt;/strong&gt; → &lt;strong&gt;Manage additional GitHub Actions&lt;/strong&gt; → &lt;strong&gt;Convert login and password to token&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A new sub-section will appear right above.&lt;/p&gt;

&lt;p&gt;Select &lt;strong&gt;From login and password&lt;/strong&gt;, fill your login and password from GitHub and press &lt;strong&gt;Create token credentials&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;create_token.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;Above this sub-section, click &lt;strong&gt;Add GitHub server&lt;/strong&gt;. Keep the &lt;strong&gt;API URL&lt;/strong&gt; unchanged.&lt;/p&gt;

&lt;p&gt;Under &lt;strong&gt;Credentials&lt;/strong&gt; dropdown menu, select the token just created and test your connection.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;github_server.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;h1 id=&#34;step-4-testing-it&#34;&gt;Step 4: Testing it&lt;/h1&gt;

&lt;p&gt;If using periodical build, click the &lt;strong&gt;Build now&lt;/strong&gt; icon to test. If the test fails, check the console output to find the issue (e.g. missing compiler).&lt;/p&gt;

&lt;p&gt;If using GitHub trigger, change a file in the repository. The build should start automatically in a few seconds.&lt;/p&gt;

&lt;p&gt;#Step 5: Adding slave machines - Optional&lt;/p&gt;

&lt;p&gt;As your projects grow, you may run out of resources in your machine. A possible solution is to add one or more slave machines, which will be responsible for building your projects, while the current machine will become the master and manage everything (the master will still be able to run jobs if desired).&lt;/p&gt;

&lt;p&gt;The slave machine doesn&amp;rsquo;t need Jenkins installed on it. There are many ways to connect the slave with the master, here, SSH will be used.&lt;/p&gt;

&lt;p&gt;Install Java and Git in the slave using:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install default-jre
sudo apt-get install git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create a directory to be used by Jenkins, in this case will be the same path used by default in the master machine: /var/lib/jenkins&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mkdir /var/lib/jenkins
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Change the ownership of the directory to the same user used to login using SSH&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chown ubuntu:ubuntu /var/lib/jenkins
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Back to the master machine:&lt;/p&gt;

&lt;p&gt;Go to &lt;strong&gt;Manage Jenkins&lt;/strong&gt; → &lt;strong&gt;Manage Nodes&lt;/strong&gt; → &lt;strong&gt;New Node&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Name your node and select &lt;strong&gt;Permanent Agent&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The recommended &lt;strong&gt;# of executors&lt;/strong&gt; is the number of cores in the slave machine&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Remote root directory&lt;/strong&gt; is the path to the directory created.&lt;/p&gt;

&lt;p&gt;If necessary to divide the slave machines into different groups, label them (e.g. the OS running in the machine, the CPU architecture)&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Launch method&lt;/strong&gt; used here will be SSH, but other methods are also fine.&lt;/p&gt;

&lt;p&gt;Simply enter your host and create a credential using your username and password, or username and private key.&lt;/p&gt;

&lt;p&gt;Press &lt;strong&gt;Save&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;slave_node.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;##Step 5.1: Restricting machines where projects can be run&lt;/p&gt;

&lt;p&gt;If your slaves have different environments, your should restrict the machines where each project will run.&lt;/p&gt;

&lt;p&gt;Under the &lt;strong&gt;project&lt;/strong&gt; settings, check &lt;strong&gt;Restrict where this project can be run&lt;/strong&gt; and type the machine name, use a label, or even use a more complex rule using logical operators (click the &lt;strong&gt;?&lt;/strong&gt; for more information)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;restrict_where_this_project_can_be_run.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;

&lt;p&gt;To prevent the master machine to run projects, go to &lt;strong&gt;Manage Jenkins&lt;/strong&gt; → &lt;strong&gt;Manage Nodes&lt;/strong&gt; → &lt;strong&gt;master&lt;/strong&gt; → &lt;strong&gt;Configure&lt;/strong&gt; → &lt;strong&gt;# of executors&lt;/strong&gt; and set to 0.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Install IBM SDK on Ubuntu 16.04/14.04 Power Machines</title>
      <link>/post/sdk/</link>
      <pubDate>Mon, 30 May 2016 00:00:00 +0000</pubDate>
      <guid>/post/sdk/</guid>
      <description>

&lt;h1 id=&#34;downloading-packages&#34;&gt;Downloading Packages&lt;/h1&gt;

&lt;p&gt;You can use a script to download the necessary packages in the link above:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/at_downloader/?cm_mc_uid=92476109699314629396752&amp;amp;cm_mc_sid_50200000=1464625581
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download the script and change its permission with the command above:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chmod +x &amp;lt;script name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then run the script with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./&amp;lt;script name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Please download the packages for Ubuntu 14.10. Then, the folder will be full of .deb
files. The next step is to install some of these packages using dpkg.&lt;/p&gt;

&lt;h1 id=&#34;instaling-packages-and-toolchain&#34;&gt;Instaling Packages and Toolchain&lt;/h1&gt;

&lt;p&gt;Now, you need to install some of these. This is simple, but you have to do it following
the order above. The command for each of those is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dpkg -i &amp;lt;package name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The correct order is (the X is the version of the software):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;advance-toolchain-atX.X-runtime-X.X-X
advance-toolchain-atX.X-devel-X.X-X
advance-toolchain-atX.X-perf-X.X-X
advance-toolchain-atX.X-mcore-libs-X.X-X
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can ignore the errors and move on.&lt;/p&gt;

&lt;h1 id=&#34;installing-ibm-sdk&#34;&gt;Installing IBM SDK&lt;/h1&gt;

&lt;p&gt;After all the dependencies issues are solved, download fdpr_wrap, fdpr-pro, pthread-mon, ibm-sdk-lop and ibm-sdk-lop-remote-dependencies on
this link:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://www-304.ibm.com/webapp/set2/sas/f/lopdiags/sdkdownload.html#4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install each of these packages with dpkg again, running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo dpkg -i &amp;lt;package name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;respecting the sequence above.&lt;/p&gt;

&lt;p&gt;Note: to run the ibm-sdk-loop on the Power Machines using ssh, you will have to connect
to the server using&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh -XC -c blowfish-cbc,arcfour &amp;lt;user&amp;gt;@&amp;lt;host&amp;gt; -p &amp;lt;port_number&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The blowfish-cbc,arcfour will make your connection even better.
This command is necessary to xforward the image of the sdk running.
Note2: if you get the &amp;ldquo;no matching cipher found&amp;rdquo; error, here you go the solution:&lt;/p&gt;

&lt;p&gt;run the command above:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh -Q cipher localhost | paste -d , -s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now its time to change the sshd_config file on the server(super privileges needed).
Add on the /etc/ssh/sshd_config a line with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Ciphers &amp;lt;output of the last command&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reboot the machine to make this alterations running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo shutdown -r now
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Post written by Guilherme Lucas.
You can see some of my work at &lt;a href=&#34;https://github.com/Guilhermeslucas&#34; target=&#34;_blank&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimizing C/C&#43;&#43; applications</title>
      <link>/post/sdk_opt/</link>
      <pubDate>Mon, 30 May 2016 00:00:00 +0000</pubDate>
      <guid>/post/sdk_opt/</guid>
      <description>

&lt;h1 id=&#34;optimizing-c-c-applications-with-ibm-sdk-build-advisor&#34;&gt;Optimizing C/C++ Applications with IBM SDK Build Advisor&lt;/h1&gt;

&lt;p&gt;This is a brief text about how to use the IBM SDK Build Advisor to optimize C/C++ aplications on Power Servers.
You can get the project and learn how to run on the link below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://github.com/Guilhermeslucas/cmp
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;running-seismic-applications-without-optimization-flags&#34;&gt;Running seismic applications without optimization flags&lt;/h2&gt;

&lt;p&gt;Here are some results on Power Machine before the optimization process.&lt;br /&gt;
real    0m46.837s&lt;br /&gt;
real    0m48.391s&lt;br /&gt;
real    0m52.570s&lt;br /&gt;
real    0m49.249s&lt;br /&gt;
real    0m48.863s&lt;/p&gt;

&lt;h2 id=&#34;importing-a-c-c-project-to-ibm-sdk&#34;&gt;Importing a C\C++ Project to IBM SDK&lt;/h2&gt;

&lt;p&gt;Before you begin, make sure there is a Makefile inside your project. Now, inside the SDK:&lt;br /&gt;
1. Go to &lt;strong&gt;File &amp;gt; Import&lt;/strong&gt;
2. In the import window, expand &lt;strong&gt;C\C++&lt;/strong&gt; and click in &lt;strong&gt;Existing Code as Makefile Project&lt;/strong&gt;
3. Now go to &lt;strong&gt;Browse&lt;/strong&gt; next to the &lt;strong&gt;Existing code Location&lt;/strong&gt;.
4. Type a name for your project
5. Locate the code and then click &lt;strong&gt;OK&lt;/strong&gt;.
6. Back to the &lt;strong&gt;Import Existing Code&lt;/strong&gt; window, click the Advanced Toolchain Version corresponding to the one you have installed on the Power Machine.
7. Click &lt;strong&gt;Finish&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;using-the-build-advisor&#34;&gt;Using the Build Advisor&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Right Click on the project, go to &lt;strong&gt;Properties&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Select the build advisor&lt;/li&gt;
&lt;li&gt;Enable &lt;strong&gt;Enable extra advice&lt;/strong&gt; and then &lt;strong&gt;Finish&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Right click on the project and build. The suggestions will appear.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;final-results&#34;&gt;Final results&lt;/h2&gt;

&lt;p&gt;After using the flags that the SDK suggested&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-std=c99 -Ofast -fpeel-loops -flto -fopenmp -mcmodel=medium -ftree-vectorize -mcpu=power8 -mtune=power8 -funroll-loops
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I got the following results:&lt;br /&gt;
real    0m3.177s&lt;br /&gt;
real    0m2.573s&lt;br /&gt;
real    0m3.066s&lt;br /&gt;
real    0m2.954s&lt;br /&gt;
real    0m2.930s&lt;/p&gt;

&lt;p&gt;As you can see, Build Advisor is very effective.&lt;/p&gt;

&lt;p&gt;Post written by Guilherme Lucas.
You can see some of my work at &lt;a href=&#34;https://github.com/Guilhermeslucas&#34; target=&#34;_blank&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Instalação de Seismic Unix e Cmp_toy em arquitetura Intel</title>
      <link>/post/ic/</link>
      <pubDate>Fri, 20 May 2016 00:00:00 +0000</pubDate>
      <guid>/post/ic/</guid>
      <description>

&lt;h1 id=&#34;instalação-do-su-e-do-cmp-toy-na-máquina-pessoal&#34;&gt;Instalação do SU e do Cmp_toy na máquina pessoal&lt;/h1&gt;

&lt;h2 id=&#34;instalação-do-su&#34;&gt;Instalação do SU&lt;/h2&gt;

&lt;p&gt;Seismic Unix é um conjunto de ferramentas extremamente úteis para o processamento de dados sísmicos. Para instalá-lo no Ubuntu 14.04, precisei baixar algumas bibliotecas. Segue quais são e como instalá-las:&lt;/p&gt;

&lt;p&gt;&lt;X11/Xlib.h&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install libx11-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;X11/Intrinsic.h&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;X11/Intrinsic.h&amp;gt; - sudo apt-get install libxt-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Também precisamos do CMake para completar a instalação do Seismic Unix. Rode:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install cmake
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Link do repositório do cmp_toy:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;github.com/gga-cepetro/cmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora para realmente terminar a instalção, basta rodar os seguintes comandos:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;install_dir=~/src/cwp
mkdir -p $install_dir &amp;amp;&amp;amp; cd $install_dir
export CWPROOT=$PWD
echo &amp;quot;export CWPROOT=$PWD&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
echo &#39;export PATH=$PATH:$CWPROOT/bin&#39; &amp;gt;&amp;gt; ~/.bashrc
wget ftp://ftp.cwp.mines.edu/pub/cwpcodes/cwp_su_all_44R1.tgz
tar zxf cwp_su_all_44R1.tgz
cd src
sed -i &#39;s/^XDRFLAG/#XDRFLAG/&#39; Makefile.config
make install ; make xtinstall
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora para testar se o software, basta executar&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;suplane | suximage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Uma imagem com três planos deve ser apresentada. Ela parece ser um pouco esquista, a princípio, mas se uma janela com uma imagem foi aberta, então a instalação foi realizada com sucesso.&lt;/p&gt;

&lt;h2 id=&#34;instalação-do-cmp-toy&#34;&gt;Instalação do cmp_toy&lt;/h2&gt;

&lt;p&gt;Agora para instalar o cmp_toy e obter as curvas desejadas, precisamos executar os seguintes comandos, após obter o cmp_toy.tar.gz :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tar -xzf cmp_toy.tar.gz
mkdir build
cd build
cmake ..
make
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora que o software está instalado, vamos testá-lo. É necessário mudar para o diretório pai desse que estamos e rodar o script de teste, que usa uma imagem criada extamente para esse teste:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd ..
./test-cmp.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A saída desse comando (ao completar 100%) deve seguir o seguinte padrão, com números possivelmente diferentes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[100%] Processing CDP 300
real	0m56.573s
user	0m56.589s
sys	0m0.008s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora, para testar a imagem gerada, basta rodar o seguinte comando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;suximage &amp;lt; cmp.stack.su
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O output desse comando deve ser uma imagem com o plot de algumas curvas.&lt;/p&gt;

&lt;p&gt;Post escrito por Guilherme Lucas.
Mais um pouco do meu trabalho no meu Github &lt;a href=&#34;https://github.com/Guilhermeslucas&#34; target=&#34;_blank&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Instalação de Seismic Unix e Cmp_toy em arquitetura Power</title>
      <link>/post/power/</link>
      <pubDate>Fri, 20 May 2016 00:00:00 +0000</pubDate>
      <guid>/post/power/</guid>
      <description>

&lt;h1 id=&#34;tutorial-de-instalação-do-cmp-toy-em-máquinas-power&#34;&gt;Tutorial de instalação do cmp_toy em Máquinas Power&lt;/h1&gt;

&lt;p&gt;Esse é um breve tutorial de como foi para instalar e rodar o código sísmico cmp_toy nas máquinas Power, acessado pelo sistema de Minicloud.
Todo o processo foi feito usando uma máquina com Ubuntu 16.04 instalado, mas também deve funcionar em máquinas com sistemas Debian Based.&lt;/p&gt;

&lt;h2 id=&#34;resolução-de-problemas-nos-pacotes&#34;&gt;Resolução de problemas nos pacotes&lt;/h2&gt;

&lt;p&gt;Ao logar na máquina, tive alguns problemas com pacotes quebrados. Para arrumar esse problema usei os comandos comandos do dpkg e do apt-get, respectivamente:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo dpkg --configure -a
sudo apt-get -f install
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;primeiros-softwares-e-pacotes-necessários&#34;&gt;Primeiros Softwares e Pacotes necessários&lt;/h2&gt;

&lt;p&gt;O primeiro software que precisei, foi o editor de texto Vim, muito poderoso e eficiente, ainda mais quando estamos acessando uma máquina remotamente. Para instalá-lo basta executar:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install vim
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Após copiar o meu .vimrc para a máquina remota, baixei os dois compiladores necessários para rodar o código. Pra esse, preciso do compilador de C e C++, e por preferências pessoais instalei o gcc e g++. Segue os comandos para instalação de cada um deles:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install gcc
sudo apt-get install g++
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Link do repositório do cmp_toy:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;github.com/gga-cepetro/cmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Durante a instalação é necessário rodar o CMake, que também não esta instalado. Para acertar esse problema, rode:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install cmake
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vale lembrar que todos os comandos desde o início do desse tutorial devem ser feitos logado na máquina remota.&lt;/p&gt;

&lt;h2 id=&#34;trocando-arquivos-remotamente-e-instalando-do-software&#34;&gt;Trocando arquivos remotamente e instalando do software&lt;/h2&gt;

&lt;p&gt;Como fazemos acesso às máquinas com o comando &lt;code&gt;ssh -p&lt;/code&gt; , ou seja, acessamos por meio de uma porta específica, temos que executar o comando scp de maneira diferente também, para copiar um arquivo local para uma máquina remota. Nesse caso, queremos copiar o arquivo cmp_toy.tar.gz (você deve estar no diretório desse arquivo, ou seja, na sua máquina física e não logado nas máquinas remotas).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scp -P &amp;lt;numero da porta&amp;gt; cmp_toy.tar.gz  seu_usuario@host_remoto:/algum/diretorio/remoto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora, se conectado na máquina remota, e vá até o diretório onde mandou o arquivo. Voce deve encontrar o cmp_toy.tar.gz. Agora para instalá-lo, rode os seguintes comandos:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tar -xzf cmp_toy.tar.gz
cd cmp_toy
mkdir build
cd build
cmake ..
make
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora que a instalação do software foi feita com sucesso, precisamos testá-lo. Para isso, basta ir para o diretório pai e rodar o script de teste, que usa uma imagem pronta para teste.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd ..
./test-cmp.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Após um tempinho, você deve receber uma saída que segue o seguinte padrão (não necessariamente com os mesmos números):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[100%] Processing CDP 300

real	0m59.968s
user	0m59.908s
sys	0m0.056s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Basicamente, os passos são esses. Tentei fazer esse tutorial da maneira mais detalhada possível. Se ainda restarem dúvidas, não exitem em entrar em contato.&lt;/p&gt;

&lt;p&gt;Post escrito por Guilherme Lucas.
Mais um pouco do meu trabalho no meu Github &lt;a href=&#34;https://github.com/Guilhermeslucas&#34; target=&#34;_blank&#34;&gt;https://github.com/Guilhermeslucas&lt;/a&gt; .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up an OpenStack-based cloud with Power8 | Part 04 – Glance</title>
      <link>/post/openstack_setup_4/</link>
      <pubDate>Wed, 16 Sep 2015 00:00:00 +0000</pubDate>
      <guid>/post/openstack_setup_4/</guid>
      <description>&lt;p&gt;Glance is the Openstack Image Service and enables users to discover, register, and retrieve virtual machine images. This service allows users to query virtual machine images information and retrieve the image itself using a REST API and must be installed in the controller node.&lt;/p&gt;

&lt;p&gt;#Prerequisites&lt;/p&gt;

&lt;p&gt;Load the OpenRC file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;source adm-credentiansl.sh 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create a database for Glance:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql -u root -p
CREATE DATABASE glance;
GRANT ALL PRIVILEGES ON glance.* TO &#39;glance&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;glance&#39;;
GRANT ALL PRIVILEGES ON glance.* TO &#39;glance&#39;@&#39;%&#39; IDENTIFIED BY &#39;glance&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create the keystone entities, service and endpoint:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openstack user create --password-prompt glance
openstack role add --project service --user glance admin
openstack service create --name glance --description &amp;quot;OpenStack Image service&amp;quot; image
openstack endpoint create --publicurl http://controller:9292 \
          --internalurl http://controller:9292  --adminurl http://controller:9292 \
          --region RegionOne image
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Install and Configure&lt;/p&gt;

&lt;p&gt;Install the packages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install glance python-glanceclient 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the file &lt;em&gt;/etc/glance/glance-api.cnf&lt;/em&gt; as following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[DEFAULT]
...
notification_driver = noop
verbose = True

[database]
connection = mysql://glance:GLANCE_DBPASS@controller/glance

[keystone_authtoken]
auth_uri = http://controller:5000
auth_url = http://controller:35357
auth_plugin = password
project_domain_id = default
user_domain_id = default
project_name = service
username = glance
password = GLANCE_PASS

[paste_deploy]
flavor = keystone

[glance_store]
default_store = file
filesystem_store_datadir = /var/lib/glance/images/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also edit the file &lt;em&gt;/etc/glance/glance-registry.cnf&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[DEFAULT]
...
notification_driver = noop
verbose = True

[database]
connection = mysql://glance:GLANCE_DBPASS@controller/glance
[keystone_authtoken]
auth_uri = http://controller:5000
auth_url = http://controller:35357
auth_plugin = password
project_domain_id = default
user_domain_id = default
project_name = service
username = glance
password = GLANCE_PASS

[paste_deploy]
flavor = keystone
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Populate the image service database:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;su -s /bin/sh -c &amp;quot;glance-manage db_sync&amp;quot; glance
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finalize the installation process:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service glance-registry restart
service glance-api restart
rm -f /var/lib/glance/glance.sqlite
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Greenlet Fix&lt;/p&gt;

&lt;p&gt;The Greenlet version that is in the Ubuntu repository has problems with PPC64le architecture, therefore we need to manually download and install a newer version of the library.&lt;/p&gt;

&lt;p&gt;Download and unpack the package code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://github.com/python-greenlet/greenlet/archive/master.zip -D greenlet.zip
unzip greenlet.zip -D 
cd greenlet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install the package:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export CFLAGS=-O1;
./setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the glance services:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service glance-registry restart
service glance-api restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Upload an image to the Image Server&lt;/p&gt;

&lt;p&gt;Configure the server to use the API version 2.0 and reload the credentials:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo &amp;quot;export OS_IMAGE_API_VERSION=2&amp;quot; | tee -a adm-credentials.sh
source adm-credentials.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As an example upload Ubuntu 14.04.02 PPC64le to the server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;glance image-create --name=&amp;quot;ubuntu1404-ppc64le&amp;quot; --disk-format=qcow2  --container-format=bare \
       --is-public=true \
       -copy-from https://cloud-images.ubuntu.com/releases/14.04/14.04.2/ubuntu-14.04-server-cloudimg-ppc64el-disk1.img
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check the list of images:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;glance image-list
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Setting up an OpenStack-based cloud with Power8 | Part 03 – Keystone</title>
      <link>/post/openstack_setup_3/</link>
      <pubDate>Wed, 09 Sep 2015 00:00:00 +0000</pubDate>
      <guid>/post/openstack_setup_3/</guid>
      <description>&lt;p&gt;This service provides a central directory of users mapped to the OpenStack services. It&amp;rsquo;s used to provide an authentication and authorization service for other OpenStack services. In addition to the identity service, we will install two more packages, the Apache HTTP server and the Memcahed, responsible, respectively, for receiving requests and store the authentication tokens.&lt;/p&gt;

&lt;p&gt;#Prerequisites&lt;/p&gt;

&lt;p&gt;All the keystone data will be stored in a database, acess the mysql and execute the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;mysql -u root -p
CREATE DATABASE keystone;
GRANT ALL PRIVILEGES ON keystone.* TO &#39;keystone&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;keystone&#39;;
GRANT ALL PRIVILEGES ON keystone.* TO &#39;keystone&#39;@&#39;%&#39; IDENTIFIED BY &#39;keystone&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Install and Configure&lt;/p&gt;

&lt;p&gt;The version Kilo uses a WSGI server to listen the requests to keystone, we choose to use the Apache Server running a WSGI mod.&lt;/p&gt;

&lt;p&gt;Execute the following commands to disable keystone automatic start and install the packages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;echo &amp;quot;manual&amp;quot; &amp;gt; /etc/init/keystone.override
apt-get install keystone python-openstackclient apache2 libapache2-mod-wsgi \
        memcached python-memcache
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the following sections in the file /etc/keystone/keystone.conf:&lt;/li&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;[DEFAULT]
...
admin_token = ADMIN_TOKEN
verbose = True

[database]
connection = mysql://keystone:KEYSTONE_DBPASS@controller/keystone

[memcache]
servers = localhost:11211

[token]
provider = keystone.token.providers.uuid.Provider
driver = keystone.token.persistence.backends.memcache.Token

[revoke]
driver = keystone.contrib.revoke.backends.sql.Revoke
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create the file /etc/apache2/sites-available/wsgi-keystone.conf with the following content:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;Listen 5000
Listen 35357

&amp;lt; VirtualHost *:5000 &amp;gt;
    WSGIDaemonProcess keystone-public processes=5 threads=1 user=keystone display-name=%{GROUP}
    WSGIProcessGroup keystone-public
    WSGIScriptAlias / /var/www/cgi-bin/keystone/main
    WSGIApplicationGroup %{GLOBAL}
    WSGIPassAuthorization On
    &amp;lt; IfVersion &amp;gt;= 2.4 &amp;gt;
      ErrorLogFormat &amp;quot;%{cu}t %M&amp;quot;
    &amp;lt; /IfVersion &amp;gt;
    LogLevel info
    ErrorLog /var/log/apache2/keystone-error.log
    CustomLog /var/log/apache2/keystone-access.log combined
&amp;lt; /VirtualHost &amp;gt;
&amp;lt; VirtualHost *:35357 &amp;gt;
    WSGIDaemonProcess keystone-admin processes=5 threads=1 user=keystone display-name=%{GROUP}
    WSGIProcessGroup keystone-admin
    WSGIScriptAlias / /var/www/cgi-bin/keystone/admin
    WSGIApplicationGroup %{GLOBAL}
    WSGIPassAuthorization On
    &amp;lt; IfVersion &amp;gt;= 2.4 &amp;gt;
      ErrorLogFormat &amp;quot;%{cu}t %M&amp;quot;
    &amp;lt; /IfVersion &amp;gt;
    LogLevel info
    ErrorLog /var/log/apache2/keystone-error.log
    CustomLog /var/log/apache2/keystone-access.log combined
&amp;lt; /VirtualHost &amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install and configure the WSGI mod for Apache:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;ln -s /etc/apache2/sites-available/wsgi-keystone.conf /etc/apache2/sites-enabled
mkdir -p /var/www/cgi-bin/keystone
curl http://git.openstack.org/cgit/openstack/keystone/plain/httpd/keystone.py?h=stable/kilo \
     | tee /var/www/cgi-bin/keystone/main /var/www/cgi-bin/keystone/admin
chown -R keystone:keystone /var/www/cgi-bin/keystone
chmod 755 /var/www/cgi-bin/keystone/*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the Apache service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;rm -f /var/lib/keystone/keystone.db
service apache2 restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Create the service endpoint&lt;/p&gt;

&lt;p&gt;To really have the Keystone service working is needed to create a service endpoint to listen requests:&lt;/p&gt;

&lt;p&gt;Export the following lines to obtain administrator privileges on Keystone:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;export OS_TOKEN=ADMIN
export OS_URL=http://controller:35357/v2.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Registry the service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;openstack service create --name keystone --description &amp;quot;OpenStack Identity&amp;quot; identity
openstack endpoint create --publicurl http://controller:5000/v2.0 \
          --internalurl http://controller:5000/v2.0 --adminurl http://controller:35357/v2.0 \
          --region RegionOne identity
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Create the environment entities&lt;/p&gt;

&lt;p&gt;Each of the services that compose OpenStack uses the keystone as the authentication point, this process involves a combination of various entities (users, projects, etc.). You can better understand the functioning of Keystone at the &lt;a href=&#34;http://docs.openstack.org/kilo/install-guide/install/apt/content/keystone-concepts.html&#34; target=&#34;_blank&#34;&gt;documentation page&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;Create the Admininstration and Demo projetct:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;openstack project create --description &amp;quot;Admin Project&amp;quot; admin
openstack project create --description &amp;quot;Demo Project&amp;quot; demo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create users and roles and after make sure each user is registred in one role:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;openstack role create admin
openstack role create user
openstack user create --password-prompt admin
openstack user create --password-prompt demo
openstack role add --project admin --user admin admin
openstack role add --project demo --user demo user
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each service that will be installed is represent as an user in Keystone, they will be part of an project that will contain all the services:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;openstack project create --description &amp;quot;Service Project&amp;quot; service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#OpenRC files&lt;/p&gt;

&lt;p&gt;To simplify the keystone authentication process create a file that contains the credenditals and export to the system.&lt;/p&gt;

&lt;p&gt;Create the file adm-credentials.sh and add the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;export OS_PROJECT_DOMAIN_ID=default
export OS_USER_DOMAIN_ID=default
export OS_PROJECT_NAME=admin
export OS_TENANT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=SENHA_ADMIN
export OS_AUTH_URL=http://controller:35357/v3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load the file content:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;source adm-credentials.sh
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Setting up an OpenStack-based cloud with Power8 | Part 02 – Environment Setup</title>
      <link>/post/openstack_setup_2/</link>
      <pubDate>Fri, 21 Aug 2015 00:00:00 +0000</pubDate>
      <guid>/post/openstack_setup_2/</guid>
      <description>&lt;p&gt;The environment will consist of two Power8 machines with Ubuntu 15.04 installed, one of the machines will contain the core cloud services (controller node), and the other one the virtualization services (compute node). In this guide we are going to install the newest OpenStack release, the Kilo version. However, before installing the cloud services it&amp;rsquo;s necessary to properly set up the environment, this post will cover all the datails.&lt;/p&gt;

&lt;p&gt;#Passwords&lt;/p&gt;

&lt;p&gt;As a convention, passwords for each service will be the service name in lowercase, do not forget that in a real environment passwords must be chosen carefully.&lt;/p&gt;

&lt;p&gt;#Network&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s possible to install OpenStack with two different network architectures, legacy networking (nova-network) and Neutron. Initially we will use nova-network, our network environment is represented as shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/cULbdw1.png&#34; alt=&#34;Nova-network&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that we have two networks, the 10.0.0.0/24 is the management network (where the nodes will establish comunicate) and the 10.0.2.0/24 is the external network (each created VM will have an IP external acessible).&lt;/p&gt;

&lt;p&gt;Edit the file &lt;em&gt;/etc/hosts&lt;/em&gt; on all machines and add the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#controller
10.0.0.10 controller
#compute
10.0.0.11 compute01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Network Time Protocol (NTP)&lt;/p&gt;

&lt;p&gt;In order to synchronize services installed on different nodes we will install NTP.&lt;/p&gt;

&lt;p&gt;First of all install NTP on all machines:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install ntp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;##On controller&lt;/p&gt;

&lt;p&gt;Edit the file &lt;em&gt;/etc/ntp.conf&lt;/em&gt; and add or edit the follwing lines:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server 0.ubuntu.pool.ntp.org iburst
restrict -4 default kod notrap nomodify
restrict -6 default kod notrap nomodify
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the NTP service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service ntp restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;##On compute&lt;/p&gt;

&lt;p&gt;Edit the file &lt;em&gt;/etc/ntp.conf&lt;/em&gt; and change the server to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server controller iburst
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the NTP service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service ntp restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Openstack and system packages&lt;/p&gt;

&lt;p&gt;We have to configure the package respository to point to the Openstack Kilo release and verify if the system is up-to-date. Perform the followig step on all nodes.&lt;/p&gt;

&lt;p&gt;Install Ubuntu keyring and set the Kilo repository:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install ubuntu-cloud-keyring
echo &amp;quot;deb http://ubuntu-cloud.archive.canonical.com/ubuntu&amp;quot; \
&amp;quot;trusty-updates/kilo main&amp;quot; &amp;gt; /etc/apt/sources.list.d/cloudarchive-kilo.list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Upgrade the packages on your system:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get update
apt-get dist-upgrade
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#SQL database&lt;/p&gt;

&lt;p&gt;The SQL database will be installed only on controlle node, the openstack services mostly use a database to store all the information they need. We choose to install MySQL server.&lt;/p&gt;

&lt;p&gt;Install packages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install mysql-server python-mysqldb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit the file &lt;em&gt;/etc/mysql/mysql.conf.d/mysqld.conf&lt;/em&gt; in the [mysqld] section:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[mysqld]
...
bind-address = 10.0.0.10
default-storage-engine = innodb
innodb_file_per_table
collation-server = utf8_general_ci
init-connect = &#39;SET NAMES utf8&#39;
character-set-server = utf8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the Mysql service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service mysql restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Execute the following mysql script to secure the database service:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql_secure_installation
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;##Message Queue&lt;/p&gt;

&lt;p&gt;Openstack uses the strategy of a queue message to coordinate the actions related to the services, in other words, a message queue running on the controller node coordinates the comunication between the services in order to have all the services properly. In this guide we will use a message queue server called RabbitMQ.&lt;/p&gt;

&lt;p&gt;Install the packages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install rabbitmq-server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create the openstack user:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rabbitmqctl add_user openstack RABBIT_PASS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As mentioned in password section, replace &lt;em&gt;RABBIT_PASS&lt;/em&gt; by &lt;em&gt;rabbit&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Configure permissions to openstack user:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rabbitmqctl set_permissions openstack &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;##Next steps&lt;/p&gt;

&lt;p&gt;With the environment properly configured we can setup the OpenStack services, in the next post we will configure the identity service, known as Keystone.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up an OpenStack-based cloud with Power8 | Part 01 – Introduction</title>
      <link>/post/openstack_setup_1/</link>
      <pubDate>Thu, 20 Aug 2015 00:00:00 +0000</pubDate>
      <guid>/post/openstack_setup_1/</guid>
      <description>&lt;p&gt;#Introduction&lt;/p&gt;

&lt;p&gt;In this series we are going to detail all the necessary steps to setup an OpenStack-based cloud with IBM POWER8 machines from the scratch, but first of all, let&amp;rsquo;s take a look at some basic questions like what is OpenStack and why one would want to install and use it?&lt;/p&gt;

&lt;p&gt;#What is OpenStack?&lt;/p&gt;

&lt;p&gt;OpenStack is a free and open-source set of connected components aiming to serve as an cloud computing operating system capable of managing large pools of compute, storage and networking resources, all managed through a administrator dashboard. It&amp;rsquo;s robustness and reliability as one of the most active open-source project today makes it an really good choice for offering cloud computing services (&lt;a href=&#34;https://en.wikipedia.org/wiki/Cloud_computing#Infrastructure_as_a_service_.28IaaS.29&#34; target=&#34;_blank&#34;&gt;IaaS&lt;/a&gt;) on standarized hardware, and due to its simplicity and massive scalability it can be used as an solution for a large amout of users, from a small home environments with few machines to large datacenters with hundreds of machines.&lt;/p&gt;

&lt;p&gt;The OpenStack project began first in 2010 as an joint project of Rackspace Hosting and NASA, today, the project itself is managed by the OpenStack Foundation and have more than 500 supporters among companies and research centers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/PNQ4Dro.png&#34; alt=&#34;OpenStack Services&#34; /&gt;&lt;/p&gt;

&lt;p&gt;#Components&lt;/p&gt;

&lt;p&gt;The main project is implemented in a modular architecture with many components, each one performing its own responsibility in the system. The diagram below can be found at the OpenStack official documentation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/QiQGJHe.png&#34; alt=&#34;OpenStack components connections&#34; /&gt;&lt;/p&gt;

&lt;p&gt;##Horizon (Dashboard)&lt;/p&gt;

&lt;p&gt;This component responsibility consists in providing a web-based interface to easily access the OpenStack services.&lt;/p&gt;

&lt;p&gt;##Compute (Nova)&lt;/p&gt;

&lt;p&gt;The main part of any IaaS system, the Nova project performs the controller role, managing and automating pools of computer resources. It supports many virtualization technologies and is it responsibility to manage the virtual machines on the system.&lt;/p&gt;

&lt;p&gt;##Networking (Neutron)&lt;/p&gt;

&lt;p&gt;Manages the networks and IP adresses, providing users total control over network configurations. Standard network models works with separate VLANs for each user to distribute the network access, the Neutron component treats the question differently, managing the IP adressess, allowing a more flexible and maintainable network usage.&lt;/p&gt;

&lt;p&gt;##Object Storage (Swift)&lt;/p&gt;

&lt;p&gt;The Swift component stores and retrieves unstructured data object through the HTTP based APIs.&lt;/p&gt;

&lt;p&gt;##Block Storage (Cinder)&lt;/p&gt;

&lt;p&gt;Provides persistent storage to running services, its implemented in such a way that makes creating and managing block storage very easy.&lt;/p&gt;

&lt;p&gt;##Identity Service (Keystone)&lt;/p&gt;

&lt;p&gt;This provides a central directory of users mapped to the OpenStack services. It is used to provide an authentication and authorization service for other OpenStack services.&lt;/p&gt;

&lt;p&gt;##Image Service (Glance)&lt;/p&gt;

&lt;p&gt;This provides the discovery, registration and delivery services for the disk and server images. It stores and retrieves the virtual machine disk image.&lt;/p&gt;

&lt;p&gt;##Telemetry (Ceilometer)&lt;/p&gt;

&lt;p&gt;It monitors the usage of the Cloud services and decides the billing accordingly. This component is also used to decide the scalability and obtain the statistics regarding the usage.&lt;/p&gt;

&lt;p&gt;##Orchestration (Heat)&lt;/p&gt;

&lt;p&gt;This component manages multiple Cloud applications through an OpenStack-native REST API and a CloudFormation-compatible Query API.&lt;/p&gt;

&lt;p&gt;#Why would I use OpenStack?&lt;/p&gt;

&lt;p&gt;In sight of all the features listed above and all the benefits that OpenStack can offer to its users and administrators we choose it to serve as infrastructure to our POWER8-based cloud, the steps to setup and manage the system will be discussed throughout the next series posts, keep in touch!&lt;/p&gt;

&lt;p&gt;#Sources:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/OpenStack&#34; target=&#34;_blank&#34;&gt;Wikipedia OpenStack article&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.openstack.org&#34; target=&#34;_blank&#34;&gt;Official OpenStack documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up a Debian Gateway Virtual Machine on PowerKVM</title>
      <link>/post/debian_gateway/</link>
      <pubDate>Sat, 08 Aug 2015 00:00:00 +0000</pubDate>
      <guid>/post/debian_gateway/</guid>
      <description>

&lt;p&gt;There are many reasons why one would want to build its custom router instead of buying one. Control and flexibility are two reasons, and we need both when dealing with large traffic. The purpose of this guide is to give a step-by-step solution starting on how to build a virtual machine. For this, we will assume that PowerKVM is already up and running along with its network configurations.&lt;/p&gt;

&lt;p&gt;So, for this guide we will need:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A PowerKVM machine&lt;/li&gt;
&lt;li&gt;Two network cards&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this case, &lt;strong&gt;eth0&lt;/strong&gt; will be our internal network interface and &lt;strong&gt;eth1&lt;/strong&gt; our external network interface. Both of them will be bridged to the virtual machine and this configuration can be made through Kimchi&amp;rsquo;s web interface.&lt;/p&gt;

&lt;h1 id=&#34;creating-a-debian-virtual-machine&#34;&gt;Creating a Debian Virtual Machine&lt;/h1&gt;

&lt;h2 id=&#34;downloading-the-right-iso&#34;&gt;Downloading the right ISO&lt;/h2&gt;

&lt;p&gt;First we&amp;rsquo;ll download Debian&amp;rsquo;s 8.1 DVD Image for PPC64el architecture. It can be found on &lt;a href=&#34;http://cdimage.debian.org/debian-cd/8.1.0/ppc64el/iso-dvd/&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt; and should be stored in /var/lib/kimchi/isos/ folder.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /var/lib/kimchi/isos
wget http://cdimage.debian.org/debian-cd/8.1.0/ppc64el/iso-dvd/debian-8.1.0-ppc64el-DVD-1.iso
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then run &lt;em&gt;md5sum&lt;/em&gt; to see if the file is corrupted:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget http://cdimage.debian.org/debian-cd/8.1.0/ppc64el/iso-dvd/MD5SUMS
md5sum -c MD5SUMS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result should be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;debian-8.1.0-ppc64el-DVD-1.iso: OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Otherwise, try downloading again.&lt;/p&gt;

&lt;h2 id=&#34;bringing-to-life&#34;&gt;Bringing to Life&lt;/h2&gt;

&lt;p&gt;Now that we have our ISO, we&amp;rsquo;ll create an &lt;em&gt;qcow2&lt;/em&gt; image using &lt;em&gt;qemu&lt;/em&gt; to act as a hard drive. Those images should be stored in &lt;em&gt;/var/lib/libvirt/images/&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;qemu-img create -f qcow2 -o preallocation=metadata storage.qcow2 10G
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, we can start the installation using &lt;em&gt;virt-install&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;virt-install -r 12228 --os-variant=debianwheezy --network bridge=virbr0,model=virtio --accelerate -n debian --vcpus=maxvcpus=16,sockets=2,cores=2,threads=4 -f ./storage.qcow2 --graphics vnc,listen=0.0.0.0 -c /var/lib/kimchi/isos/debian-8.1.0-ppc64el-DVD-1.iso
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you&amp;rsquo;re using a different OS, you can list all available options with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;virt-install --os-variant list
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Instalation will start. In this case, it was done throught Kimchi&amp;rsquo;s web monitor, but can be done using libvirt. Proceed normally. After it&amp;rsquo;s finished, you can start your VM and login with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;virsh start debian
virsh console debian
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#Network Configuration&lt;/p&gt;

&lt;p&gt;As said before, &lt;strong&gt;eth0&lt;/strong&gt; and &lt;strong&gt;eth1&lt;/strong&gt; will be bridged to the VM through Kimchi&amp;rsquo;s web interface, where &lt;strong&gt;eth0&lt;/strong&gt; is our internal network interface and &lt;strong&gt;eth1&lt;/strong&gt;, external network.&lt;/p&gt;

&lt;p&gt;##Setting IPs
We&amp;rsquo;ll edit &lt;em&gt;/etc/network/interfaces&lt;/em&gt; file and assign static IP&amp;rsquo;s both internal and external. Your external address and gateway should be provided by your ISP.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nano /etc/network/interfaces
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;auto lo
iface lo inet loopback

# The primary network interface
allow-hotplug eth0
iface eth0 inet static
   address 10.0.0.1
   netmask 255.255.255.0

allow-hotplug eth1
iface eth1 inet static
   address 0.0.0.0
   netmask 255.255.255.0
   gateway 0.0.0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit your &lt;em&gt;/etc/resolv.conf&lt;/em&gt; if needed by your ISP:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nano /etc/resolv.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;nameserver ISP_server;
search ISP_address;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After restarting your network service, you should have something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systemctl restart networking &amp;amp;&amp;amp; ifconfig

eth0      Link encap:Ethernet  HWaddr 52:54:00:37:bc:11
          inet addr:10.0.0.1  Bcast:10.0.0.255  Mask:255.255.255.0

eth1      Link encap:Ethernet  HWaddr 52:54:00:7b:74:6f
          inet addr: 0.0.0.0  Bcast:0.0.0.0  Mask:255.255.255.0

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See if it&amp;rsquo;s working by pinging internal and external addresses:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ping www.cnn.com 
ping 10.0.0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;##Routing
Start by flushing all previous configurations, if they exist.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -F
iptables -t nat -F
iptables -t mangle -F
iptables -X
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll now allow established connections, outgoing connections and setup masquerade as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -A INPUT -i lo -j ACCEPT
iptables -A FORWARD -i eth1 -o eth0 -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A FORWARD -i eth0 -o eth1 -j ACCEPT
iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now, we&amp;rsquo;ll allow IP Forwarding:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And your Iptables should look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -L
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Chain INPUT (policy ACCEPT)
target     prot opt source               destination
ACCEPT     all  --  anywhere             anywhere

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination
ACCEPT     all  --  anywhere             anywhere             state RELATED,ESTABLISHED
ACCEPT     all  --  anywhere             anywhere

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now a client should successfully connect to the internet.&lt;/p&gt;

&lt;p&gt;##Making it Permanent
Now we want to apply these iptables configurations everytime we start this machine. This can be done by saving them in a file and restoring on the next boot.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables-save &amp;gt;&amp;gt; /etc/iptables.rules
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On &lt;em&gt;/etc/network/interfaces&lt;/em&gt;, add this line underneath &amp;ldquo;iface lo inet loopback&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nano /etc/network/interfaces
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;pre-up iptables-restore &amp;lt; /etc/iptables.rules
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#That&amp;rsquo;s it&lt;/p&gt;

&lt;p&gt;By now you should have a basic Linux gateway for your network. Much more advanced configuration can be done that can add enormous flexibility. It&amp;rsquo;s up to you to start exploring and unleash the true power of having a dedicated machine as your router.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
